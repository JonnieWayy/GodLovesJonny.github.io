<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>vlp on Zijie Wang`s Blog</title>
    <link>http://wzj.life/tags/vlp/</link>
    <description>Recent content in vlp on Zijie Wang`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Sat, 11 Mar 2023 17:19:21 +0800</lastBuildDate><atom:link href="http://wzj.life/tags/vlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[论文阅读笔记 -- VLP] RelationCLIP: Training-free FG Visual &amp; Language Concept Match (2023)</title>
      <link>http://wzj.life/2023/prn367/</link>
      <pubDate>Sat, 11 Mar 2023 17:19:21 +0800</pubDate>
      
      <guid>http://wzj.life/2023/prn367/</guid>
      <description>RelationCLIP: Training-free Fine-grained Visual and Language Concept Matching (2022) 概述 本文提出一种 RelationCLIP 架构。 模型架构 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VLP] MedCLIP: CL from Unpaired Medical Images and Text (EMNLP 2022)</title>
      <link>http://wzj.life/2023/prn365/</link>
      <pubDate>Thu, 09 Mar 2023 15:16:48 +0800</pubDate>
      
      <guid>http://wzj.life/2023/prn365/</guid>
      <description>MedCLIP: Contrastive Learning from Unpaired Medical Images and Text (EMNLP 2022) 开源代码传送门 概述 图文预训练在医药领域的困难 可获取的数据量不足 医药任务中各域之间的差异更加细化 本文提出 MedCLIP，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VLP] Vision Learners Meet Web Image-Text Pairs (2023)</title>
      <link>http://wzj.life/2023/prn361/</link>
      <pubDate>Sun, 05 Mar 2023 08:34:37 +0800</pubDate>
      
      <guid>http://wzj.life/2023/prn361/</guid>
      <description>2301.07088 Vision Learners Meet Web Image-Text Pairs (2023) 开源代码传送门 概述 可以将先前的表征学习方法分为三类： Single-modal Discriminative (SimCLR) Single-modal Generative (MAE) Mlti-modal Discriminative (CLIP) 两个发现： 生成式方法的迁移表现更好 单模态 SSL 方法通常比多</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VLP] RILS: Masked Visual Reconst. in Language Semantic Space (CVPR 2023)</title>
      <link>http://wzj.life/2023/prn360/</link>
      <pubDate>Sat, 04 Mar 2023 22:00:41 +0800</pubDate>
      
      <guid>http://wzj.life/2023/prn360/</guid>
      <description>RILS: Masked Visual Reconstruction in Language Semantic Space (CVPR 2023) 开源代码传送门 概述 本文提出一种 masked visual Reconstruction In Language semantic Space (RILS) 预训练框架。 架构对比</description>
    </item>
    
  </channel>
</rss>
