<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CNN on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/tags/cnn/</link>
    <description>Recent content in CNN on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Thu, 02 Dec 2021 20:43:49 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/tags/cnn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[论文阅读笔记 -- ViT] MetaFormer is Actually What You Need for Vision (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn133/</link>
      <pubDate>Thu, 02 Dec 2021 20:43:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn133/</guid>
      <description>2111.11418 MetaFormer is Actually What You Need for Vision (2021) 开源代码传送门 概述 Transformer 中的编码器包含两部分，其一是注意力模块，用于混合 token 之间的信息，本文称之为 token mixer；其二是其余的模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Escaping the Big Data Paradigm with Compact Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn114/</link>
      <pubDate>Thu, 11 Nov 2021 20:39:25 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn114/</guid>
      <description>2104.05704 Escaping the Big Data Paradigm with Compact Transformers (2021) 开源代码传送门 概述 针对 Transformer 模型的数据饥饿 (data hungry) 传统观点，尝试弥合 Transformer 和 CNN 两种架构之间的鸿沟，结合二者优势，使得基于 Transformer 的模型能够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Contextual Transformer Networks for Visual Recognition (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn89/</link>
      <pubDate>Thu, 02 Sep 2021 21:44:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn89/</guid>
      <description>2107.12292 Contextual Transformer Networks for Visual Recognition (CVPRW 2021) 开源代码传送门 概述 现有 ViT 方法的问题 只是基于各位置上孤立的 key 和 query 求得注意力矩阵，忽略了相邻 key 之间丰富的上下文信息。 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] CAT: Cross Attention in Vision Transformer (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn77/</link>
      <pubDate>Thu, 12 Aug 2021 16:00:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn77/</guid>
      <description>2106.05786 CAT: Cross Attention in Vision Transformer (2021) 开源代码传送门 核心 设计了一种在单通道特征图上做注意力的方法，提出交叉注意力。 结合 Transformer 和 CNN 的优点构建 CAT。 Patch 内自注意力块 (IPSA) 与 Patch</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Transformer in Convolutional Neural Networks (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn70/</link>
      <pubDate>Tue, 03 Aug 2021 12:09:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn70/</guid>
      <description>2106.03180 Transformer in Convolutional Neural Networks (2021) 开源代码传送门 概览 本文提出层级化的多头注意力 (H-MHSA)。 为了结合 CNN 与 Transformer 的优势，提出 Transformer in Convolutional Neural Networks (TransCNN) 的概念，TransCNN 直</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Early Convolutions Help Transformers See Better (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn60/</link>
      <pubDate>Tue, 27 Jul 2021 11:07:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn60/</guid>
      <description>2106.14881 Early Convolutions Help Transformers See Better (2021) ViT 模型对超参数敏感，不好优化；而 CNN 更容易优化。 本文认为问题在于 ViT 的前期视觉处理 (early visual processing)，通常是 patchify stem，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Improving Image Classification With Frequency Domain Layers (MLSP 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn48/</link>
      <pubDate>Fri, 16 Jul 2021 15:02:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn48/</guid>
      <description>Improving image classification with frequency domain layers for feature extraction (MLSP 2017) 核心 研究从频域提取的特征对深度网络架构的作用。 提出频率特征提取层。 方法 对输入图像层级式分块以提取多粒度信息，对各块使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] High-Frequency Component Explain Generalization of CNNs (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn47/</link>
      <pubDate>Fri, 16 Jul 2021 10:29:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn47/</guid>
      <description>High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks (CVPR 2020) 背景 从数据视角研究 CNN 的泛化表现。 CNN 挖掘高频成分 将原始数据分解为高低频成分，\(x = \{x_{l}, x_{h}\}\)，分别简写为 LFC</description>
    </item>
    
  </channel>
</rss>
