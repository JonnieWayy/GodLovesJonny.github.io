<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cv on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/tags/cv/</link>
    <description>Recent content in cv on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Sun, 23 Oct 2022 16:27:03 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/tags/cv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[论文阅读笔记 -- 特征分解] Visual Concepts Tokenization (NeurIPS 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn289/</link>
      <pubDate>Sun, 23 Oct 2022 16:27:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn289/</guid>
      <description>Visual Concepts Tokenization (NeurIPS 2022) 开源代码传送门 概述 本文针对视觉概念学习 (visual concept learning)，提出一种基于 transformer 的无监督方法，称为视觉概念令牌化 (Visual Concept Tokenization, VCT)，其包含</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Attention-Calibration Based Double-Branch CD ReID (KBS 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn288/</link>
      <pubDate>Sun, 23 Oct 2022 15:47:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn288/</guid>
      <description>Attention-Calibration Based Double-Branch Cross-Domain Person Re-Identification (KBS 2022) 概述 本文提出一种 Attention-Calibration Based Double-Branch Cross-Domain Person Re-Identification Network (ACDBNet)，其核心观点为：通道特征和空间特征用于提取可区别的特征，域无关特征和域特定特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Augmented Dual-Contrastive Aggregation Learn. for USVIReID(MM 22)</title>
      <link>http://jonathanwayy.xyz/2022/prn287/</link>
      <pubDate>Fri, 21 Oct 2022 13:43:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn287/</guid>
      <description>Augmented Dual-Contrastive Aggregation Learning for Unsupervised Visible-Infrared Person Re-Identification (MM 22) 开源代码传送门 概述 无监督 VI-ReID 任务。 本文提出一种 Augmented Dual-Contrastive Aggregation (ADCA) learning framework。 模型架构 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FastPR: One-stage Semantic PR via Self-supervised Learning (MM 22)</title>
      <link>http://jonathanwayy.xyz/2022/prn286/</link>
      <pubDate>Wed, 19 Oct 2022 11:45:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn286/</guid>
      <description>FastPR: One-stage Semantic Person Retrieval via Self-supervised Learning (MM 22) 开源代码传送门 概述 本文提出一种单阶段的语义行人检索方法，称为 FastPR，其包含三个主要部件： Multimodal Feature Encoder Dynamic Visual-Semantic Alignment Dual-Granularity Person Localization 模型架构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] C3CMR: CM Cross-Instance Contrastive Learn. for CMR (MM 22)</title>
      <link>http://jonathanwayy.xyz/2022/prn285/</link>
      <pubDate>Tue, 18 Oct 2022 10:04:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn285/</guid>
      <description>C3CMR: Cross-Modality Cross-Instance Contrastive Learning for Cross-Media Retrieval (MM 22) 概述 本文提出一种跨模态跨实例对比学习方法 (Cross-Modality Cross-Instance Contrastive Learning for Cross-Media Retrieval, C\(^{3}\)CMR)。 模型架构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Paired CM Data Augmentation for FG I2T Retrieval (MM 22)</title>
      <link>http://jonathanwayy.xyz/2022/prn284/</link>
      <pubDate>Mon, 17 Oct 2022 16:46:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn284/</guid>
      <description>Paired Cross-Modal Data Augmentation for Fine-Grained Image-to-Text Retrieval (MM 22) 概述 现有的数据增广方法无法改变原始数据的语义内容，且无法生成多样性丰富的数据。此外也缺少直接增广图文数据对的方法。 同时增</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CM Co-occurrence Attributes Alignments for PS by Language (MM 22)</title>
      <link>http://jonathanwayy.xyz/2022/prn283/</link>
      <pubDate>Sun, 16 Oct 2022 16:45:45 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn283/</guid>
      <description>Cross-modal Co-occurrence Attributes Alignments for Person Search by Language (MM 22) 概述 许多现有工作将 TBPR 任务视为集合对集合的属性对齐问题，但是会从在报告偏差 (reporting bias) 的困难，其导致的噪声主要在于两个方面： Noise from</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Weakly Supervised Pedestrian Segmentation for ReID (TCSVT 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn282/</link>
      <pubDate>Fri, 14 Oct 2022 12:08:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn282/</guid>
      <description>Weakly Supervised Pedestrian Segmentation for Person Re-Identification (TCSVT 2022) 概述 本文提出一种若监督的行人分割方法 (Weakly Supervised Pedestrian Segmentation, WSPS) 和一种图像合成增广方法 (Image Synthesis Augmentation, ISA) 用于 ReID。 分割表现对比 和现有弱监督分割方法</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] Generalizing to Unseen Domains: A Survey on DG (TKDE 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn281/</link>
      <pubDate>Thu, 13 Oct 2022 11:44:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn281/</guid>
      <description>Generalizing to Unseen Domains: A Survey on Domain Generalization (TKDE 2022) DeepDG 传送门 概述 域泛化综述。 域泛化定义 相关任务差异对比 现有 DG 方法分类 DG 的应用 常用 DG 数据集</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 迁移学习] Knowledge as Priors: CMKG for Datasets without SK (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn280/</link>
      <pubDate>Wed, 12 Oct 2022 11:31:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn280/</guid>
      <description>Knowledge as Priors: Cross-Modal Knowledge Generalization for Datasets without Superior Knowledge (CVPR 2020) 概述 本文基于跨模态知识蒸馏 (Cross-Modal Knowledge Distillation, CMKD) 任务，研究将从成对数据的源数据集上学习到的跨模态知识迁移到监督模态缺失的目标数据</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Style Variable and Irrelevant Learning for Generalizable ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn279/</link>
      <pubDate>Tue, 11 Oct 2022 11:07:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn279/</guid>
      <description>2209.05235 Style Variable and Irrelevant Learning for Generalizable Person Re-identification (2022) 概述 现有方法可以分为三类 基于对抗学习的方法 基于归一化的方法 基于元学习的方法 一个基本问题 DG-ReID 中包含的域偏差 (domain bias) 主要是哪些因</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FRIDA: Fisheye Re-Identification Dataset with Annotations (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn278/</link>
      <pubDate>Mon, 10 Oct 2022 10:21:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn278/</guid>
      <description>2210.01582 FRIDA: Fisheye Re-Identification Dataset with Annotations (2022) 数据集获取传送门 概述 本文提出鱼眼图像 ReID 任务，并构建了一个新数据集 FRIDA。 旨在找出被两个摄像头同时捕捉到的两种图像中相同的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] GReID with Relevance-aware Mixture of Experts (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn277/</link>
      <pubDate>Thu, 06 Oct 2022 14:28:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn277/</guid>
      <description>Generalizable Person Re-identification with Relevance-aware Mixture of Experts (CVPR 2021) 概述 现有工作通常将多个源域数据整合到一起训练一个模型，这类方法存在如下问题： 为不同的域学习一个公共的特征空间，可能会忽略</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Farewell to MI: Variational Distillation for CM ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn276/</link>
      <pubDate>Thu, 06 Oct 2022 10:33:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn276/</guid>
      <description>Farewell to Mutual Information: Variational Distillation for Cross-Modal Person Re-Identification (CVPR 2021) 概述 本文为信息瓶颈 (Information Bottleneck, IB) 提出了一种新策略，称为变分自蒸馏 (Variational Self-Distillation, VSD)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parallel Data Augmentation for Text-based Person ReID (IJCNN 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn275/</link>
      <pubDate>Tue, 04 Oct 2022 10:11:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn275/</guid>
      <description>Parallel Data Augmentation for Text-based Person Re-identification (IJCNN 2022) 概述 本文提出一种 Parallel Data Augmentation (PDA) 方法。 本文方法</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域自适应] Feat. Align. by Uncertainty and Self-Training for SFUDA (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn274/</link>
      <pubDate>Tue, 27 Sep 2022 14:32:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn274/</guid>
      <description>2208.14888 Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation (2022) 概述 本文提出一种 source-free UDA 方法，称为 Feature Alignment by Uncertainty and Self-Training (FAUST)。 模型架构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] MVDG: A Unified Multi-view Framework for DG (ECCV 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn273/</link>
      <pubDate>Mon, 26 Sep 2022 13:48:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn273/</guid>
      <description>MVDG: A Unified Multi-view Framework for Domain Generalization (ECCV 2022) 开源代码传送门 概述 域泛化问题。 本文认为源域上过拟合的问题不仅存在于训练阶段，对测试阶段也有很大影响。 本文提出一种多视角架</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Continuous and Unified Person Re-Identification (SPL 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn272/</link>
      <pubDate>Fri, 23 Sep 2022 13:45:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn272/</guid>
      <description>Continuous and Unified Person Re-Identification (SPL 2022) 概述 可将 ReID with piecemeal new data 分为两类： Online-learning ReID Domain Incremental Learning ReID 本文提出一种 Continuous and Unified ReID (CUReID) 任务，需要模型在不同风格的连续数据流上训练，并在各训练步骤后的联</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Composed IR via Explicit Erasure and Replenishment(TIP 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn271/</link>
      <pubDate>Mon, 19 Sep 2022 15:44:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn271/</guid>
      <description>Composed Image Retrieval via Explicit Erasure and Replenishment With Semantic Alignment (TIP 2022) 概述 Composed Image Retrieval (CIR) 任务。 本文将 CIR 任务分为两个显式的子过程： 删去参考图像中不符合用户需求的细节 补充包含用户需求的文本细节 本</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] CrossNorm and SelfNorm for Generalization under DS (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn270/</link>
      <pubDate>Sun, 18 Sep 2022 13:28:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn270/</guid>
      <description>CrossNorm and SelfNorm for Generalization under Distribution Shifts (ICCV 2021) 开源代码传送门 概述 本文从两个方面处理分布迁移问题： 增大训练分布 减小测试分布 本文提出互补的 CrossNorm 和 SelfNorm。 本文方法 可</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] Feature-based Style Randomization for DG (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn269/</link>
      <pubDate>Sat, 17 Sep 2022 15:07:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn269/</guid>
      <description>2106.03171 Feature-based Style Randomization for Domain Generalization (2021) 概述 现有大部分 DG 方法只在源域做图像级别的数据增广，本文旨在提高增广的多样性，提出一种基于特征的风格随机化模块 (Feature-based Style Randomization, FSR)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] Attention Consistency on Visual Corruptions for SSDG (CVPRW 22)</title>
      <link>http://jonathanwayy.xyz/2022/prn268/</link>
      <pubDate>Fri, 16 Sep 2022 17:30:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn268/</guid>
      <description>Attention Consistency on Visual Corruptions for Single-Source Domain Generalization (CVPRW 22) 开源代码传送门 概述 单源域泛化问题。 本文认为一个健壮的 single DG 模型应当对同一训练样本的多个增广给出一致的诠释；此外，所采用的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Image-Specific Info. Suppression and Implicit Local Alignment (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn267/</link>
      <pubDate>Sat, 03 Sep 2022 16:01:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn267/</guid>
      <description>2208.14365 Image-Specific Information Suppression and Implicit Local Alignment for Text-based Person Search (2022) 概述 两类会影响表现的图像特有信息： Image Background Environmental Factors 本文提出一种联合信息语义对齐网络 (joint Information and Semantic Alignment Network, ISANet)。 模型架构 Relation-Guide Localization</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Identity-Sensitive Knowledge Propagation for CCReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn266/</link>
      <pubDate>Wed, 31 Aug 2022 20:55:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn266/</guid>
      <description>2208.12023 Identity-Sensitive Knowledge Propagation for Cloth-Changing Person Re-identification (2022) 概述 本文提出一种对身份敏感的知识传播框架 (Identity-Sensitive Knowledge Propagation framework, DeSK-Pro)。 模型架构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Dynamic Template Initialization for Part-Aware Person Re-ID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn265/</link>
      <pubDate>Wed, 31 Aug 2022 14:46:43 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn265/</guid>
      <description>2208.11440 Dynamic Template Initialization for Part-Aware Person Re-ID (2022) 概述 现有的局部特征学习策略可分为三类： 基于手工划分的方法 基于额外语义的方法，如行人解析或姿态估计 基于注意力的方法 这些方法各</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Intra-Modal Constraint Loss For Image-Text Retrieval (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn264/</link>
      <pubDate>Tue, 30 Aug 2022 21:15:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn264/</guid>
      <description>2207.05024 Intra-Modal Constraint Loss For Image-Text Retrieval (2022) 开源代码传送门 概述 本文提出一种模态内约束损失 (Intra-Modal Constraint loss, IMC)，以减小同一模态内负样本对的影响。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] VAC-Net: Visual Attention Consistency Network for ReID (ICMR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn263/</link>
      <pubDate>Tue, 30 Aug 2022 20:06:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn263/</guid>
      <description>VAC-Net: Visual Attention Consistency Network for Person Re-identification (ICMR 2022) 概述 本文提出一种视觉注意力一致性网络 (Visual Attention Consistency Network, VAC-Net)，用于同时解决视角变换和尺度变换问题。 模型架构 Input-wise Visual Consistent Loss Layer-wise Visual Consistent</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Domain Invariant Representations for Gen. ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn262/</link>
      <pubDate>Tue, 30 Aug 2022 17:34:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn262/</guid>
      <description>2103.15890 Learning Domain Invariant Representations for Generalizable Person Re-identification (2022) 概述 本文认为行人图像受以下两组潜在随机变量的影响： Identity-specific Factors \(S\) Domain-specific Factors \(V\) \(V\) 可能会混淆模型，两者间的伪相关也会使得模型难以基于 \(S\) 对 ID</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] See Finer, See More: Implicit Modality Alignment for TBPR (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn261/</link>
      <pubDate>Tue, 30 Aug 2022 14:01:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn261/</guid>
      <description>2208.08608 See Finer, See More: Implicit Modality Alignment for Text-based Person Retrieval (2022) 开源代码传送门 概述 现有方法的主要问题 分开的子模型缺乏模态间的交互 图文部件标注很费时，而且一些配对可能丢失 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Granularity-Unified Representations for T2I ReID (MM 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn260/</link>
      <pubDate>Fri, 19 Aug 2022 16:31:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn260/</guid>
      <description>Learning Granularity-Unified Representations for Text-to-Image Person Re-identification (MM 2022) 开源代码传送门 概述 视觉特征包含细粒度信息，而文本特征描述粗粒度属性，这导致了同一句文本描述适用于相似而不相同的多张图像。 本</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 隐私保护] Learnable Privacy-Preserving Anonymization for PImages (MM 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn259/</link>
      <pubDate>Wed, 03 Aug 2022 17:11:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn259/</guid>
      <description>Learnable Privacy-Preserving Anonymization for Pedestrian Images (MM 2022) 开源代码传送门 概述 本文关注 ReID 数据的隐私保护问题。 针对不同对象的应用效果 方法架构 训练策略 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Feature-Distribution Perturbation and Calibration for GReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn257/</link>
      <pubDate>Tue, 19 Jul 2022 18:11:43 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn257/</guid>
      <description>2205.11197 Feature-Distribution Perturbation and Calibration for Generalized ReID (2022) 概述 本文提出一种特征分布扰动与校准模型 (Feature-Distribution Perturbation and Calibration model, PECA)，其包含局部分布扰动和全局分布校准。 本文方法</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Style Interleaved Learning for Generalizable Person Re-identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn256/</link>
      <pubDate>Sat, 16 Jul 2022 13:34:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn256/</guid>
      <description>2207.03132 Style Interleaved Learning for Generalizable Person Re-identification (2022) 开源代码传送门 概述 本文提出一种风格交叉学习框架 (Style Interleaved Learning Framework)，每次迭代包含两次前向传播和一次反向传播，用合成的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Multiple Biological Granularities Network for Person ReID (ICMR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn255/</link>
      <pubDate>Tue, 12 Jul 2022 15:07:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn255/</guid>
      <description>Multiple Biological Granularities Network for Person Re-Identification (ICMR 2022) 概述 本文提出一种 Multiple Biological Granularities Network (MBGN) 架构。 本文方法 Adaptive Body Segmentation Algorithm Global Spatial Relation Pixel Attention 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] Learning to Diversify for Single Domain Generalization (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn254/</link>
      <pubDate>Mon, 11 Jul 2022 15:25:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn254/</guid>
      <description>Learning to Diversify for Single Domain Generalization (ICCV 2021) 开源代码传送门 概述 主流的 DG 技术可分为基于对齐的和基于增广的两种。 本文关注只有单个源域的域泛化问题，提出一种 Learning-to-diversify (L2D) 方法。 本文方</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] Domain Generalization: A Survey (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn253/</link>
      <pubDate>Thu, 07 Jul 2022 13:47:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn253/</guid>
      <description>2103.02503 Domain Generalization: A Survey (2021) 概述 域泛化综述。 两类 DG Multi-Source DG Single-Source DG 常用的 DG 数据集 表现衡量 通常遵循 leave-one-domain-out 原则，即留出一个域作为目标域。 用在留出的域上平均或最坏的表现来评估</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Meta Batch-Instance Normalization for Generalizable ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn252/</link>
      <pubDate>Sun, 03 Jul 2022 15:43:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn252/</guid>
      <description>Meta Batch-Instance Normalization for Generalizable Person Re-Identification (CVPR 2021) 开源代码传送门 概述 本文发现 BN 模型主要基于各个 mini-batch 中的风格变化来学习有鉴别力的信息，但是难以处理风格没见过的样本，因此称之为 u</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Dual Distribution Alignment Network for Generalizable ReID (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn251/</link>
      <pubDate>Sat, 02 Jul 2022 15:23:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn251/</guid>
      <description>Dual Distribution Alignment Network for Generalizable Person Re-Identification (AAAI 2021) 概述 DG for Person ReID 的两大困难 Domain-wise Variations Identity-wise Similarities 本文提出一种端到端的 双分布对齐网络 (Dual Distribution Alignment Network, DDAN)。 本文方法 Domain-wise Adversarial Feature Learning 旨在应对 Domain-wise Variations 问题。 将</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 域泛化] CADG: A Model Based on Cross Attention for D. Generalization (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn250/</link>
      <pubDate>Sat, 02 Jul 2022 13:47:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn250/</guid>
      <description>CADG: A Model Based on Cross Attention for Domain Generalization (2022) 概述 相比于集成学习，训练单个端到端模型来解决分布迁移问题更加可行。 本文设计了一种针对域泛化的交叉注意力 (Cross Attention for Domain Generalization, CAD</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TriReID: Towards MM ReID via Descriptive Fusion Model (ICMR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn249/</link>
      <pubDate>Thu, 30 Jun 2022 18:06:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn249/</guid>
      <description>TriReID: Towards Multi-Modal Person Re-Identification via Descriptive Fusion Model (ICMR 2022) 概述 本文提出以文本与草图相结合作为 query 的 ReID 任务，构建了 TriReID 数据集，提出一种描述性的融合模型 (Descriptive Fusion Model, DFM)。 TriReID 数据集 数据集对</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- Person Search] Weakly Supervised Sketch Based Person Search (ICMR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn248/</link>
      <pubDate>Mon, 27 Jun 2022 13:41:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn248/</guid>
      <description>Weakly Supervised Sketch Based Person Search (ICMR 2021) 概述 弱监督 Sketch Based Person Search 任务，没有选框标注。 本文提出一种基于聚类与特征注意力的弱监督学习架构 (clustering and feature attention based weakly supervised learning framework, CFA)，并构建了 Sketch</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Meta Distribution Alignment for Generalizable Person ReID (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn247/</link>
      <pubDate>Sun, 26 Jun 2022 16:16:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn247/</guid>
      <description>Meta Distribution Alignment for Generalizable Person Re-Identification (CVPR 2022) 开源代码传送门 概述 Domain Generalization (DG) ReID 任务。 现有方法通常试图学习域不变的特征，但是忽略了一种典型有效的跨域策略，即跨越源域和目标域对齐</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Emphasizing Comple. Samples for Non-literal CMR (CVPRW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn246/</link>
      <pubDate>Fri, 24 Jun 2022 14:06:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn246/</guid>
      <description>Emphasizing Complementary Samples for Non-literal Cross-modal Retrieval (CVPRW 2022) 概述 本文提出图像与文本之间关系存在远近，设计了两种度量： DISCREPANCY: 一阶，样本与其邻居的邻居之间的关系 DIVERSITY: 二阶，样本的邻居与其他邻居之</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Hierarchical VT KD for Life-Long Correlation Learning (IJCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn245/</link>
      <pubDate>Wed, 22 Jun 2022 15:31:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn245/</guid>
      <description>Hierarchical Visual-Textual Knowledge Distillation for Life-Long Correlation Learning (IJCV 2021) 概述 本文提出一种视觉-文本终身知识蒸馏方法 (Visual-textual Life-long Knowledge Distillation approach, VLKD)，在语义与注意力级别利用从现有数据中学习到的知识。 核心思路</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] LUDA ReID with Coordinated Anti-forgetting and Adaptation (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn244/</link>
      <pubDate>Mon, 20 Jun 2022 14:40:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn244/</guid>
      <description>Lifelong Unsupervised Domain Adaptive Person Re-identification with Coordinated Anti-forgetting and Adaptation (CVPR 2022) 数据集传送门 概述 LL ReID 连续的监督域自适应任务 需要大量目标域中的标注，费时费力不适合快速自适应及隐私保护 旨在平衡抑制遗</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FMCNet: Feature-Level Modality Compensation for VI ReID (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn243/</link>
      <pubDate>Sat, 18 Jun 2022 17:05:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn243/</guid>
      <description>FMCNet: Feature-Level Modality Compensation for Visible-Infrared Person Re-Identification (CVPR 2022) 概述 本文提出一种特征级别的模态弥补网络 (Feature-level Modality Compensation Network, FMCNet)。 模型架构 MD Loss FMC Module</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Doppelganger Saliency: Towards More Ethical Person ReID (CVPRW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn242/</link>
      <pubDate>Fri, 17 Jun 2022 13:27:43 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn242/</guid>
      <description>Doppelganger Saliency: Towards More Ethical Person Re-Identification (CVPRW 2022) 概述 本文关注 ReID 模型的可解释性及其对于相似行人图像的区分。 本文方法</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Id-Free Person Similarity Learning (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn241/</link>
      <pubDate>Thu, 16 Jun 2022 16:20:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn241/</guid>
      <description>Id-Free Person Similarity Learning (CVPR 2022) 概述 本文旨在仅利用 bounding box 作为监督信息学习行人搜索模型，称为 PointID。 模型架构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-modal Local Shortest Path and Global Enhancement (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn240/</link>
      <pubDate>Thu, 16 Jun 2022 13:50:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn240/</guid>
      <description>2206.04401 Cross-modal Local Shortest Path and Global Enhancement for Visible-Thermal Person Re-Identification (2022) 概述 本文构建了跨模态的局部最短路模块和全局增强模块，核心思想在于利用局部特征对齐解决遮挡问题，通过增强全局特征解决</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TeachText: CrossModal Generalized Distillation for TVR (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn239/</link>
      <pubDate>Wed, 15 Jun 2022 15:34:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn239/</guid>
      <description>TeachText: CrossModal Generalized Distillation for Text-Video Retrieval (ICCV 2021) 开源代码传送门 概述 本文提出 TEACHTEXT，充分利用来自多个文本编码器的额外信息。 不同文本嵌入的影响 本文发现很多 query 都对所</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Disentangled Representation Learning for Text-Video Retrieval (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn238/</link>
      <pubDate>Wed, 15 Jun 2022 10:44:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn238/</guid>
      <description>2203.07111 Disentangled Representation Learning for Text-Video Retrieval (2022) 概述 两个隐含的假设 文本描述可能只涉及局部的视频内容 同一段视频存在不同的描述视角 典型的文本-视频检索架构及本文方法 模型架构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Augmented Geometric Distillation for Data-Free Incre. ReID (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn237/</link>
      <pubDate>Tue, 14 Jun 2022 15:04:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn237/</guid>
      <description>Augmented Geometric Distillation for Data-Free Incremental Person ReID (CVPR 2022) 开源代码传送门 概述 本文关注 Incremental ReID (IL-ReID) 任务，提出了一种增广的几何蒸馏架构 (Augmented Geometric Distillation framework, AGD)，其包含增广蒸馏 (AD) 和几何蒸馏 (GD)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Salient-to-Broad Transition for Video Person Re-identification (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn236/</link>
      <pubDate>Tue, 14 Jun 2022 10:17:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn236/</guid>
      <description>Salient-to-Broad Transition for Video Person Re-identification (CVPR 2022) 开源代码传送门 概述 现有方法的两大不足： 注意力中心集中于显著但是局部的区域，扩大注意力区域能够进一步增强鲁棒性 帧之间时序关联即</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CM ReID via Modality-aware Collaborative Ensemble Learning (TIP 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn235/</link>
      <pubDate>Mon, 13 Jun 2022 19:04:06 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn235/</guid>
      <description>Cross-Modality Person Re-Identification via Modality-aware Collaborative Ensemble Learning (TIP 2020) 概述 本文提出一种借助中间级别可共享双分支网络 (middle-level sharable two-stream network, MSTN) 的模态可知协作集成学习方法 (modality-aware collaborative ensemble learning, MACE)，其基本想法是在特征级</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Memory-Augmented Unidirectional Metrics for ReID (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn234/</link>
      <pubDate>Mon, 13 Jun 2022 15:57:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn234/</guid>
      <description>Learning Memory-Augmented Unidirectional Metrics for Cross-modality Person Re-identification (CVPR 2022) 概述 本文提出一种 Memory-Augmented Unidirectional Metric (MAUM) 学习方法。 其学习两个单向的尺度，即 IR to RGB 和 RGB to IR，而非通常的一个公共中转，得到两个模态特定的代</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- GReID] Modeling 3D Layout For Group Re-Identification (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn233/</link>
      <pubDate>Mon, 13 Jun 2022 15:23:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn233/</guid>
      <description>Modeling 3D Layout For Group Re-Identification (CVPR 2022) 数据集传送门 概述 Group Re-identification (GReID) 任务。 通常处理包含 2 到 6 人的组，将含有超过 60% 相同成员的组视为相同类别。 本文从 3D 视角对分布关系进行建模，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Negative-Aware Attention Framework for IT Matching (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn232/</link>
      <pubDate>Sun, 12 Jun 2022 10:51:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn232/</guid>
      <description>Negative-Aware Attention Framework for Image-Text Matching (CVPR 2022) 开源代码传送门 概述 现有工作通常忽视了失配文本部件的作用，其描述了图像中不存在的内容。 本文认为一个合理的匹配架构应当同时考虑两</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Online Unsupervised Domain Adaptation for Person Re-identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn231/</link>
      <pubDate>Sat, 11 Jun 2022 14:13:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn231/</guid>
      <description>2205.04383 Online Unsupervised Domain Adaptation for Person Re-identification (2022) 概述 两类用于 ReID 的 UDA 方法 Domain Translation-based Methods Pseudo-label based Methods 这些方法都假设能够在训练过程中获取到一大批来自目标域的样本，从而进行离线 (offline) 的自适应。而本</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Identity-Guided Human Semantic Parsing for Person ReID (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn230/</link>
      <pubDate>Thu, 09 Jun 2022 20:50:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn230/</guid>
      <description>Identity-Guided Human Semantic Parsing for Person Re-Identification (ECCV 2020) 开源代码传送门 概述 本文提出一种身份指导的语义解析方法 (Identity-guided Semantic Parsing, ISP)，通过行人身份标签定位躯干部分和物件。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Super‐resolution‐based Part Collaboration Network for VReID (WWW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn229/</link>
      <pubDate>Tue, 07 Jun 2022 14:52:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn229/</guid>
      <description>Super‐resolution‐based Part Collaboration Network for Vehicle Re‐identification (WWW 2022) 概述 Vehicle ReID 的两个主要困难 Intra-instance Difference Inter-instance Similarity 本文提出一种双分支</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Scalable Vehicle Re-Identification via Self-Supervision (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn228/</link>
      <pubDate>Thu, 26 May 2022 12:13:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn228/</guid>
      <description>2205.07613 Scalable Vehicle Re-Identification via Self-Supervision (2022) 概述 本文提出一种 Self-Supervised and Boosted VEhicle Re-Identification (SSBVER) 方法，包含一个学生网络和一个教师网络，二者结构相同。</description>
    </item>
    
    <item>
      <title>Latex argmin 与 argmax 中下标出现在下方的一种方式</title>
      <link>http://jonathanwayy.xyz/2022/latex_argminmax_down/</link>
      <pubDate>Fri, 13 May 2022 00:27:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/latex_argminmax_down/</guid>
      <description>记录一种 Latex 中使 argmin 与 argmax 命令的下标出现在下方的一种方式： \begin{equation} \mathop{\arg\min}_{\theta} ... \end{equation} 如此即可。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] X-Pool: CM Language-Video Attention for TV Retrieval (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn227/</link>
      <pubDate>Wed, 11 May 2022 11:41:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn227/</guid>
      <description>X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval (CVPR 2022) 开源代码传送门 概述 现有工作通常用视频的整体特征进行匹配，但是一段视频可能包含多样的内容。 本文提出 X-Pool，进行文本与视</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Clothes-Changing Person ReID with RGB Modality Only (CVPR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn226/</link>
      <pubDate>Tue, 10 May 2022 10:12:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn226/</guid>
      <description>Clothes-Changing Person Re-identification with RGB Modality Only (CVPR 2022) 开源代码传送门 概述 CCReID 任务。 本文旨在更好地从 RGB 模态挖掘与衣着无关的信息，而不借助额外模态，提出一种基于衣着的对抗损失 (Clothes-based Adversarial Loss, C</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Lifelong Person ReID by Pseudo Task Knowledge Preservation (AAAI 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn225/</link>
      <pubDate>Sun, 08 May 2022 16:30:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn225/</guid>
      <description>Lifelong Person Re-identification by Pseudo Task Knowledge Preservation (AAAI 2022) 开源代码传送门 概述 Lifelong ReID 任务。 两个主要困难 面向任务的域鸿沟 训练集与测试集的 ID 不重叠，与识别任务的终身学习不同，是一个开集问</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Uncertainty-based CMR with Probabilistic Representations (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn224/</link>
      <pubDate>Thu, 28 Apr 2022 20:01:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn224/</guid>
      <description>2204.09268 Uncertainty-based Cross-Modal Retrieval with Probabilistic Representations (2022) 概述 不确定性的来源 文本方面主要来自单词和短语的一词多义 图像方面主要来自图像形成阶段，如遮挡等情况 同一张图像可以从许多不同角度</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Probabilistic Compositional Embeddings for MM IR (CVPRW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn223/</link>
      <pubDate>Wed, 27 Apr 2022 10:29:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn223/</guid>
      <description>2204.05845 Probabilistic Compositional Embeddings for Multimodal Image Retrieval (CVPRW 2022) 开源代码传送门 概述 本文关注多模态图像检索 (multimodal image retrieval) 任务，其 query 包含任意数量的图文数据，并提出了一种 Multimodal Probabilistic Composer (MPC)。 本文方法 Modality-Specific</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态预训练] LiT: Zero-Shot Transfer with Locked-image text Tuning (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn222/</link>
      <pubDate>Sun, 24 Apr 2022 16:44:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn222/</guid>
      <description>2111.07991 LiT: Zero-Shot Transfer with Locked-image text Tuning (2022) 概述 零射迁移 (zero-shot transfer)，不同于传统零射学习，其预训练过程中看不到迁移相关的监督信息。 本文提出采用对比学习架构，提</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态预训练] Democratizing Contrastive Language-Image Pre-training (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn221/</link>
      <pubDate>Sat, 16 Apr 2022 20:27:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn221/</guid>
      <description>2203.05796 Democratizing Contrastive Language-Image Pre-training: A CLIP Benchmark of Data, Model, and Supervision (2022) 开源代码传送门 概述 现有关于 CLIP 的工作由于其训练策略及所用数据的差异，难以公平对比其表现。 本文旨在构建一个公平且可以</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cloning Outfits from Real-World Images to 3D Characters (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn220/</link>
      <pubDate>Thu, 14 Apr 2022 21:46:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn220/</guid>
      <description>2204.02611 Cloning Outfits from Real-World Images to 3D Characters for Generalizable Person Re-Identification (2022) 概述 本文直接自动从真实行人图像克隆得到虚拟 3D 人物。 数据集对比</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Uncertainty-Aware Multi-Shot Knowledge Distillation for ReID (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn219/</link>
      <pubDate>Thu, 07 Apr 2022 17:39:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn219/</guid>
      <description>Uncertainty-Aware Multi-Shot Knowledge Distillation for Image-Based Object Re-Identification (AAAI 2020) 概述 本文提出一种不确定性可知的多设教师-学生网络 (Uncertainty-aware Multi-shot Teacher-Student Network, UMTS)，包含一个教师网络和一个学生网络，利用多张图像来增强表</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-Modality Earth Mover’s Distance for Visible Thermal ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn218/</link>
      <pubDate>Thu, 24 Mar 2022 15:01:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn218/</guid>
      <description>2203.01675 Cross-Modality Earth Mover’s Distance for Visible Thermal Person Re-Identification (2022) 概述 VT-ReID 任务。 常用的分布对齐策略容易受到类内差异的影响。 本文提出一种新的分布对齐方法，成为跨模态推土机距离 (Cross-Modality</description>
    </item>
    
    <item>
      <title>Latex 使用 thanks 脚注后多出一个空白页问题解决办法</title>
      <link>http://jonathanwayy.xyz/2022/latex_thanks_blank_page_one/</link>
      <pubDate>Thu, 24 Mar 2022 14:50:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/latex_thanks_blank_page_one/</guid>
      <description>问题描述 在 LaTex 中使用如下命令添加作者及其单位： \author{A, B, C} \thanks{A is xxxxxx, B is xxxxxx, C is xxxxxx} 编译后发现在文档最开头多出了一个空白页。 原因分析 \thanks 放在 \author 命令外面，导致其</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] A Novel Mix-normalization Method for Generalizable MS ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn217/</link>
      <pubDate>Wed, 23 Mar 2022 21:28:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn217/</guid>
      <description>2201.09846 A Novel Mix-normalization Method for Generalizable Multi-source Person Re-identification (2022) 概述 本文旨在从数据增广角度出发，解决 generalizable multi-source person ReID 任务。 传统的 batch normalization 用相同的统计量来归一化一个 batch 中的所有样本，这可能会导致在训</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Sequential Learning for Cross-modal Retrieval (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn215/</link>
      <pubDate>Sun, 20 Mar 2022 20:59:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn215/</guid>
      <description>Sequential Learning for Cross-modal Retrieval (ICCVW 2019) 概述 本文提出一种序列化跨模态学习方法，依次学习各模态，并提出一种元学习方法来处理灾难性遗忘问题。 模型架构 Meta-learner</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] LOOPITR: Combining Dual and Cross Encoder Architectures(2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn214/</link>
      <pubDate>Sun, 20 Mar 2022 18:47:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn214/</guid>
      <description>2203.05465 LOOPITR: Combining Dual and Cross Encoder Architectures for Image-Text Retrieval (2022) 概述 本文提出 LOOPITR 模型，整合双编码器和交叉编码器架构。 本文方法 双编码器的输出作为交叉编码器的输入，得到匹配分数。 从交叉编</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Lifelong Person ReID via Contrastive Rehearsal (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn213/</link>
      <pubDate>Sat, 19 Mar 2022 17:31:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn213/</guid>
      <description>2203.06468 Unsupervised Lifelong Person Re-identification via Contrastive Rehearsal (2022) 开源代码传送门 概述 Lifelong Person ReID 任务，本文用无监督域自适应替代监督的跨域微调，提出无监督终身行人重识别任务。 本文将基于伪标签的对比</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Part-Aware Self-Supervised Pre-Training for Person ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn212/</link>
      <pubDate>Wed, 16 Mar 2022 08:16:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn212/</guid>
      <description>2203.03931 Part-Aware Self-Supervised Pre-Training for Person Re-identification (2022) 开源代码传送门 概述 研究表明在 LUPerson 上无监督预训练的表现比 ImageNet 上监督预训练更好。先前的工作直接采用现有的分类任务上的 SSL 方法，并不能完</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Two-stream Hierarchical Similarity Reasoning for IT Matching(2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn211/</link>
      <pubDate>Tue, 15 Mar 2022 22:43:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn211/</guid>
      <description>2203.05349 Two-stream Hierarchical Similarity Reasoning for Image-text Matching (2022) 概述 本文提出一种双分支层级化相似度推理网络 (Two-Stream Hierarchical Similarity Reasoning Network, TSHSR)。 模型架构 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] A Reproducibility Concern about Image-Text Retrieval (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn210/</link>
      <pubDate>Tue, 15 Mar 2022 12:38:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn210/</guid>
      <description>2203.03853 Where Does the Performance Improvement Come From? - A Reproducibility Concern about Image-Text Retrieval (2022) 开源代码传送门 概述 本文从可复现性层面对图文检索模型进行分析。 本文将图文检索架构分为三个模块： 模态嵌入 模态交互</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Fine-grained Cross-modal Alignment Network for TVR (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn209/</link>
      <pubDate>Wed, 09 Mar 2022 14:44:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn209/</guid>
      <description>Fine-grained Cross-modal Alignment Network for Text-Video Retrieval (MM 2021) 概述 文本-视频检索问题。 本文提出一种细粒度跨模态对齐网络 (Fine-grained Cross-modal Alignment Network, FCA-Net)。 模型架构 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Landmark Guided Embeddings for Animal ReID (WACVW 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn208/</link>
      <pubDate>Tue, 08 Mar 2022 21:27:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn208/</guid>
      <description>Learning Landmark Guided Embeddings for Animal Re-identification (WACVW 2020) 概述 动物重识别问题。 本文提出利用局部关键点来提升精度。 模型架构 热图示例 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Clothing Status Awareness for Long-Term Person ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn207/</link>
      <pubDate>Tue, 08 Mar 2022 16:14:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn207/</guid>
      <description>Clothing Status Awareness for Long-Term Person Re-Identification (ICCV 2021) 概述 本文关注 Long-Term Person Re-identification (LT-reID) 问题，现有方法可主要分为两类： Biometrics-based Approach Dada Adaptation based Approach 这些方法并没有显式地考虑真实的衣着状况，即各行人到底是否换了</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning by Aligning: VI ReID Using CM Correspondences (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn206/</link>
      <pubDate>Mon, 07 Mar 2022 23:17:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn206/</guid>
      <description>Learning by Aligning: Visible-Infrared Person Re-Identification Using Cross-Modal Correspondences (ICCV 2021) 开源代码传送门 概述 本文旨在利用跨模态图像之间的密集相关性。 本文方法 特征提取 浅层参数独立，深层参数共享。 CMAlign Module 用于双向对齐</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Multi-Scale Body-Part Mask Guided Attention for ReID (CVPRW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn205/</link>
      <pubDate>Mon, 07 Mar 2022 17:40:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn205/</guid>
      <description>Multi-Scale Body-Part Mask Guided Attention for Person Re-identification (CVPRW 2019) 概述 本文提出一种 Multi-scale Body-part Mask Guided Attention Network (MMGA) 架构。 整体架构 注意力模块 可视化示例</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Complementary Features Learning for ATReID (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn204/</link>
      <pubDate>Sun, 06 Mar 2022 12:56:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn204/</guid>
      <description>Pose-Guided Complementary Features Learning for Amur Tiger Re-Identification (ICCVW 2019) 开源代码传送门 概述 本文将老虎的姿态简化为头部朝右和头部朝左两种，将姿态分类作为子任务引入 ReID 特征学习架构。 提出一种多分支结</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Part-Pose Guided Amur Tiger Re-Identification (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn203/</link>
      <pubDate>Sat, 05 Mar 2022 22:07:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn203/</guid>
      <description>Part-Pose Guided Amur Tiger Re-Identification (ICCVW 2019) 开源代码传送门 概述 老虎重识别，2019 Computer Vision for Wild life Conservation Challenge (CVWC2019) Plain ReID 和 Wild ReID 赛道第一名。 Tiger ReID 相比 Person ReID 的差异 姿态变化更多 遮挡更多，复杂的自然</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] A Strong Baseline for Tiger Re-ID and its Bag of Tricks (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn202/</link>
      <pubDate>Sat, 05 Mar 2022 18:20:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn202/</guid>
      <description>A Strong Baseline for Tiger Re-ID and its Bag of Tricks (ICCVW 2019) 开源代码传送门 概述 老虎重识别任务，CVWC 2019 挑战赛 Plain ReID 赛道第三名。 本文方法 图像变换到 \(256 \times 256\)，分别对特征图做</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] ATRW: A Benchmark for Amur Tiger ReID in the Wild (MM 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn201/</link>
      <pubDate>Sat, 05 Mar 2022 15:49:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn201/</guid>
      <description>1906.05586 ATRW: A Benchmark for Amur Tiger Re-identification in the Wild (MM 2020) 数据集传送门 概述 老虎重识别任务，构建了 Amur Tiger Re-identification in the Wild (ATRW) 数据集。 通过条纹信息分辨 ID，将不同侧的老虎视为不同的样本。 数</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose Guided Gated Fusion for Person Re-identification (WACV 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn200/</link>
      <pubDate>Fri, 04 Mar 2022 18:14:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn200/</guid>
      <description>Pose Guided Gated Fusion for Person Re-identification (WACV 2020) 概述 本文提出一种新的 ReID 架构，包含一个外观学习分支和一个姿态估计分支，二者由一个门控融合网络整合到一起，从骨架网络中间层动态</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FD-GAN: Pose-guided Feature Distilling GAN (NeurIPS 2018)</title>
      <link>http://jonathanwayy.xyz/2022/prn199/</link>
      <pubDate>Fri, 04 Mar 2022 17:06:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn199/</guid>
      <description>FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification (NeurIPS 2018) 开源代码传送门 概述 本文提出一种特征蒸馏对抗生成网络 (Feature Distilling Generative Adversarial Network, FD-GAN)，在姿态变换情况下保留身份信息而不增加推断时</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Copy And Paste Method Based on Pose for Re-identification (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn198/</link>
      <pubDate>Fri, 04 Mar 2022 14:56:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn198/</guid>
      <description>2107.10479 Copy And Paste Method Based on Pose for Re-identification (2021) 概述 本文提出 Multiple Scenarios ReID 任务，有更复杂的背景、遮挡和姿态。 本文设计了一种基于姿态的复制粘帖方法 (Copy and Paste method based on Pose, CPP)，用于构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Visible Part Matching for Occluded ReID (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn197/</link>
      <pubDate>Thu, 03 Mar 2022 17:36:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn197/</guid>
      <description>Pose-guided Visible Part Matching for Occluded Person ReID (CVPR 2020) 开源代码传送门 概述 本文提出一种姿态指导的可见部分匹配网络 (Pose-guided Visible Part Matching network, PVPM)，以自学习形式挖掘可见分数，包含两个主要部件</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Efficient Online Label Consistent Hashing (ICME 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn196/</link>
      <pubDate>Thu, 24 Feb 2022 23:10:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn196/</guid>
      <description>Efficient Online Label Consistent Hashing for Large-Scale Cross-Modal Retrieval (ICME 2021) 概述 本文关注在线跨模态哈希问题，提出一种在线标签一致哈希方法 (Online Label Consistent Hashing approach, OLCH)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] HAVANA: Hierarchical and Variation-Normalized Autoencoder (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn195/</link>
      <pubDate>Tue, 22 Feb 2022 10:05:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn195/</guid>
      <description>2101.02568 HAVANA: Hierarchical and Variation-Normalized Autoencoder for Person Re-identification (2021) 概述 ReID 任务的一大困难在于同 ID 行人图像之间存在的差异，本文提出 HierArchical and VAriation-Normalized Autoencoder (HAVANA) 架构，在无需额外数据标注的情况下处理这一问题，其包</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Robust Person ReID by Modelling Feature Uncertainty (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn194/</link>
      <pubDate>Mon, 21 Feb 2022 12:55:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn194/</guid>
      <description>Robust Person Re-identification by Modelling Feature Uncertainty (ICCV 2019) 开源代码传送门 概述 本文关注如何用带噪训练数据学习一个健壮的 ReID 模型，数据噪声可以分为两类： Label Noise Data Outliers 本文提出 DistributionNet 以应对这两种噪声</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ASR / 终身学习] Towards Lifelong Learning of End-to-end ASR (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn193/</link>
      <pubDate>Sat, 19 Feb 2022 21:06:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn193/</guid>
      <description>2104.01616 Towards Lifelong Learning of End-to-end ASR (2021) 概述 终身学习 (LLL) 可分为三类： Regularization-based Methods: 通过在损失函数中加入正则化项来加固模型中的关键参数 Architecture-based Methods: 为各任务分配一定的模型容量，或扩展模型以</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 增量学习] Striking a Balance between Stability-Plasticity for CIL (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn192/</link>
      <pubDate>Sat, 19 Feb 2022 16:12:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn192/</guid>
      <description>Striking a Balance between Stability and Plasticity for Class-Incremental Learning (ICCV 2021) 概述 类增量学习任务 (Class-Incremental Learning, CIL)。 适应新类要求模型具有可塑性 (plasticity)，而不忘记学到的旧类别要求稳定性 (</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Adaptive CM Prototypes for Cross-Domain VLR (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn191/</link>
      <pubDate>Wed, 16 Feb 2022 22:09:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn191/</guid>
      <description>Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval (CVPR 2021) 概述 将在带标签源域上学习到的模型迁移到不带标签的目标域的任务被称为无监督域自适应 (UDA)，本文研究 UDA 设定下的跨模态检索问</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Generalising without Forgetting for Lifelong Person ReID (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn190/</link>
      <pubDate>Tue, 15 Feb 2022 15:53:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn190/</guid>
      <description>Generalising without Forgetting for Lifelong Person Re-Identification (AAAI 2021) 概述 本文关注 Lifelong ReID 任务，与传统终身学习任务相比有三个主要的不同及困难： 训练与测试类别不重叠，属于 ZSL 问题 数据序列来自不同的域 各</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Object ReID Using Teacher-Like and Light Students (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn189/</link>
      <pubDate>Tue, 15 Feb 2022 13:35:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn189/</guid>
      <description>Object Re-identification Using Teacher-Like and Light Students (BMVC 2021) 概述 本文提出一种联合蒸馏与剪枝方法 (Joint Distillation and Pruning method, JDP) 以学习与教师相似且轻量的学生模型 (Teacher-Like and Light students, TTL students)，其结合了知识蒸</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Lifelong ReID via Adaptive Knowledge Accumulation (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn188/</link>
      <pubDate>Sun, 13 Feb 2022 20:25:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn188/</guid>
      <description>Lifelong Person Re-Identification via Adaptive Knowledge Accumulation (CVPR 2021) 开源代码传送门 概述 本文提出终身行人重识别任务 (Lifelong Person Re-identification, LReID)，设计了一种自适应知识积累架构 (Adaptive Knowledge Accumulation framework, AKA)，从旧的域持续</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Continual Learning in Cross-modal Retrieval (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn187/</link>
      <pubDate>Sun, 13 Feb 2022 15:51:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn187/</guid>
      <description>Continual Learning in Cross-modal Retrieval (CVPRW 2021) 概述 本文将终身学习与跨模态检索相结合。 终身学习的一个困境在于所谓的灾难性遗忘 (catastrophic forgetting)，当前一种主流方法是给损失</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Multi-level Alignment Network for DA CMR (NC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn186/</link>
      <pubDate>Sat, 12 Feb 2022 18:05:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn186/</guid>
      <description>Multi-level Alignment Network for Domain Adaptive Cross-modal Retrieval (Neurocomputing 2021) 概述 本文关注域自适应跨模态检索问题，提出一种多级对齐网络 (Multi-level Alignment Network, MAN)，其包含一个视觉编码器、一个文本编码器和一个公共空</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-Modal Cross-Domain Moment Alignment Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn185/</link>
      <pubDate>Fri, 11 Feb 2022 15:51:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn185/</guid>
      <description>Cross-Modal Cross-Domain Moment Alignment Network for Person Search (CVPR 2020) 概述 本文最早提出跨模态跨域的文本行人检索任务，设计了一种时刻对齐网络 (Moment Alignment Network, MAN)，其包含三种对齐模块： Domain Alignment (DA) Cross-modal Alignment (CA) Exemplar Alignment</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Person Search by Text Attribute Query as ZSL (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn184/</link>
      <pubDate>Thu, 10 Feb 2022 13:47:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn184/</guid>
      <description>Person Search by Text Attribute Query as Zero-Shot Learning (ICCV 2019) 概述 本文最早将基于文本属性的行人检索任务定义为零样本学习问题，其 ZSL 设定上的主要困难在于粒度更细、图像噪声更多、行人类别</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] MVB: A Large-Scale Dataset for Baggage ReID (PRCV 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn183/</link>
      <pubDate>Sun, 06 Feb 2022 18:08:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn183/</guid>
      <description>MVB: A Large-Scale Dataset for Baggage Re-Identification and Merged Siamese Networks (PRCV 2019) 开源代码传送门 概述 行李 ReID 任务，本文构建了一个大规模的新数据集，称为 MVB (Multi View Baggage)，并提出一种基线模型，称为</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 哈希] Faster Person Re-Identification (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn182/</link>
      <pubDate>Fri, 04 Feb 2022 16:55:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn182/</guid>
      <description>Faster Person Re-Identification (ECCV 2020) 开源代码传送门 概述 ReID 任务与一般的图像任务相比具有其特殊性，属于开放集合中实例级别的匹配，训练集与测试集的类别 (ID) 不同，这导致了需要很</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch 修改官方预训练模型输入通道数</title>
      <link>http://jonathanwayy.xyz/2022/ldp_pytorch_resnet_input/</link>
      <pubDate>Thu, 03 Feb 2022 15:48:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/ldp_pytorch_resnet_input/</guid>
      <description>有时需要修改预训练模型的输入通道数，在此记录一下一种可行的方法。 首先加载需要修改的预训练模型，查看一下模型的第一层，以 ResNet-50 为例： import torchvision.models as models backbone = models.resnet101(pretrained=False)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Hashing Person Re-ID with Self-distilling Smooth Relaxation (NC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn181/</link>
      <pubDate>Sun, 30 Jan 2022 22:02:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn181/</guid>
      <description>Hashing Person Re-ID with Self-distilling Smooth Relaxation (Neurocomputing 2021) 概述 影响哈希 ReID 表现的两大因素： 特征表征：与非哈希方法的浮点特征相比，哈希编码在表征能力上具有内在的劣势 哈希松弛度：为了能够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像检索] Self-Supervised Product Quantization for Uns. IR (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn180/</link>
      <pubDate>Sun, 30 Jan 2022 14:47:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn180/</guid>
      <description>Self-Supervised Product Quantization for Deep Unsupervised Image Retrieval (ICCV 2021) 开源代码传送门 概述 本文提出首个无监督端到端基于量化的图像检索方法，称为 Self-supervised Product Quantization (SPQ) Network，联合学习特征提取器和编码。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Divide-and-Merge the Embedding Space (Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn179/</link>
      <pubDate>Sat, 29 Jan 2022 14:55:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn179/</guid>
      <description>Divide-and-Merge the Embedding Space for Cross-modality Person Search (Neurocomputing 2021) 概述 本文提出一种分治嵌入学习架构 (Divide-and-Merge Embedding Learning Framework, DME)，关注两方面： 如何提取健壮的局部表征，而避免产生无意义信息 如何有效合并多</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Tiled SE: Channel Att. With Local Spatial Context (ICCVW 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn178/</link>
      <pubDate>Thu, 27 Jan 2022 18:06:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn178/</guid>
      <description>Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context (ICCVW 2021) 概述 旨在分析有效的通道注意力所需的最小空间上下文。 本文基于 SENet 提出一种 Tiled Squeeze-and-Excite (TSE) 注意力。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Short Range Correlation Transformer for Occluded Person ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn177/</link>
      <pubDate>Mon, 24 Jan 2022 14:16:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn177/</guid>
      <description>2201.01090 Short Range Correlation Transformer for Occluded Person Re-Identification (2022) 概述 Vision Transformer 在有遮挡的情况下并不擅长捕捉局部特征，本文提出一种基于 Vision Transformer 包含三种模块的 PFT 模型，以提升 patch 序列的短距离相关性并提取</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 知识蒸馏] SimReg: Regression as a Simple Yet Effective Tool (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn176/</link>
      <pubDate>Sun, 23 Jan 2022 14:22:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn176/</guid>
      <description>2201.05131 SimReg: Regression as a Simple Yet Effective Tool for Self-supervised Knowledge Distillation (BMVC 2021) 开源代码传送门 概述 本文关注自监督模型的蒸馏，发现 backbone 输出的特征比预测头最后一层输出的特征能更好地与教师模型相匹配</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- GeM Pooling 的 Pytorch 实现</title>
      <link>http://jonathanwayy.xyz/2022/ldp_gempooling/</link>
      <pubDate>Fri, 21 Jan 2022 23:21:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/ldp_gempooling/</guid>
      <description>记录一下 Generalized Mean Pooling (GeM 池化) 的一种 PyTorch 实现方式。 定义 GeM 池化公式定义如下： $$f_{g, c} = (\frac{1}{hw} \sum_{(i, j)} f_{4, (c, i, j)}^p)^{1/p}_{c = 1, 2, \dots, C},$$ 其中超参数 \(p &amp;gt; 0\)，默认设为 3.0，\(f_</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Explainable ReID With Attribute-Guided Metric Distillation (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn175/</link>
      <pubDate>Fri, 21 Jan 2022 14:49:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn175/</guid>
      <description>Explainable Person Re-Identification With Attribute-Guided Metric Distillation (ICCV 2021) 开源代码传送门 概述 旨在借助语义属性学习一个解释器，以回答如下两个问题： 是什么属性使两个人不同？ 各属性对差异有多大的影响？ 本</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像检索] DOLG: Deep Orthogonal Fusion of Local Global Feat. (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn174/</link>
      <pubDate>Thu, 20 Jan 2022 17:48:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn174/</guid>
      <description>DOLG: Single-Stage Image Retrieval With Deep Orthogonal Fusion of Local and Global Features (ICCV 2021) 开源代码传送门 (PaddlePaddle) 概述 本文提出一种深度正交局部与全局特征融合模型 (Deep Orthogonal Local and Global feature fusion model, DOLG)，由一个局部分支和一个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parsing-based View-aware Embedding Network for VReID (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn173/</link>
      <pubDate>Tue, 18 Jan 2022 14:44:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn173/</guid>
      <description>Parsing-based View-aware Embedding Network for Vehicle Re-Identification (CVPR 2020) 概述 车辆 ReID 任务。 本文提出一种基于解析的视角可知的嵌入网络 (Parsing-based View-aware Embedding Network, PVEN)，包含三个部分： vehicle part parser view-aware feature alignent common-visible feature enhancement 本文方法 Vehicle Part Parser</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] On Exploring Pose Estimation as an Auxiliary Learning Task (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn172/</link>
      <pubDate>Sun, 16 Jan 2022 20:46:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn172/</guid>
      <description>2201.03859 On Exploring Pose Estimation as an Auxiliary Learning Task for Visible-Infrared Person Re-identification (2022) 开源代码传送门 概述 本文提出一种双分支的 VI-ReID 架构，通过联合学习一个姿态估计的辅助任务和一个行人 ReID 的主任务，提取模态</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 人脸识别] End2End OFR by Masking Corrupted Features (TPAMI 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn171/</link>
      <pubDate>Fri, 14 Jan 2022 16:38:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn171/</guid>
      <description>End2End Occluded Face Recognition by Masking Corrupted Features (TPAMI 2021) 开源代码传送门 概述 本文关注带遮挡的人脸识别问题。 主要有两类应对遮挡的思路： 恢复 (Recovering): 先恢复被遮挡的面部，再进行识别，但恢复面</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Masking Modalities for Cross-modal Video Retrieval (WACV 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn170/</link>
      <pubDate>Thu, 13 Jan 2022 14:33:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn170/</guid>
      <description>Masking Modalities for Cross-modal Video Retrieval (WACV 2022) 概述 通过自然语言检索视频。 本文提出一种新的预训练策略，从教学视频中学习多模态融合。预训练过程中使用一种模态掩码策略 (modality masking str</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Integrating Information Theory and Advers. Learning (PR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn169/</link>
      <pubDate>Thu, 13 Jan 2022 13:21:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn169/</guid>
      <description>Integrating Information Theory and Adversarial Learning for Cross-modal Retrieval (PR 2021) 概述 本文将香农信息论与对抗学习相结合，以对抗的方式结合信息熵预测器与模态分类器。 本文方法 信息熵与模态不确定性 用信息熵衡</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Fusion-Attention Network for Person Search with Language (PRL 2018)</title>
      <link>http://jonathanwayy.xyz/2022/prn168/</link>
      <pubDate>Wed, 12 Jan 2022 21:10:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn168/</guid>
      <description>Fusion-Attention Network for Person Search with Free-form Natural Language (PRL 2018) 概述 这个课题上比较早的一篇文章，提出一种描述增强的融合注意力网络 (Description-Strengthened and Fusion-Attention Network, DSFA-Net)，包含一个融合子网络和一个注</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Clustering Active Learning for Person ReID (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn167/</link>
      <pubDate>Wed, 12 Jan 2022 15:46:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn167/</guid>
      <description>2112.13308 Unsupervised Clustering Active Learning for Person Re-identification (BMVC 2021) 概述 本文提出一种无监督聚类主动学习模型 (Unsupervised Clustering Active Learning model, UCAL)，结合无监督学习与主动学习的优势。 基本无监督聚类模型 选择基于 DBSCAN</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Transformer based LP Search with Multiple Region Slicing (TCSVT 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn166/</link>
      <pubDate>Wed, 12 Jan 2022 15:12:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn166/</guid>
      <description>Transformer based Language-Person Search with Multiple Region Slicing (TCSVT 2021) 概述 本文提出一种基于 Transformer 的语言-行人搜索架构，提出两种新的分割方式，分为重叠分割 (Overlapped Slicing, OS) 与基于关键点的分割 (Key-point-based Slicing)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Multi-Domain Joint Training for Person Re-Identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn165/</link>
      <pubDate>Wed, 12 Jan 2022 14:20:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn165/</guid>
      <description>2201.01983 Multi-Domain Joint Training for Person Re-Identification (2022) 概述 本文发现多个域联合训练得到的 ReID 表现比独立训练各个域要差，称为域冲突问题 (domain conflict problem)，域冲突可能来自于三种因素： 数</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Quality-aware Part Models for Occluded Person Re-identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn164/</link>
      <pubDate>Tue, 11 Jan 2022 13:17:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn164/</guid>
      <description>2201.00107 Quality-aware Part Models for Occluded Person Re-identification (2022) 概述 本文提出一种称为 Quality-aware Part Models (QPM) 的方法以解决遮挡 ReID 问题，其包含一个部分特征学习分支和一个全局特征学习分支。 Joint Learning Part Feature and Quality Scores Part Feature Extractor</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Attention Based Instance Discri. Learning (WACV 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn163/</link>
      <pubDate>Mon, 10 Jan 2022 12:09:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn163/</guid>
      <description>Unsupervised Attention Based Instance Discriminative Learning for Person Re-Identification (WACV 2022) 开源代码传送门 概述 本文提出一种组注意力模块 (grouped attention module, GAM) 以处理无监督 ReID 问题。 本文方法 Grouped Attention Module (GAM) 分为通道注意力和空间注意力两部分</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Text-Based Person Search with Limited Data (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn162/</link>
      <pubDate>Sat, 08 Jan 2022 14:00:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn162/</guid>
      <description>2110.10807 Text-Based Person Search with Limited Data (BMVC 2021) 开源代码传送门 概述 关注 TBPS 任务中训练数据缺乏的问题。 本文提出一种跨模态动量对比学习架构 (cross-modal momentum contrasive learning framework, CM-MoCo) 来丰富给定 mini-batch 中的训练数据，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TAGPerson: A Target-Aware Generation Pipeline for Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn161/</link>
      <pubDate>Sat, 08 Jan 2022 13:10:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn161/</guid>
      <description>2112.14239 TAGPerson: A Target-Aware Generation Pipeline for Person Re-identification (2021) 开源代码传送门 概述 本文提出一种目标可知的生成方法 (Target-Aware Generation pipeline, TAGPerson) 用于生成自动标注的合成 ReID 数据集。 本文方法的三点优势： 在渲染过程中</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Specific Person Retrieval via Incomplete Text Description (ICMR 2015)</title>
      <link>http://jonathanwayy.xyz/2022/prn160/</link>
      <pubDate>Fri, 07 Jan 2022 20:57:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn160/</guid>
      <description>Specific Person Retrieval via Incomplete Text Description (ICMR 2015) 概述 Specific Person Retrieval vis Incomplete Text Description 任务。 用户所提供的属性通常是不完整的，本文采用一种线性稀疏重构 (linear sparse reconstruction) 来不全不完整的属性。 本文方法 包含线下</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Improving Person ReID with Temporal Constraints (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn159/</link>
      <pubDate>Fri, 07 Jan 2022 16:16:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn159/</guid>
      <description>Improving Person Re-Identification with Temporal Constraints (WACVW 2022) DAA 数据集传送门 概述 本文构建了一个新的数据集，称为 DAA，旨在关注视觉信息的同时关注时空信息，数据集中含有时间戳信息、帧序号、</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FTN: Foreground-Guided Texture-Focused Person Re-Identification (2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn158/</link>
      <pubDate>Fri, 07 Jan 2022 13:18:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn158/</guid>
      <description>FTN: Foreground-Guided Texture-Focused Person Re-Identification (2020) 概述 本文关注背景干扰 (background interference) 问题，提出一种前景指导下关注纹理的网络 (Foreground-Guided Texture-Focused Network)，其包含一个语义编码器 (S-Enc)、一个紧凑</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Event-Driven Re-Id: Privacy-Preserving Person ReId (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn157/</link>
      <pubDate>Thu, 06 Jan 2022 14:04:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn157/</guid>
      <description>Event-Driven Re-Id: A New Benchmark and Method Towards Privacy-Preserving Person Re-Identification (WACVW 2022) 概述 关注 ReID 系统的隐私保护问题。事件相机 (event cameras) 记录场景的异步亮度变化，称之为事件 (event)。视觉信息被丢弃，只剩下</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] On the Importance of Appearance and Interaction (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn156/</link>
      <pubDate>Wed, 05 Jan 2022 14:24:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn156/</guid>
      <description>On the Importance of Appearance and Interaction Feature Representations for Person Re-Identification (WACVW 2022) 概述 本文认为不止是表征能力强的特征本身，特征之间的交互也在匹配时起到关键作用，交互信息与基于外观的特征互补。 本文</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Adversarial Attribute-Text Embedding for Person Search (TMM 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn155/</link>
      <pubDate>Tue, 04 Jan 2022 10:58:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn155/</guid>
      <description>Adversarial Attribute-Text Embedding for Person Search with Natural Language Query (TMM 2020) 概述 本文提出一种对抗的属性-文本嵌入网络 (adversarial attribute-text embedding network, AATE)。 视觉属性图卷积网络 包含一个视觉注意力模块和一个图卷积网络</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Person Tube Retrieval via Language Description (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn154/</link>
      <pubDate>Mon, 03 Jan 2022 20:17:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn154/</guid>
      <description>Person Tube Retrieval via Language Description (AAAI 2020) 概述 应该是开了一个新坑。 Person tube 指的是视频中包含一个行人的一系列 bounding box，其中的行人被较好框出而无需进行额外的行人检测。 本文提出</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] DRSL: Deep Relational Similarity Learning for CMR (INS 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn153/</link>
      <pubDate>Sun, 02 Jan 2022 15:11:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn153/</guid>
      <description>DRSL: Deep Relational Similarity Learning for Cross-modal Retrieval (Information Sciences 2021) 概述 学习公共空间的方法大多假设跨模态学习过程中的信息量是对等的，但通常各模态的信息量是不平衡的。 本文提出一种深度关系相</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Hybrid Ranking Representation for Person ReID (PR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn152/</link>
      <pubDate>Sun, 02 Jan 2022 14:10:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn152/</guid>
      <description>Learning Hybrid Ranking Representation for Person Re-identification (PR 2022) 概述 本文提出一种双分支的 RANkinG Ensemble (RANGEv2) 方法，联合优化外观特征与排序上下文信息以生成外部排序表征 (external ranking representation)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] A Feature Disentangling Approach via SS Data Augmentation (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn151/</link>
      <pubDate>Sat, 01 Jan 2022 14:25:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn151/</guid>
      <description>A Feature Disentangling Approach for Person Re-identification via Self-supervised Data Augmentation (Applied Soft Computing 2021) 开源代码传送门 概述 本文方法主要的两点改进： 通过打乱图像通道而非常用的 GAN，设计了一个自监督的数据增广方法，并</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Self-supervised Geometric Features Discovery (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn150/</link>
      <pubDate>Wed, 29 Dec 2021 15:30:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn150/</guid>
      <description>Self-supervised Geometric Features Discovery via Interpretable Attention for Vehicle Re-Identification and Beyond (ICCV 2021) 概述 本文提出一种新的架构来学习具有鉴别能力的几何特征 (geometric features)，其借助自监督学习和一个简单但是可解释的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] The Devil is in the Details for Vehicle ReID (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn149/</link>
      <pubDate>Wed, 29 Dec 2021 15:05:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn149/</guid>
      <description>The Devil is in the Details: Self-Supervised Attention for Vehicle Re-Identification (ECCV 2020) 概述 本文提出一种针对车辆 ReID 的自监督注意力 (SAVER)，自动关注车辆图像中的显著区域而无需额外的人工标注。 自监督残</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Self-Supervised Visual Representations for CMR (ICMR 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn148/</link>
      <pubDate>Wed, 29 Dec 2021 12:48:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn148/</guid>
      <description>Self-Supervised Visual Representations for Cross-Modal Retrieval (ICMR 2019) 概述 本文提出一种自监督的跨模态检索架构，利用图文之间的相关性作为监督信号，以学习能够有效迁移到其他 CV 任务上的视觉特征。 监督学</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Cross and Learn: Cross-Modal Self-Supervision (GCPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn147/</link>
      <pubDate>Wed, 29 Dec 2021 12:06:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn147/</guid>
      <description>Cross and Learn: Cross-Modal Self-Supervision (GCPR 2018) 开源代码传送门 概述 本文关注自监督学习任务，常用的流程是在一个需要语义理解的代理任务上预训练一个网络，本文利用跨模态信息作为监督</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Barlow Twins: SSL via Redundancy Reduction (ICML 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn146/</link>
      <pubDate>Tue, 28 Dec 2021 13:14:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn146/</guid>
      <description>Barlow Twins: Self-Supervised Learning via Redundancy Reduction (ICML 2021) 开源代码传送门 概述 自监督学习任务 (SSL)。 现有工作的一个共同目标是要学习在不同扰动之下依旧稳定的表征，一种典型做法是最大</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Feature Erasing and Diffusion Network for Occluded ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn145/</link>
      <pubDate>Tue, 28 Dec 2021 10:56:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn145/</guid>
      <description>2112.08740 Feature Erasing and Diffusion Network for Occluded Person Re-Identification (2021) 概述 现实场景下主要存在两种干扰： Non-Pedestrian Occlusion (NPO) Non-Target Pedestrian (NTP) 现有方法更多关注前者而忽略了后者，预训练的姿态估计与行人解析模型在含有多个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 视觉对话] RAN with Reinforced Generator for Visual Dialog (TOMM 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn144/</link>
      <pubDate>Mon, 27 Dec 2021 17:59:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn144/</guid>
      <description>Recurrent Attention Network with Reinforced Generator for Visual Dialog (TOMM 2020) 概述 视觉对话 (Visual Dialog) 任务，代理 (agent) 根据所提供的图像与对话历史，回答关于图像中视觉内容的一系列具有时序关系的自然语言问题。 两个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] FGITR via Discriminative Latent Space Learning (SPL 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn143/</link>
      <pubDate>Sun, 26 Dec 2021 15:06:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn143/</guid>
      <description>Fine-Grained Image-Text Retrieval via Discriminative Latent Space Learning (SPL 2021) 概述 本文关注细粒度图文检索，提出一种有鉴别力的潜在空间学习方法 (Discriminative Latent Space Learning, DLSL)。 图文编码 分别用 ResNet-50 和词袋模型编码图文数据</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] DBPS with Multi-Grained Matching Networks (Displays 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn142/</link>
      <pubDate>Sat, 25 Dec 2021 16:05:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn142/</guid>
      <description>Description-Based Person Search with Multi-Grained Matching Networks (Displays 2021) 概述 本文提出一种多粒度匹配架构 (multi-grained matching framework)。 全局粒度表征 ResNet-50 / BERT 细粒度表征 对行人图像使用 Graphonomy 方法进行 human parsin</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-Modal Knowledge Adaptation for LB Person Search (TIP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn141/</link>
      <pubDate>Sat, 25 Dec 2021 14:59:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn141/</guid>
      <description>Cross-Modal Knowledge Adaptation for Language-Based Person Search (TIP 2021) 概述 本文着眼于公共空间学习时不同模态间表征的不一致性。 文本可用于指导图像特征丰富其重要的新人细节通知避免图像独有信息的干扰</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TBPS via Multi-Granularity Embedding Learning (IJCAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn140/</link>
      <pubDate>Sat, 25 Dec 2021 14:15:45 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn140/</guid>
      <description>Text-based Person Search via Multi-Granularity Embedding Learning (IJCAI 2021) 概述 现有方法多存在嵌入模糊问题 (ambiguity embedding problem)。 本文提出一种多粒度嵌入学习模型 (multi-granularity embedding learning model, MGEL)，从粗到细表征行人，并</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Feature Disentangling for Occluded ReID (AAAI 2022)</title>
      <link>http://jonathanwayy.xyz/2021/prn139/</link>
      <pubDate>Fri, 24 Dec 2021 18:43:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn139/</guid>
      <description>Pose-guided Feature Disentangling for Occluded Person Re-identification Based on Transformer (AAAI 2022) 开源代码传送门 概述 本文试图在不涉及空间对齐的情况下结合额外的姿态信息与 Transformer，提出一种姿态指导的特征</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 去除 plt.savefig() 保存图像时的白边</title>
      <link>http://jonathanwayy.xyz/2021/ldp_plt_savefig_nowhite/</link>
      <pubDate>Wed, 22 Dec 2021 17:01:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_plt_savefig_nowhite/</guid>
      <description>在用 plt 保存图像时发现图像带有白边，查阅文档后解决了这一问题，在此记录一下。 将语句写成如下形式即可： plt.savefig(&amp;#39;xxx.png&amp;#39;, dpi=500, bbox_inches=&amp;#39;tight&amp;#39;, pad_inches=0.0) 其中将 pad_inches 参数置零即可去除白边，而将</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] PGGANet: Pose Guided Graph Attention Network for ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn138/</link>
      <pubDate>Mon, 20 Dec 2021 17:26:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn138/</guid>
      <description>2111.14411 PGGANet: Pose Guided Graph Attention Network for Person Re-identification (2021) 概述 现有方法多只是将姿态热图与特征图相乘得到局部关键点特征，但这种做法并非最佳选择： backbone 输出的全局特征高度抽象，各个像素</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Stronger Baseline for Person Re-Identification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn137/</link>
      <pubDate>Mon, 20 Dec 2021 16:40:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn137/</guid>
      <description>2112.01059 Stronger Baseline for Person Re-Identification (2021) 概述 由于训练数据较之于分类任务更加有限，ReID 有过高的过拟合风险，为了缓解这一问题主要有两种思路： 设计更加轻量级的网络结构，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Semantic-aligned Feature Representation for TBPS (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn136/</link>
      <pubDate>Mon, 20 Dec 2021 15:56:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn136/</guid>
      <description>2112.06714 Learning Semantic-aligned Feature Representation for Test-based Person Search (2021) 概述 本文提出一种语义对齐嵌入方法 (semantic-aligned embedding method)，自动实现细粒度特征的语义对齐，无需额外模型以及跨模态注意力。 方法 Modality-specific Feature</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- PyTorch 报错 Got 3 and 1 in dimension 1 的一种解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_got3and1/</link>
      <pubDate>Mon, 13 Dec 2021 17:34:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_got3and1/</guid>
      <description>问题描述 在 dataloader 相关部分出现如下报错： RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 1 in dimension 1 at /pytorch/aten/src/TH/generic/THTensorMath.c:3586 原因分析 RGB 图像中混有单通道的灰度图，导致堆叠时无法对齐。 解决办</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 报错 RuntimeError: ... is at version 2; expected version 1 ... 的一种解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_loss_grad/</link>
      <pubDate>Sun, 12 Dec 2021 17:35:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_loss_grad/</guid>
      <description>问题描述 模型训练时遇到如下报错： RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [50, 76, 512]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True). 一种解决办法 将原先的</description>
    </item>
    
    <item>
      <title>Latex 调整表格宽度与高度</title>
      <link>http://jonathanwayy.xyz/2021/latex_resizebox/</link>
      <pubDate>Thu, 09 Dec 2021 12:01:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_resizebox/</guid>
      <description>有时会遇到表格超出页面正常宽度的情况，可使用 \resizebox 命令进行调整。 \begin{table} \centering \resizebox{\columnwidth}{20mm}{ \begin{tabular}{l|ccc} \toprule Method &amp;amp; Top-1 &amp;amp; Top-5 &amp;amp; Top-10 \\ \midrule DSSL \small{$_{MM21}$} \tiny{\cite{dssl}} &amp;amp; 59.98 &amp;amp; 80.41 &amp;amp; \textbf{87.56} \\ \bottomrule \end{tabular}} \caption{xxxxxxxx.} \label{tab:example} \end{table} 注：命令加在 tabular 外一层，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 知识蒸馏 / 互学习] Deep Mutual Learning (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn135/</link>
      <pubDate>Tue, 07 Dec 2021 12:32:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn135/</guid>
      <description>Deep Mutual Learning (CVPR 2018) 开源代码传送门 1 开源代码传送门 2 概述 本文提出互学习 (mutual learning) 的概念，在若干个学生模型之间进行知识蒸馏。 深度互学习 定义 由两个网络分别计算得</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] GroupBERT: Enhanced TF with Efficient Grouped Structures (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn134/</link>
      <pubDate>Thu, 02 Dec 2021 21:15:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn134/</guid>
      <description>2106.05822 GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures (2021) 概述 本文对 Transformer 曾的结构进行了一些改进： 增加一个卷积模块作为自注意力模块的补充，分解局部与全局关系的学习 引入 grouped transformeation 以降低前馈层</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] MetaFormer is Actually What You Need for Vision (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn133/</link>
      <pubDate>Thu, 02 Dec 2021 20:43:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn133/</guid>
      <description>2111.11418 MetaFormer is Actually What You Need for Vision (2021) 开源代码传送门 概述 Transformer 中的编码器包含两部分，其一是注意力模块，用于混合 token 之间的信息，本文称之为 token mixer；其二是其余的模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Learning LocFeat with Multiple Dynamic Attention (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn132/</link>
      <pubDate>Wed, 01 Dec 2021 10:57:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn132/</guid>
      <description>Learning Deep Local Features With Multiple Dynamic Attentions for Large-Scale Image Retrieval (ICCV 2021) 开源代码传送门 概述 由于图像内容的多样性，只提取一张注意力图难以有效捕捉所有潜在的语义模式。 本文提出一个新架构，使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning To Know Where To See for Occluded ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn131/</link>
      <pubDate>Tue, 30 Nov 2021 11:50:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn131/</guid>
      <description>Learning To Know Where To See: A Visibility-Aware Approach for Occluded Person Re-Identification (ICCV 2021) 概述 随着姿态估计粒度的细化，其预测误差随之上升。 本文试图找到一种策略，能在不过分依赖姿态信息的情况下处理遮挡问</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 对抗攻击] Multi-Expert AAD Using Context Inconsistency (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn130/</link>
      <pubDate>Mon, 29 Nov 2021 13:39:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn130/</guid>
      <description>Multi-Expert Adversarial Attack Detection in Person Re-Identification Using Context Inconsistency (ICCV 2021) 概述 ReID 属于排序问题而非分类问题，因而现有针对分类问题的防御方法并不适合 ReID 任务。 本文提出多专家对抗攻击检测方法 (Multi-Expert Adversarial Attack Detection,</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Syncretic Modality Collaborative Learning for VI-ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn129/</link>
      <pubDate>Mon, 29 Nov 2021 11:06:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn129/</guid>
      <description>Syncretic Modality Collaborative Learning for Visible Infrared Person Re-Identification (ICCV 2021) 概述 现有借助第三模态方法的缺陷 由可视图像生成，导致新模态和可视模态高度相关，但和红外模态不相关 可视图像与红外图像的特征</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Feature Alignment for Occluded ReID (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn128/</link>
      <pubDate>Sun, 28 Nov 2021 19:56:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn128/</guid>
      <description>Pose-Guided Feature Alignment for Occluded Person Re-Identification (ICCV 2019) 概述 本文最早提出了 Occluded ReID 任务，并构建了 Occluded-DukeMTMC 数据集，query 图像全部带遮挡，而 gallery 图像有完整与遮挡两种情况。 Partial ReID 与 Occluded ReID 问题的对比</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning to Disentangle Scenes for ReID (Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn127/</link>
      <pubDate>Sat, 27 Nov 2021 13:37:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn127/</guid>
      <description>2111.05476 Learning to Disentangle Scenes for Person Re-identification (Neurocomputing 2021) 概述 为了有效分解复杂场景，本文提出一种分治策略 (divide-and-conquer strategy)，主要分析了两种情况： 遮挡 (occlusion) 尺度变化 (scale variation) 对输入的图像采</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Matching on Sets: Conquer OcReID Without Alignment (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn126/</link>
      <pubDate>Fri, 26 Nov 2021 16:19:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn126/</guid>
      <description>Matching on Sets: Conquer Occluded Person Re-Identification Without Alignment (AAAI 2021) 概述 本文提出一种在集合上匹配 (Matching on Sets, MoS) 的方法，从而避免复杂而又容易出错的空间对齐过程。 考虑到卷积特征通道通常会编码视觉模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] View Confusion Feature Learning for Person ReID  (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn125/</link>
      <pubDate>Fri, 26 Nov 2021 15:23:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn125/</guid>
      <description>View Confusion Feature Learning for Person Re-identification (ICCV 2019) 概述 本文提出一种视角混淆特征学习模型 (View Confusion Feature Learning, VCFL)，通过结合 view-generic 与 view-specific 模型学习 view-invariant 的特征。 从三个层面实现视角混淆： 基于分类器</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CMReID via Modality Confusion and Center Aggregation(ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn124/</link>
      <pubDate>Fri, 26 Nov 2021 13:08:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn124/</guid>
      <description>Cross-Modality Person Re-Identification via Modality Confusion and Center Aggregation (ICCV 2021) 概述 本文提出一种端到端的模态混淆学习网络 (Modality Confusion Learning network, MCLNet)，其核心想法在于混淆特征学习过程中的模态鉴别，使得优化显</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] SphereReID: Deep Hypersphere Manifold Embedding for ReID (2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn123/</link>
      <pubDate>Thu, 25 Nov 2021 10:10:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn123/</guid>
      <description>SphereReID: Deep Hypersphere Manifold Embedding for Person Re-identification (2019) 开源代码传送门 概述 本文提出一种 metric-based 的架构，称为 SphereReID，引入一个新的损失函数 Sphere Loss。 Softmax Loss $$L_{softmax} = -\frac{1}{N} \sum_{i= 1}^{N} log \frac{e^{z_{y_{i}}}}{\sum_{j=1}^C e^{e^{z_{j}}}},$$ $$z_{j} =</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] GreyReID: Two-stream Framework with RGB-grey Information (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn122/</link>
      <pubDate>Wed, 24 Nov 2021 12:41:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn122/</guid>
      <description>GreyReID: A Novel Two-stream Deep Framework with RGB-grey Information for Person Re-identification (TOMM 2021) 概述 着重关注不同行人之间色彩信息相似的问题，本文称之为 ReID 的色彩过拟合 (color over-fitting)。 RGB 图像与灰度图</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 频域] HLFNet: High-low Frequency Network for Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn121/</link>
      <pubDate>Tue, 23 Nov 2021 14:29:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn121/</guid>
      <description>HLFNet: High-low Frequency Network for Person Re-Identification (IEEE Signal Processing Letters 2021) 概述 本文提出一种高低频网络 (high-low frequency network, HLFNet)。 Frequency Splitting Module (FSM) 利用 guide filter 将原始图像分为高低频图像： $$I_{l} = \mathcal{G}(I_{o}),$$ $$I_{h} = I_{o} / (I_{l} + eps).$$ 将得到</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Occlude Them All: Occlusion-Aware Attention Network (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn120/</link>
      <pubDate>Mon, 22 Nov 2021 15:13:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn120/</guid>
      <description>Occlude Them All: Occlusion-Aware Attention Network for Occluded Person Re-ID (ICCV 2021) 概述 将遮挡按如下分类 4 locations: top, bottom, left, right 2 areas: half, quarter 本文提出一种遮挡可知的掩码网络 (Occlusion-Aware Mask Network, OAMN)，包含三个主要部件： attention-guided mask module occlusion augmentation</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Occluded ReID With Single-Scale Global Representation (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn119/</link>
      <pubDate>Sat, 20 Nov 2021 17:40:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn119/</guid>
      <description>Occluded Person Re-Identification With Single-Scale Global Representations (ICCV 2021) 数据集传送门（尚未更新） 概述 本文提出一种新的 ReID 模型，学习单尺度全局级别的行人表征 (single-scale global-level pedestrian representations)。 构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Weakly Supervised Text-Based Person Re-Identification (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn118/</link>
      <pubDate>Fri, 19 Nov 2021 16:42:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn118/</guid>
      <description>Weakly Supervised Text-Based Person Re-Identification (ICCV 2021) 开源代码传送门 概述 本文提出弱监督图文 ReID，即在训练阶段没有 ID 标注。 新任务的两个困难 各模态内由于类内差异造成的影响难以处理 跨</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CM-NAS for Visible-Infrared Person Re-Identification (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn117/</link>
      <pubDate>Thu, 18 Nov 2021 09:42:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn117/</guid>
      <description>CM-NAS: Cross-Modality Neural Architecture Search for Visible-Infrared Person Re-Identification (ICCV 2021) 开源代码传送门 概述 Visible-Infrared ReID 任务。 现有工作多是设计一个 two-stream 架构，因而就产生了一个问题：哪些层应当被分为两个分支，哪些层应该共享</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] BV-Person: A Large-Scale Dataset for Bird-View ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn116/</link>
      <pubDate>Wed, 17 Nov 2021 20:40:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn116/</guid>
      <description>BV-Person: A Large-Scale Dataset for Bird-View Person Re-Identification (ICCV 2021) 数据集与开源代码传送门 概述 本文提出一种新的 ReID 任务，即鸟瞰视角下的 ReID，并制作了一个大规模数据集，称为 BV-Perso</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] LapsCore: Language-Guided Search via Color Reasoning (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn115/</link>
      <pubDate>Mon, 15 Nov 2021 11:06:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn115/</guid>
      <description>LapsCore: Language-Guided Person Search via Color Reasoning (ICCV 2021) 概述 现有方法隐式地学习跨模态局部关联。 颜色在检索中至关重要。 本文提出一种基于颜色推理的新方法，称为 LapsCore，通过解</description>
    </item>
    
    <item>
      <title>Latex 表格中绘制经过指定列的水平线</title>
      <link>http://jonathanwayy.xyz/2021/latex_cline/</link>
      <pubDate>Sat, 13 Nov 2021 14:47:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_cline/</guid>
      <description>在用 Latex 绘制表格的过程中，有时需要绘制不完全贯穿整行的水平线，可用如下命令指定需要贯穿的列： \cline{起始列-终止列} 此命令中列从 1 开始排</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Escaping the Big Data Paradigm with Compact Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn114/</link>
      <pubDate>Thu, 11 Nov 2021 20:39:25 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn114/</guid>
      <description>2104.05704 Escaping the Big Data Paradigm with Compact Transformers (2021) 开源代码传送门 概述 针对 Transformer 模型的数据饥饿 (data hungry) 传统观点，尝试弥合 Transformer 和 CNN 两种架构之间的鸿沟，结合二者优势，使得基于 Transformer 的模型能够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Structured MM Feature Embedding and Alignment (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn113/</link>
      <pubDate>Wed, 10 Nov 2021 19:27:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn113/</guid>
      <description>Structured Multi-modal Feature Embedding and Alignment for Image-Sentence Retrieval (MM 2021) 概述 现有细粒度方法的问题 忽略了模态内的上下文语义以及部件之间的结构化关系，导致无法有效捕获语义 以多对多匹配范式隐式建模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Joint Generative and Contrastive Learning for UnS. ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn112/</link>
      <pubDate>Tue, 09 Nov 2021 09:03:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn112/</guid>
      <description>Joint Generative and Contrastive Learning for Unsupervised Person Re-identification (CVPR 2021) 开源代码传送门 概述 自监督对比学习方法 对于一张图像，最大化其两个增广视角之间的共识 (agreement between two augmented views)，视角指的是对于某</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Query-Adaptive Convolution and Temporal Lifting (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn111/</link>
      <pubDate>Mon, 08 Nov 2021 12:14:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn111/</guid>
      <description>Interpretable and Generalizable Person Re-Identification with Query-Adaptive Convolution and Temporal Lifting (ECCV 2020) 开源代码传送门 概述 现有的许多 ReID 方法只是在两个表征向量之间简单计算距离，而无视了两张图像真实内容之间的直接关系。 本文</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Knowledge-SV Learning: Knowledge Consensus Constraints (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn110/</link>
      <pubDate>Thu, 04 Nov 2021 11:07:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn110/</guid>
      <description>Knowledge-Supervised Learning: Knowledge Consensus Constraints for Person Re-Identification (MM 2021) 概述 本文旨在利用知识在不引入额外推断成本的基础上，约束同一数据上的多视角共识以提升精度。 行人 ReID 相较于图像分类的特殊性 检索</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] MCCN: Multimodal Coordinated Clustering Network (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn109/</link>
      <pubDate>Tue, 02 Nov 2021 19:54:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn109/</guid>
      <description>MCCN: Multimodal Coordinated Clustering Network for Large-Scale Cross-modal Retrieval (MM 2021) 概述 本文关注大规模多个模态应用场景下的模态不平衡的跨模态检索问题，提出一种多模态协同的聚类网络 (Multimodal Coordinated Clustering Network, MCCN)。 MCCN 包</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Inter- and Intra-part Relational Transformer (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn108/</link>
      <pubDate>Sun, 31 Oct 2021 17:14:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn108/</guid>
      <description>Pose-guided Inter- and Intra-part Relational Transformer for Occluded Person Re-Identification (MM 2021) 开源代码传送门 概述 本文提出一种姿态指导的部件内间关系 Transformer。 姿态指导的特征提取 $$M = GMP(\hat{M}),$$ $$c_{g} = max(M_{g}),$$ $$F_{pose} = GAP((M &amp;gt; \tau)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 数据增强] Cut-Thumbnail: A Novel Data Augmentation for CNN (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn107/</link>
      <pubDate>Fri, 29 Oct 2021 14:34:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn107/</guid>
      <description>Cut-Thumbnail: A Novel Data Augmentation for Convolutional Neural Network (MM 2021) 开源代码传送门 概述 现有的数据增强方法通过改变空间或色彩信息、增加噪音或混合来自不同图像的信息，来提高网络的泛化能力和鲁</description>
    </item>
    
    <item>
      <title>Latex 旋转文字方向</title>
      <link>http://jonathanwayy.xyz/2021/latex_rotatebox/</link>
      <pubDate>Thu, 28 Oct 2021 12:34:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_rotatebox/</guid>
      <description>有时在 Latex 表格中需要改变文字方向，可以用如下语句实现： \rotatebox{角度}{文本}</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Feature Learning with KD for Occluded ReID (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn106/</link>
      <pubDate>Tue, 26 Oct 2021 22:45:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn106/</guid>
      <description>Pose-Guided Feature Learning with Knowledge Distillation for Occluded Person Re-Identification (MM 2021) 概述 本文提出一种通过知识蒸馏进行基于姿态指导的特征学习架构 (Pose-Guided Feature Learning with Knowledge Distillation network, PGFL-KD) 架构，姿态信息用于约束全局特征的学习而在测</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TBPS in Full Images via Semantic-Driven Proposal Generation (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn105/</link>
      <pubDate>Fri, 15 Oct 2021 16:42:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn105/</guid>
      <description>2109.12965 Text-based Person Search in Full Images via Semantic-Driven Proposal Generation 概述 提出在完整图像中进行行人检索的任务，可视为 Person Detection 和 Text-based Person Retrieval 的结合。 本文提出 Semantic-Driven Region Proposal Net (SDPRN)。 构建了两个新数据集 CUHK-SYSU-TBPS</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 报错 RuntimeError: CUDA error: invalid device ordinal 解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_invalid_device_ordinal/</link>
      <pubDate>Wed, 13 Oct 2021 23:06:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_invalid_device_ordinal/</guid>
      <description>问题描述 在涉及 to(device) 操作时出现如下报错： RuntimeError: CUDA error: invalid device ordinal 解决办法 在该操作前指定可选的 GPU 卡： import os os.environ[&amp;#39;CUDA_VISIBLE_DEVICES&amp;#39;] = &amp;#34;0,1,2,3,4,5,6,7&amp;#34;</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch 取矩阵对角线元素</title>
      <link>http://jonathanwayy.xyz/2021/ldp_pytorch_diag/</link>
      <pubDate>Tue, 12 Oct 2021 19:13:06 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_pytorch_diag/</guid>
      <description>在 Pytorch 中，可以用 torch.diag 取矩阵的对角线元素，返回的是一个向量；使用 torch.diag_embed 可将向量变换为以该向量为对角线的方阵。 In [1]: import torch In [2]: A = torch.randn(3, 3) In [3]: A Out[3]: tensor([[ 0.1808, 0.2905, -2.2199], [-0.8913, 1.1296, 0.6261],</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 读取 pkl 文件报错 ValueError: unsupported pickle protocol: 5 解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_pickle_protocol_5/</link>
      <pubDate>Sun, 26 Sep 2021 21:00:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_pickle_protocol_5/</guid>
      <description>问题描述 使用 Python 读取 .pkl 文件时报错如下： ValueError: unsupported pickle protocol: 5 原因分析 Python 3.8 以上版本在保存 .pkl 文件时使用的协议号为 5，即 protocol 关键字为 5，若在读取时使用低于 3.8 版本的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像分解] Blind Image Decomposition (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn104/</link>
      <pubDate>Sun, 26 Sep 2021 17:07:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn104/</guid>
      <description>2108.11364 Blind Image Decomposition (2021) 开源代码传送门 概述 本文提出提出盲图像分解 (Blind Image Decomposition, BID) 任务，并设计了 Blind Image Decomposition Network (BIDeN)。 BID 的特点 不固定源部件数目，只设定一个潜在源部</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Posterior and Prior for Uncertainty Modeling in ReID(2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn103/</link>
      <pubDate>Sat, 25 Sep 2021 15:30:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn103/</guid>
      <description>2007.08785 Learning Posterior and Prior for Uncertainty Modeling in Person Re-Identification (2020) 概述 本文在 ReID 任务中同时学习样本后验与类别先验，以量化输入图像及其相应类别的不确定性。 整体架构 上分支用 GAP 处理特征图得到</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Person Search Challenges and Solutions: A Survey (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn102/</link>
      <pubDate>Fri, 24 Sep 2021 22:10:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn102/</guid>
      <description>2105.01605v1 Person Search Challenges and Solutions: A Survey (2021) 概述 关于 Image-based Person Search 与 Text-based Person Search 的综述。 本文与现有综述的差异 Detection-identification Inconsistency Problem Person Search 研究进展时间线 三个主要挑战 从场景图像学习具有足够鉴别能力的行人</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 人机交互 / 跨模态检索] Interactive Natural Language Person Search (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn101/</link>
      <pubDate>Fri, 24 Sep 2021 19:53:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn101/</guid>
      <description>2002.08434v1 Interactive Natural Language-based Person Search (2020) CUHK-QA 数据集传送门 概述 可以认为本文是换了一种说法，把 Text-based Person Search 称为 Zero-shot re-ID。 将 language-based re-ID 视为一种 VQA 任务，输入为图文对，输出为二值化答案。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 风格迁移] Style Transfer with Adaptive Instance Normalization (ICCV 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn100/</link>
      <pubDate>Thu, 23 Sep 2021 16:48:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn100/</guid>
      <description>Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization (ICCV 2017) 概述 本文基于 instance normalization (IN) 提出 adaptive instance normalization (AdaIN)，解决风格迁移任务中的灵活性-速度困境。 Adaptive Instance Normalization (AdaIN) $$AdaIN(x, y) = \sigma (y) (\frac{x - \mu (x)}{\sigma (x)}) + \mu (y).$$ 风</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像标注] Unsupervised Image Captioning (CVPR 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn99/</link>
      <pubDate>Wed, 22 Sep 2021 13:14:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn99/</guid>
      <description>Unsupervised Image Captioning (CVPR 2019) 开源代码传送门 概述 无监督图像标注任务，即不使用任何标记好的图文对来训练图像标注模型。 三个目标 用文本对抗生成方法，在句子语料上训练一</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- PyTorch 出现 NotImplementedError 报错的一种可能情况</title>
      <link>http://jonathanwayy.xyz/2021/ldp_torch_notimplementederror/</link>
      <pubDate>Tue, 21 Sep 2021 23:36:45 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_torch_notimplementederror/</guid>
      <description>问题描述 PyTorch 一使用网络进行计算即出现如下报错： raise NotImplementedErrorh 问题原因 经过反复的调试和检查后，发现是 forward 函数的问题，网络模型类中的 def forward 一行多缩进了一个 Tab 位，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] SDMCH: Supervised Discrete Manifold-Embeded (IJCAI 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn98/</link>
      <pubDate>Thu, 16 Sep 2021 15:23:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn98/</guid>
      <description>SDMCH: Supervised Discrete Manifold-Embedded Cross-Modal Hashing (IJCAI 2018) 概述 本文提出离散流形嵌入跨模态哈希方法 (Discrete Manifold-Embedded Cross-Modal Hashing, SDMCH)。 既挖掘数据的非线性流形结构，也在多模态之间构建相关性。 流形结构学</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Semantically Self-Aligned Network for T2I Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn97/</link>
      <pubDate>Mon, 13 Sep 2021 13:18:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn97/</guid>
      <description>2107.12666v2 Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification (2021) 开源代码传送门 概述 自然语言描述的自由形式带来的两个问题 同一张图像对应的描述可能非常不同 对于身体部件的描述可能以任意顺序呈</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Windows 环境下 Python 2 可用的一个 Tensorflow 轮子</title>
      <link>http://jonathanwayy.xyz/2021/ldp_py2_win_tf/</link>
      <pubDate>Sun, 12 Sep 2021 20:39:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_py2_win_tf/</guid>
      <description>Tensorflow 在 Windows 环境下不支持 Python 2，但是最近需要在一台 Windows 系统的工作站上给基于 Python 2.7 的虚拟环境配置 Tensorflow。 记录一下找到的一个可用的轮子： https://github.com/fo40225/tensorflow-windows-wheel 下载</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 2 安装 grpcio 的一个可用版本</title>
      <link>http://jonathanwayy.xyz/2021/ldp_py2_grpcio/</link>
      <pubDate>Sun, 12 Sep 2021 20:25:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_py2_grpcio/</guid>
      <description>在一台 Windows 工作站上需要配置一个基于 Python 2.7 的 TF 虚拟环境，安装一个依赖包 grpcio 时遇到了问题。 分析以后应该是由于新版本的 grpcio 不支持 Python 2.7 了，直接用 pip 安装不行，</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Windows 下使用 pip 安装 opendr</title>
      <link>http://jonathanwayy.xyz/2021/ldp_win_opendr/</link>
      <pubDate>Sun, 12 Sep 2021 15:35:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_win_opendr/</guid>
      <description>问题描述 直接使用 pip install opendr 会报一个 failed with exit code 1181 的错误。 解决办法 首先安装 glfw，是 opengl 的一个框架： pip install glfw 在这里下载 opendr 后构建并安装： &amp;gt; git clone https://github.com/polmorenoc/opendr.git &amp;gt; cd ./opendr/opendr &amp;gt; python</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 2 安装 opencv-python 包出错解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_python2_opencv/</link>
      <pubDate>Sat, 11 Sep 2021 21:46:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_python2_opencv/</guid>
      <description>问题描述 在为使用 Python 2.7 的虚拟环境使用如下命令安装 OpenCV 时 pip2 install opencv-python 出现了如下报错： TypeError: &amp;#39;NoneType&amp;#39; object is not iterable 原因分析 出现这种情况是因为最新版的 OpenCV 不再支持 Python 2.7，而</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parameter-Efficient Person Re-identification in the 3D Space (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn96/</link>
      <pubDate>Sat, 11 Sep 2021 14:44:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn96/</guid>
      <description>2006.04569 Parameter-Efficient Person Re-identification in the 3D Space (2020) 开源代码传送门 概述 考察 2D 行人外观与 3D 几何结构之间的互补信息。 本文提出 Omni-scale Graph Network (OG-Net)，在 3D 空间中进行 ReID。 模型架</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] PCNET: Parallelly Conquer Large Variance of Person ReId (ICIP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn95/</link>
      <pubDate>Fri, 10 Sep 2021 13:22:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn95/</guid>
      <description>PCNET: Parallelly Conquer the Large Variance of Person Re-Identification (ICIP 2021) 概述 本文提出 Parallelly Conquer Net (PCNet)，主要包含三个部件： Pose Adaptation Module (PAM) Global Alignment Module (GAM) Pixel-Wised Attention Module (PWAM) 用模块聚合单元 (Module Aggregation Unit) 整合各个子模块生成的特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 3D 跨模态检索] Cross-Modal Center Loss for 3D CM Retrieval (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn94/</link>
      <pubDate>Thu, 09 Sep 2021 22:52:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn94/</guid>
      <description>Cross-Modal Center Loss for 3D Cross-Modal Retrieval (CVPR 2021) 概述 现有方法的问题 核心想法是最小化由预训练模型提取的特征之间的跨模态差异，预训练模型没有参与训练或进行微调 现有的损失函数主</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Modality-Specific and Shared GAN (PR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn93/</link>
      <pubDate>Thu, 09 Sep 2021 21:42:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn93/</guid>
      <description>Modality-Specific and Shared Generative Adversarial Network for Cross-modal Retrieval (PR 2020) 概述 本文提出 Modality-Specific and Shared Generative Adversarial Network (\(MS^2GAN\))。 生成模型 标签预测 将模态中特征与公共空间特征拼接后用于预测标签，采用</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Aggregation-based Graph Convolutional Hashing (TMM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn92/</link>
      <pubDate>Thu, 09 Sep 2021 13:11:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn92/</guid>
      <description>Aggregation-based Graph Convolutional Hashing for Unsupervised Cross-modal Retrieval (TMM 2021) 概述 本文提出基于聚合的图卷积哈希方法 (Aggregation-based Graph Convolutional Hashing, AGCH)。 模型架构 主要部件 图像编码器 + 图像 GCN 文本编码器 + 文本 GCN 融合模块 生成</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Learning Sufficient Scene Representation(Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn91/</link>
      <pubDate>Wed, 08 Sep 2021 19:36:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn91/</guid>
      <description>Learning Sufficient Scene Representation for Unsupervised Cross-modal Retrieval (Neurocomputing 2021) 背景 此前有工作从统计层面证明分析了跨模态检索的过程，借助变分推断证明了不可能同时最大化模态内与模态间相似度，二者会互相约</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Unsupervised Cross-modal Retrieval through AL (ICME 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn90/</link>
      <pubDate>Tue, 07 Sep 2021 14:45:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn90/</guid>
      <description>Unsupervised Cross-modal Retrieval through Adversarial Learning (ICME 2017) 概述 本文提出基于对抗学习的无监督跨模态检索 (Unsupervised Cross-modal Retrieval with Adversarial, UCAL)。 包含四个部分： 图像特征映射 文本特征映射 模态分类器，生成二元特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Contextual Transformer Networks for Visual Recognition (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn89/</link>
      <pubDate>Thu, 02 Sep 2021 21:44:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn89/</guid>
      <description>2107.12292 Contextual Transformer Networks for Visual Recognition (CVPRW 2021) 开源代码传送门 概述 现有 ViT 方法的问题 只是基于各位置上孤立的 key 和 query 求得注意力矩阵，忽略了相邻 key 之间丰富的上下文信息。 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Attention-Guided Semantic Hashing (ICME 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn88/</link>
      <pubDate>Thu, 02 Sep 2021 12:29:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn88/</guid>
      <description>Attention-Guided Semantic Hashing for Unsupervised Cross-Modal Retrieval (ICME 2021) 概述 无监督跨模态哈希问题。 本文提出注意力指导的语义哈希模型 (Attention-Guided Semantic Hashing)。 模型架构 特征提取 VGG-16 提取图像特征，unive</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Learning Omni-frequency Region-adaptive Representations (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn87/</link>
      <pubDate>Mon, 30 Aug 2021 11:13:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn87/</guid>
      <description>Learning Omni-frequency Region-adaptive Representations for Real Image Super-Resolution (AAAI 2021) 概述 本文提出 Omni-frequency Region-adaptive Network (ORNet) 解决真实图像超分问题。 模型架构 频率分解模块 (Frequency Decomposition Module, FD) FD 模块由两个阶段组成： 频率分解阶段 频率增强阶段 频率</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learn 3D Shape Feature for Texture-insensitive Person ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn86/</link>
      <pubDate>Sun, 29 Aug 2021 14:30:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn86/</guid>
      <description>Learning 3D Shape Feature for Texture-insensitive Person Re-identification (CVPR 2021) 开源代码传送门 背景 Person ReID 任务。 研究表明 Person ReID 相当依赖衣着外观纹理 (clothing appearance textures)，大多数现有方法在衣着纹理较迷惑时表现</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Frequency Separation for Real-World Super-Resolution (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn85/</link>
      <pubDate>Fri, 27 Aug 2021 13:40:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn85/</guid>
      <description>1911.07850 Frequency Separation for Real-World Super-Resolution (ICCVW 2019) 开源代码传送门 速览 速读一篇文献，主要关注一下频域相关的处理。 下采样操作去除了高频信息而保留低频信息。 因而本文对高低频信息进行</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Focal Frequency Loss for Image Reconstruction (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn84/</link>
      <pubDate>Thu, 26 Aug 2021 20:50:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn84/</guid>
      <description>2012.12821 Focal Frequency Loss for Image Reconstruction and Synthesis (ICCV 2021) 开源代码传送门 项目主页传送门 背景 Image Reconstruction And Synthesis 任务。 本文提出一种 Focal Frequency Loss，直接在频域中优化生成模型。 Focal Frequency Loss 由 2D DFT 的公式表</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] HAL: Mitigating Visual Semantic Hubs (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn83/</link>
      <pubDate>Thu, 26 Aug 2021 12:55:43 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn83/</guid>
      <description>HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs (AAAI 2020) 背景 本文主要针对图文匹配任务中的枢纽点问题 (Hubness Problem) 进行研究。 由于图文匹配中的嵌入空间是由联合建模视觉和语言得到的，通常将其</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 枢纽点问题 (Hubness Problem)</title>
      <link>http://jonathanwayy.xyz/2021/ldp_hubness_problem/</link>
      <pubDate>Wed, 25 Aug 2021 18:08:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_hubness_problem/</guid>
      <description>当特征嵌入空间是一个高维空间时，容易出现枢纽点问题 (Hubness Problem)。 问题定义 在高维空间中，一部分测试集的类别可能会成为很多数据点的 K 近邻 (</description>
    </item>
    
    <item>
      <title>Latex 使用 longtable 实现多页显示长表格</title>
      <link>http://jonathanwayy.xyz/2021/latex_longtable/</link>
      <pubDate>Wed, 25 Aug 2021 12:41:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_longtable/</guid>
      <description>在使用 Latex 写论文时，有时会出现表格过长超出一页的情况，可以通过 longtable 包实现表格的多页显示。 首先引入宏包 \usepackage{longtable} 使用 longtable 首先删去 \begin{table} 和 \end{table}，</description>
    </item>
    
    <item>
      <title>编译 Latex 遇到 File ended while scanning use of 
ewlbel 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/latex_newlbel/</link>
      <pubDate>Wed, 25 Aug 2021 12:23:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_newlbel/</guid>
      <description>问题描述 编译 Latex 时出现如下报错： File ended while scanning use of \@newl@bel... 解决办法 将目录中除了 .tex 文件以及图像、参考文献等文件其外的其余文件均删除后重新编译即可。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Step-Wise Hierarchical Alignment Network (IJCAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn82/</link>
      <pubDate>Mon, 23 Aug 2021 14:43:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn82/</guid>
      <description>Step-Wise Hierarchical Alignment Network for Image-Text Matching (IJCAI 2021) 背景 现有方法的问题 根据明显差异来鉴别图文对，可能会因而无法区分具有微小上下文信息差异但是语义内容相似的样本。 本文提出一种逐</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Probabilistic Embeddings for Cross-Modal Retrieval (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn81/</link>
      <pubDate>Thu, 19 Aug 2021 11:43:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn81/</guid>
      <description>Probabilistic Embeddings for Cross-Modal Retrieval (CVPR 2021) 开源代码传送门 背景 一张图像可能与多条不同的文本相匹配，一条文本也可能对应多张不同的图像。 本文提出一种概率跨模态嵌入模型 (Probabilistic Cross-Modal Embedding, P</description>
    </item>
    
    <item>
      <title>Latex 表格使用 toprule、midrule 及 bottomrule 时出现 undefined control sequence 报错解决方案</title>
      <link>http://jonathanwayy.xyz/2021/latex_booktabs/</link>
      <pubDate>Tue, 17 Aug 2021 20:24:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_booktabs/</guid>
      <description>问题描述 在 Latex 表格中，使用 \toprule、\midrule 以及 \bottomrule 时报错 “undefined control sequence”。 解决办法 缺少相应宏包，导入即</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图网络 / Ad-hoc 检索] A Graph-based Relevance Matching Model (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn80/</link>
      <pubDate>Tue, 17 Aug 2021 15:53:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn80/</guid>
      <description>2101.11873 A Graph-based Relevance Matching Model for Ad-hoc Retrieval (AAAI 2021) 背景 query-document 检索任务。 两类架构 representation-based matching interaction-based matching 两种重要关系 term-level query-document interaction document-level word relationships 一个问题 用来检索的短语可能并不连续出现在文档中，可能相隔甚远。</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- PyTorch 特征傅利叶变换幅度相位分离与重建</title>
      <link>http://jonathanwayy.xyz/2021/fft-ap/</link>
      <pubDate>Mon, 16 Aug 2021 17:57:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/fft-ap/</guid>
      <description>简单记录一下如何使用 PyTorch 对做过傅利叶变换后的特征进行幅度与相位的分离与重建。 In [1]: import torch In [2]: import numpy as np # 生成一个张量作为特征 In [3]: feat = torch.rand((3,10)) In [4]: feat Out[4]: tensor([[3.7899e-01, 2.9198e-01, 6.4575e-01,</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] FDA: Fourier Domain Adaptation (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn79/</link>
      <pubDate>Mon, 16 Aug 2021 16:19:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn79/</guid>
      <description>FDA: Fourier Domain Adaptation for Semantic Segmentation (CVPR 2020) 开源代码传送门 概述 提出傅里叶域自适应 (FDA)。 FFT ==&amp;gt; 用目标图像的低频成分替换源图像低频成分 ==&amp;gt; iFFT FDA 设计了一个外圈置零的掩码：</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Phase Consistent Ecological Domain Adaptation (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn78/</link>
      <pubDate>Sun, 15 Aug 2021 12:28:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn78/</guid>
      <description>Phase Consistent Ecological Domain Adaptation (CVPR 2020) 开源代码传送门 概述 无监督域适应 (Unsupervised Domain Adaptation, UDA) 任务。 通常的 UDA 方法 学习一个从源分布到目标分布的映射 训练一个对域变化不敏感的骨架网络 本文引</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] CAT: Cross Attention in Vision Transformer (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn77/</link>
      <pubDate>Thu, 12 Aug 2021 16:00:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn77/</guid>
      <description>2106.05786 CAT: Cross Attention in Vision Transformer (2021) 开源代码传送门 核心 设计了一种在单通道特征图上做注意力的方法，提出交叉注意力。 结合 Transformer 和 CNN 的优点构建 CAT。 Patch 内自注意力块 (IPSA) 与 Patch</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图网络] Graph Reasoning Networks on a Similarity Pyramid (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn76/</link>
      <pubDate>Wed, 11 Aug 2021 15:46:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn76/</guid>
      <description>Fashion Retrieval via Graph Reasoning Networks on a Similarity Pyramid (ICCV 2019) 概述 Fashion Retrieval 任务。 一个问题在于对应位置的局部块通常是失配的，因此需要在同尺度所有局部之间遍历匹配。 设计了一种基于相似度金</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Attention in Attention Network for Image Super-Resolution (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn75/</link>
      <pubDate>Tue, 10 Aug 2021 11:12:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn75/</guid>
      <description>2104.09497 Attention in Attention Network for Image Super-Resolution (2021) 开源代码传送门 概览 图像超分任务。 提出一种 attention in attention 块 (\(A^2B\))，并设计了 \(A^2N\) 架构。 出发点 两个问题 图像的哪一部分倾向于有</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] CCNet: Criss-Cross Attention (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn74/</link>
      <pubDate>Mon, 09 Aug 2021 12:11:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn74/</guid>
      <description>CCNet: Criss-Cross Attention for Semantic Segmentation (ICCV 2019) 开源代码传送门 概述 提出十字注意力 (Criss-Cross Attention)，将参数量从非局部注意力的 \(H \times W\) 减少到了 \(H + W -1\)。 为了捕捉全图依</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Learning Joint Embedding of Food Images and Recipes (TMM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn73/</link>
      <pubDate>Sun, 08 Aug 2021 20:31:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn73/</guid>
      <description>Cross-Modal Food Retrieval: Learning a Joint Embedding of Food Images and Recipes with Semantic Consistency and Attention Mechanism (TMM 2021) 核心 相同食物的数据表征可能不同，而不同食物的数据表征可能相似，从而导致食物数据有较大的类内方差与较小</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Attentional Feature Fusion (WACV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn72/</link>
      <pubDate>Fri, 06 Aug 2021 14:50:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn72/</guid>
      <description>2009.14082 Attentional Feature Fusion (WACV 2021) 开源代码传送门 概述 本文研究特征融合 (feature fusion)，提出注意力特征融合模块 (attentional feature fusion module, AFF)。 为了缓解由于尺度变化以及小目标引起的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Context-Aware Attention Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn71/</link>
      <pubDate>Wed, 04 Aug 2021 19:43:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn71/</guid>
      <description>Context-Aware Attention Network for Image-Text Retrieval (CVPR 2020) 背景 现有方法的问题 不同的局部块有不同重要性 忽略同模态中各局部之间的语义相关性 一个单词或一个图像区域在不同的全局上下文中可能有</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Transformer in Convolutional Neural Networks (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn70/</link>
      <pubDate>Tue, 03 Aug 2021 12:09:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn70/</guid>
      <description>2106.03180 Transformer in Convolutional Neural Networks (2021) 开源代码传送门 概览 本文提出层级化的多头注意力 (H-MHSA)。 为了结合 CNN 与 Transformer 的优势，提出 Transformer in Convolutional Neural Networks (TransCNN) 的概念，TransCNN 直</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希 / 图网络] Determining the Semantic Graph Connectivity (IJCAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn69/</link>
      <pubDate>Tue, 03 Aug 2021 11:07:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn69/</guid>
      <description>Set and Rebase: Determining the Semantic Graph Connectivity for Unsupervised Cross-Modal Hashing (IJCAI 2020) 概述 两类无监督跨模态哈系 跨模态量化，最小化二进制编码与原始数据低维投影之间的鸿沟 跨模态相似度搜索 三个主要问题 在没</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Adapted Graph Reasoning and Filtration (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn68/</link>
      <pubDate>Mon, 02 Aug 2021 16:52:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn68/</guid>
      <description>Adapted Graph Reasoning and Filtration for Description-Image Retrieval (SIGIR 2021) 概述 本文处理更加抽象的文本描述。 提出一种自适应的图推理与过滤网络 (Adapted Graph Reasoning and Filtration network, AGRF)，包含两大主要部件： 自适应图推理网</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Wavelet Pooling for Convolutional Neural Networks (ICLR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn67/</link>
      <pubDate>Sat, 31 Jul 2021 19:43:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn67/</guid>
      <description>Wavelet Pooling for Convolutional Neural Networks (ICLR 2018) 概述 本文提出一种小波池化算法，使用二阶小波分解对特征进行子采样，放弃了最近临插值方法，而采用了一种子带方法，从而得以使用更少</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Wavelet-enhanced Convolutional Neural Network (2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn66/</link>
      <pubDate>Fri, 30 Jul 2021 21:55:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn66/</guid>
      <description>Wavelet-enhanced Convolutional Neural Network: A New Idea in A Deep Learning Paradigm (2018) 概览 结合 CNN 与小波变换提升分割任务表现。 小波变换在图像处理中的主要作用在于其能够将图像分解为含有不同级别细节的不同尺</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Wavelet Integrated CNNs for Noise-Robust Img Classification(CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn65/</link>
      <pubDate>Fri, 30 Jul 2021 19:49:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn65/</guid>
      <description>Wavelet Integrated CNNs for Noise-Robust Image Classification (CVPR 2020) 开源代码传送门 概述 CNN 对噪声的鲁棒性较差，随机噪声大多为高频成分，CNN 在下采样之前缺少滤波步骤，可能会导致高低频成分的混叠</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Retrieve Fast Rerank Smart: Cooperative and Joint Approaches (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn64/</link>
      <pubDate>Fri, 30 Jul 2021 11:12:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn64/</guid>
      <description>2103.11920v1 Retrieve Fast, Rerank Smart: Cooperative and Joint Approaches for Improved Cross-Modal Retrieval (2021) 开源代码传送门 核心想法 要在计算效率和模型精度上找到平衡。 四种模型 Cross-Encoders 如图 1(a) 所示。 二分类问题，将 \([CLS]\) token 输入分类器，用交</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TIED: A Cycle Consistent Encoder-Decoder Model (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn63/</link>
      <pubDate>Thu, 29 Jul 2021 11:27:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn63/</guid>
      <description>TIED: A Cycle Consistent Encoder-Decoder Model for Text-to-Image Retrieval (CVPRW 2021) 概览 Natural Language (NL) based Vehicle Track Retrieval 任务，对时间也有要求。 本文提出一种文本到图像的编码器解码器网络 (Text-to-Image Encoder-Decoder network, TIED)，将图文映射到潜在空间</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 联邦学习 / 跨模态检索] FedCMR: Federated Cross-Modal Retrieval (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn62/</link>
      <pubDate>Wed, 28 Jul 2021 14:36:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn62/</guid>
      <description>FedCMR: Federated Cross-Modal Retrieval (SIGIR 2021) 概述 基于深度学习的方法需要大量高质量的多模态数据，而现实中，多模态数据由许多不同用户 (client) 分别生成。 本文研究联邦跨模态检索 (Federated Cross-Modal Retrieval, Fe</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / 跨模态检索] Revamping Cross-Modal Recipe Retrieval (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn61/</link>
      <pubDate>Wed, 28 Jul 2021 10:41:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn61/</guid>
      <description>Revamping Cross-Modal Recipe Retrieval with Hierarchical Transformers and Self-supervised Learning (CVPR 2021) 开源代码传送门 图像编码器 \(\phi_{img}\) ResNet-50 / ResNeXt / ViT 菜谱编码器 \(\phi_{rec}\) 三类数据要处理 标题 成分 指导 用三个独立的基于 Transformer 的编码器分别处理三种数据</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Early Convolutions Help Transformers See Better (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn60/</link>
      <pubDate>Tue, 27 Jul 2021 11:07:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn60/</guid>
      <description>2106.14881 Early Convolutions Help Transformers See Better (2021) ViT 模型对超参数敏感，不好优化；而 CNN 更容易优化。 本文认为问题在于 ViT 的前期视觉处理 (early visual processing)，通常是 patchify stem，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Fine-grained Video-Text Retrieval with HGR (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn59/</link>
      <pubDate>Mon, 26 Jul 2021 11:53:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn59/</guid>
      <description>Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning (CVPR 2020) 开源代码传送门 核心 提出一种层级式的图推理模型 (Hierarchical Graph Reasoning model, HGR)，将视频-文本匹配分解为三级语义： 全局事件，在文本中对应整个句</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] A Deep Local and Global Scene-Graph Matching (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn58/</link>
      <pubDate>Sun, 25 Jul 2021 11:30:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn58/</guid>
      <description>2106.02400 A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval (2021) 核心 提出一种局部与全局场景图匹配 (Local and Global Scene Graph Matching, LGSGM) 方法。 视觉图编码器 文本编码器 图嵌入 用多尺度节点注意力将图嵌入为向量。 附</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / ReID] TransReID: Transformer-based Object Re-Identification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn57/</link>
      <pubDate>Wed, 21 Jul 2021 10:10:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn57/</guid>
      <description>2102.04378v2 TransReID: Transformer-based Object Re-Identification (2021) 开源代码传送门 背景 目标 ReID 尚未很好解决的两个问题 从全局视角提取丰富的结构模式 包含细节信息的细粒度特征提取受到下采样的限制 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] CMT: Convolutional Neural Networks Meet Vision Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn56/</link>
      <pubDate>Tue, 20 Jul 2021 14:32:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn56/</guid>
      <description>2107.06263 CMT: Convolutional Neural Networks Meet Vision Transformers (2021) 核心 本文设计了一种 CNN 与 transformer 的交集，即 CMT 架构。 CMT 块 Local Perception Unit (LPU) 绝对的位置编码破坏了平移不变性，忽视了 patch 中的局部关联与结构信息。 $$LPU(X) =</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Incorporating Convolution Designs into Visual Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn55/</link>
      <pubDate>Tue, 20 Jul 2021 10:06:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn55/</guid>
      <description>2103.11816 Incorporating Convolution Designs into Visual Transformers (2021) 核心 设计一种通过卷积增强的图像 Transformer (Convolution-enhanced image Transformer, CeiT)，将 CNN 提取低级特征、强化局部性与 Transformer 提取长程依赖的优势相结合。 Image-to-Tokens 模块 $$x&amp;rsquo; = I2T(x) = MaxPool(BN(Conv(x))).$$</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Heterogeneous Attention Network (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn54/</link>
      <pubDate>Sun, 18 Jul 2021 19:39:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn54/</guid>
      <description>Heterogeneous Attention Network for Effective and Efficient Cross-modal Retrieval (SIGIR 2021) 背景 联合嵌入 (joint embedding) 方法的问题 只进行全局匹配 文本与图像只在匹配阶段有交互 多模态的 Transformer 系方法能够在较早的阶段实现跨模态交互，但</description>
    </item>
    
    <item>
      <title>Latex 中矩阵的几种实现方式</title>
      <link>http://jonathanwayy.xyz/2021/latex_matrix/</link>
      <pubDate>Sun, 18 Jul 2021 16:20:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_matrix/</guid>
      <description>记录一下 Latex 中实现矩阵的几种方式。 1. 无括号 代码 \begin{matrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{matrix} 效果 $$\begin{matrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{matrix}$$ 2. 圆括号 代码 \begin{pmatrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{pmatrix} % 或 \left(\begin{matrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{matrix}\right) 效果</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Cross-Graph Attention Model (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn53/</link>
      <pubDate>Sun, 18 Jul 2021 11:25:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn53/</guid>
      <description>Cross-Graph Attention Enhanced Multi-Modal Correlation Learning for Fine-Grained Image-Text Retrieval (SIGIR 2021) 背景 SIGIR 2021 短文。 现有三类跨模态检索方法 全局相关性学习 局部相关性学习 高阶语义概念学习 在模态特定的语义概念 (modality-specific semantic concepts) 之外，还应</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Graph Structured Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn52/</link>
      <pubDate>Sun, 18 Jul 2021 10:10:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn52/</guid>
      <description>2004.00277 Graph Structured Network for Image-Text Matching (CVPR 2020) 开源代码传送门 总览 本文提出一种图结构匹配网络 (Graph Structured Matching Network, GSMN)，对目标、关系与属性显式建模。 以下两组相关性互相促进 细粒度目</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / ViT] M2TR: Multi-modal Multi-scale Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn51/</link>
      <pubDate>Sat, 17 Jul 2021 14:34:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn51/</guid>
      <description>2104.09770 M2TR: Multi-modal Multi-scale Transformers for Deepfake Detection (2021) 背景 Deepfake 检测任务。 本文提出一种多模态多尺度 Transformer (Multi-modal Multi-scale Transformer, M2TR)，包含一个多尺度 Transformer 模块 (MT) 和一个跨模态融合模块 (CMF)，利用频域</description>
    </item>
    
    <item>
      <title>Latex 添加无编号脚注</title>
      <link>http://jonathanwayy.xyz/2021/latex_footnote_without_number/</link>
      <pubDate>Sat, 17 Jul 2021 11:53:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_footnote_without_number/</guid>
      <description>在使用 Latex 的过程中，有时需要添加不带编号的脚注，目前尝试过有效的有两种办法，记录如下。 方法一 \renewcommand{\thefootnote}{} \footnotetext{脚注内容} 方法二 \l</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Frequency learning for image classification (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn50/</link>
      <pubDate>Fri, 16 Jul 2021 21:04:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn50/</guid>
      <description>2006.15476 Frequency learning for image classification (2020) 核心问题 如果一个神经网络完全设计成在频域进行操作会怎么样？ 本文设计了 FreqNet 研究上述问题。 本文方法 图像分块 对图像层级式地分块以提取多</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Global Filter Networks for Image Classification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn49/</link>
      <pubDate>Fri, 16 Jul 2021 19:50:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn49/</guid>
      <description>2107.00645 Global Filter Networks for Image Classification (2021) 开源代码传送门 核心方法 本文提出一种全局滤波器网络 (Global Filter Network, GFNet)，在频域中学习空间位置之间的相互关系。 不同于视觉 transformer 中的自注</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Improving Image Classification With Frequency Domain Layers (MLSP 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn48/</link>
      <pubDate>Fri, 16 Jul 2021 15:02:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn48/</guid>
      <description>Improving image classification with frequency domain layers for feature extraction (MLSP 2017) 核心 研究从频域提取的特征对深度网络架构的作用。 提出频率特征提取层。 方法 对输入图像层级式分块以提取多粒度信息，对各块使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] High-Frequency Component Explain Generalization of CNNs (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn47/</link>
      <pubDate>Fri, 16 Jul 2021 10:29:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn47/</guid>
      <description>High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks (CVPR 2020) 背景 从数据视角研究 CNN 的泛化表现。 CNN 挖掘高频成分 将原始数据分解为高低频成分，\(x = \{x_{l}, x_{h}\}\)，分别简写为 LFC</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 人脸伪造检测] Spatial-Phase Shallow Learning (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn46/</link>
      <pubDate>Thu, 15 Jul 2021 21:12:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn46/</guid>
      <description>Spatial-Phase Shallow Learning: Rethinking Face Forgery Detection in Frequency Domain (CVPR 2021) 背景 人脸伪造检测 (face forgery detection) 任务。 在合成假脸过程中使用上采样，该操作通常会在频域留下痕迹。 核心方法与观点 本文提出一种空间-</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Multi-Modality Cross Attention Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn45/</link>
      <pubDate>Wed, 14 Jul 2021 10:42:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn45/</guid>
      <description>Multi-Modality Cross Attention Network for Image and Sentence Matching (CVPR 2020) 出发点 既考虑模态间关联，也考虑模态内关联。 提出多模态交叉注意力网络 (Multi-Modality Cross Attention Network)，主要由自注意力模块与交叉注意</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像去噪] NBNet: Noise Basis Learning with Subspace Projection (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn44/</link>
      <pubDate>Mon, 12 Jul 2021 21:56:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn44/</guid>
      <description>2012.15028 NBNet: Noise Basis Learning for Image Denoising with Subspace Projection (CVPR 2021) 核心思想 通过图像投影，利用非局部的图像信息。 由输入图像生成一组图像基向量 (image basis vectors)，接着在这些基向量张成</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Non-Local Neural Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn43/</link>
      <pubDate>Mon, 12 Jul 2021 15:09:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn43/</guid>
      <description>Non-Local Neural Networks (CVPR 2018) 开源代码传送门 核心内容 提出非局部操作用于捕捉长距离依赖关系，通过输入特征图所有位置上特征的加权和计算各位置的响应值 (respons</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] CAMP: Cross-Modal Adaptive Message Passing (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn42/</link>
      <pubDate>Mon, 12 Jul 2021 10:58:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn42/</guid>
      <description>CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval (ICCV 2019) 开源代码传送门 背景 现有方法的问题 现有方法通常学习一个公共的嵌入空间，在其中衡量特征相似度，使用 ranking loss 进行训练。 这类方法没有</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 风格迁移] Photorealistic Style Transfer via Wavelet Transforms (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn41/</link>
      <pubDate>Mon, 12 Jul 2021 10:12:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn41/</guid>
      <description>Photorealistic Style Transfer via Wavelet Transforms (ICCV 2019) 开源代码传送门 背景 风格迁移任务。 模型应当在不损伤图像细节的情况下实现风格迁移。 本文提出一种基于白化与色彩变换的小波矫正迁移 (wavelet</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Channel Shuffle 操作的 PyTorch 实现</title>
      <link>http://jonathanwayy.xyz/2021/channel-shuffle/</link>
      <pubDate>Sun, 11 Jul 2021 14:26:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/channel-shuffle/</guid>
      <description>在 ShuffleNet、SA-Net 以及一系列模型中涉及到了一种 Channel Shuffle 操作，用于在沿着通道维分组运算后保证各组特征之间能够有信息交互。 Channel Shuffle 的机</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] SA-Net: Shuffle Attention for Deep CNNs (ICASSP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn40/</link>
      <pubDate>Sun, 11 Jul 2021 10:53:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn40/</guid>
      <description>2102.00240v1 SA-Net: Shuffle Attention for Deep Convolutional Neural Networks (ICASSP 2021) 开源代码传送门 背景 设计了 Shuffle Attention (SA) 模块，将特征沿着通道维分组，对每个子特征用 Shuffle 单元同时计算通道注意力与空间注意力。 Shuffle Attention (SA) 特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 图像恢复] Multi-level Wavelet-CNN for Image Restoration (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn39/</link>
      <pubDate>Sat, 10 Jul 2021 16:41:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn39/</guid>
      <description>Multi-level Wavelet-CNN for Image Restoration (CVPR 2018) 背景 图像恢复 (Image Restoration) 的目的 从观测到的较差图像 \(y\) 恢复潜在的干净图像 \(x\)。 本文设计了一种多级小波 CNN (multi-level wavelet CNN, MWCNN) 模型，增大感受野，改善</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / Transformer] FNet: Mixing Tokens with Fourier Transforms (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn38/</link>
      <pubDate>Sat, 10 Jul 2021 15:34:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn38/</guid>
      <description>2105.03824 FNet: Mixing Tokens with Fourier Transforms (2021) 开源代码传送门 出发点 用更简单的 token 混合机制取代自注意力层。 最终选择傅利叶变换，设计了 FNet 模型。 离散傅利叶变换 (Discrete Fourier Transform, DFT) 傅利叶变换将</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / 跨模态检索] Fine-grained Visual Textual Alignment (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn37/</link>
      <pubDate>Sat, 10 Jul 2021 11:14:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn37/</guid>
      <description>2008.05231 Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders (2020) 背景 在分类任务上预训练的 CNN 网络所提取的特征通常只能捕捉到图像的全局描述，而忽视了重要的局部细节。 现有方法的问题 由于交</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 多模态预训练] Unicoder-VL (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn36/</link>
      <pubDate>Sat, 10 Jul 2021 10:00:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn36/</guid>
      <description>Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training (AAAI 2020) 背景 尚未出现能够够直接处理跨模态任务与数据的预训练模型。 本文基于多层 Transformer 提出一种通用视觉语言编码器 (Universal Encoder for Vision And Language, Uni</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Swin Transformer (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn35/</link>
      <pubDate>Fri, 09 Jul 2021 10:54:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn35/</guid>
      <description>2103.14030 Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (2021) 开源代码传送门 背景 Transformer 在视觉任务上的主要困难 视觉元素的尺度可能相当不同，但是当前工作中 token 都固定尺度 图像具有更高的像素分辨率</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Generating Adversarial Examples with Adversarial Networks (IJCAI 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn34/</link>
      <pubDate>Wed, 07 Jul 2021 11:06:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn34/</guid>
      <description>Generating Adversarial Examples with Adversarial Networks (IJCAI 2018) AdvGAN 模型架构 $$\mathcal{L}_{GAN} = \mathbb{E}_{x} log \mathcal{D}(x) + \mathbb{E}_{x} log(1 - \mathcal{D}(x + \mathcal{G}(x))),$$ $$\mathcal{L}_{adv}^{f} = \mathbb{E}_{x}\mathcal{l}_f(x + \mathcal{G}(x), t),$$ $$\mathcal{L}_{hinge} = \mathbb{E}_{x} max(0, ||\mathcal{G}(x)||_{2} - c),$$ $$\mathcal{L} = \mathcal{L}_{adv}^{f} + \alpha \mathcal{L}_{GAN} + \beta \mathcal{L}_{hinge}.$$ 样本可视化</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Query Attack via Opposite-Direction Feature (2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn33/</link>
      <pubDate>Tue, 06 Jul 2021 15:13:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn33/</guid>
      <description>1809.02681 Query Attack via Opposite-Direction Feature:Towards Robust Image Retrieval (2018) 背景 现有分类攻击方法在在检索场景中的困难 其目标是类别预测，与检索任务不同 检索场景中训练时的类别与测试时通常是不同的 本文针</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Nyquist 频率与 Nyquist 间隔</title>
      <link>http://jonathanwayy.xyz/2021/ldp9/</link>
      <pubDate>Tue, 06 Jul 2021 11:36:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp9/</guid>
      <description>若带限信号 \(x(t)\) 的最高角频率为 \(\omega_{m}\)，则在一定条件下，信号 \(x(t)\) 可以用等间隔 \(T\) 的抽样值唯一表示。 抽样间隔 \(T\) 需满足： $$T \le \frac{\pi}{\omega_{m}} = \frac{1}{2f_{m}},$$ 或</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 时域抽样定理</title>
      <link>http://jonathanwayy.xyz/2021/ldp8/</link>
      <pubDate>Tue, 06 Jul 2021 11:24:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp8/</guid>
      <description>时域抽样定理 设 \(X(j\omega)\) 和 \(X(e^{j\Omega})\) 分别表示连续时间信号 \(x(t)\) 和离散时间信号 \(x[k]\) 的频谱，即 $$X(j\omega) = \int_{-\infty}^{\infty}x(t)e^{-j\omega t}dt, \ X(e^{j\Omega}) = \sum_{-\infty}^{\infty} x[k]e^{-j\Omega k}.$$ 若存在 $$x[k] = x(t)|_{t = kT},$$ 则有 $$X(e^{j\Omega}) = \frac{1}{T}\sum_{-\infty}^{+\infty} X[j(\omega - n\omega_{sam})], \quad \omega_{sam} = 2\pi/T, \quad \Omega = \omega T.$$ 表</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] XCiT: Cross-Covariance Image Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn32/</link>
      <pubDate>Mon, 05 Jul 2021 12:59:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn32/</guid>
      <description>2106.09681 XCiT: Cross-Covariance Image Transformers (2021) 开源代码传送门 背景 Transformers 中自注意力模块计算复杂度高。 本文用一种转置的注意力 (transposed attention) 取代自注意力，称为交叉协方差注意力 (cross-covariance attention, XCA)，其对于</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Similarity Reasoning and Filtration (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn31/</link>
      <pubDate>Sat, 03 Jul 2021 21:00:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn31/</guid>
      <description>2101.01368 Similarity Reasoning and Filtration for Image-Text Matching (AAAI 2021) 开源代码传送门 先前方法的缺陷 在局部特征之间计算基于标量的余弦相似度，可能并不足以表征区域与单词之间的关联模式 大多数方法使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] VOLO: Vision Outlooker for Visual Recognition (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn30/</link>
      <pubDate>Sat, 03 Jul 2021 16:23:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn30/</guid>
      <description>2106.13112v2 VOLO: Vision Outlooker for Visual Recognition (2021) 背景 制约 ViT 不如 CNN 的一个主要因素 ViT 在将细粒度特征以及上下文编码成 token 时效率较低。 本文设计了一种简单轻量的注意力机制，称为 Outl</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本 / ReID] Vulnerability of Person Re-Identification Models (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn29/</link>
      <pubDate>Fri, 02 Jul 2021 11:05:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn29/</guid>
      <description>Vulnerability of Person Re-Identification Models to Metric Adversarial Attacks (CVPR 2020) 背景 闭集 (closed-set) 任务，即训练与测试使用同样类别的任务上对抗样本已经有了较广泛的研究，开集 (open-set) 任务如 ReID 上的相关研究较少。 为了骗过</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 遮挡 ReID] High-Order Information Matters (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn28/</link>
      <pubDate>Thu, 01 Jul 2021 13:01:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn28/</guid>
      <description>High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification (CVPR 2020) 背景 本文研究遮挡 ReID 问题 (Occluded Person Re-Identification)，该问题主要受到遮挡 (occlusion) 和出界 (outliers) 两个问题困扰。大部分现</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 图网络] Beyond Low-frequency Information in GCNs (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn26/</link>
      <pubDate>Tue, 29 Jun 2021 12:00:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn26/</guid>
      <description>2101.00797 Beyond Low-frequency Information in Graph Convolutional Networks 背景 当前一些研究认为平滑信号，即低频信息是 GNN 成功的关键。 本文重点思考是否低频信息就能完全满足需求，以及其他信息在 GNN 中扮演着怎</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 图网络] Spectral Graph Attention Network (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn25/</link>
      <pubDate>Mon, 28 Jun 2021 19:34:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn25/</guid>
      <description>2003.07450 Spectral Graph Attention Network (2020) 背景 图注意力网络 (Graph Attention Network, GAT) 通过引入注意力机制优化 GCN 的卷积过程。具体来说，在节点聚合 (node aggregation) 阶段，GAT 赋予各边一个自注意力权重，用于捕</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 带噪跨模态检索] Learning Cross-Modal Retrieval With Noisy Labels (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn24/</link>
      <pubDate>Mon, 28 Jun 2021 11:45:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn24/</guid>
      <description>Learning Cross-Modal Retrieval With Noisy Labels (CVPR 2021) 背景 为了应对较高的数据标注成本，大规模数据会用到一些非专业的标注资源，从而不可避免地在标签中引入了噪音信息。 由图 2 可以看出，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Cross-Modal Learning with Adversarial Samples (NeurIPS 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn23/</link>
      <pubDate>Sun, 27 Jun 2021 13:29:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn23/</guid>
      <description>Cross-Modal Learning with Adversarial Samples (NeurIPS 2019) 文中主要以跨模态哈希检索为例，其搜索空间大致可分为四个部分：T2T、I2I、I2T/T2I、NR (not relevant)。 理想的针</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] AI-GAN: Attack-Inspired Generation of Adversarial Examples (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn22/</link>
      <pubDate>Sat, 26 Jun 2021 15:10:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn22/</guid>
      <description>2002.02196 AI-GAN: Attack-Inspired Generation of Adversarial Examples (2020) 本文设计了一种新的 GAN 的变体，称为 Attack-Inspired GAN (AI-GAN) 用于生成对抗扰动。 AI-GAN 的训练包含两个阶段： 第一阶段，联合训练一个生成器、一个鉴别器和一个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 迁移学习] FSDR: Frequency Space Domain Randomization (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn21/</link>
      <pubDate>Sat, 26 Jun 2021 11:27:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn21/</guid>
      <description>FSDR: Frequency Space Domain Randomization for Domain Generalization (CVPR 2021) 背景 语义分割受限于数据标注的难度，因此带有自动生成标签的合成图像成了缓解这一问题的一个选择。 但是这类模型由于域偏置与偏移</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 低版本 PyTorch 中 pack_padded_sequence 缺少 enforce_sorted 参数问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp7/</link>
      <pubDate>Sat, 26 Jun 2021 10:35:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp7/</guid>
      <description>背景 近期用到了一台新的堡垒机，上面的驱动环境比较老只能用 1.0.0 版本的 PyTorch。 调试了代码以后发现大体上没有遇到什么问题，唯一就是涉及到 GRU 的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Learning in the Frequency Domain (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn20/</link>
      <pubDate>Fri, 25 Jun 2021 15:44:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn20/</guid>
      <description>Learning in the Frequency Domain (CVPR 2020) 出发点 受计算资源与内存限制，大多数 CNN 模型只用低分辨率的 RGB 图像作为输入，处理现实中高分辨率图像时要先缩小尺寸，而这一过程难免带来</description>
    </item>
    
    <item>
      <title>Latex 希腊字母</title>
      <link>http://jonathanwayy.xyz/2021/latex_greeceletter/</link>
      <pubDate>Fri, 25 Jun 2021 11:30:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_greeceletter/</guid>
      <description>记录一下 Latex 中的希腊字母实现，以备查用。 小写 代码 大写 代码 \(\alpha\) \alpha \(\Alpha\) \(A\) \Alpha A \(\beta\) \beta \(\Beta\) \(B\) \Beta B \(\gamma\) \gamma \(\Gamma\) \Gamma \(\delta\) \delta \(\Delta\) \Delta \(\epsilon\) \(\varepsilon\) \epsilon \varepsilon \(\Epsilon\) \(E\) \Epsilon E \(\zeta\) \zeta \(\Zeta\) \(Z\) \Zeta Z \(\eta\) \eta \(\Eta\) \(H\) \Eta H \(\theta\) \(\vartheta\) \theta</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 带限函数</title>
      <link>http://jonathanwayy.xyz/2021/ldp6/</link>
      <pubDate>Thu, 24 Jun 2021 22:32:06 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp6/</guid>
      <description>定义 若一个函数对于以原点为中心的有限区间（带宽） \([-\mu_{max}, \mu_{max}]\)以外的频率值，其傅里叶变换均为 0，则称之为带限函数*。*</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 卷积定理</title>
      <link>http://jonathanwayy.xyz/2021/conv-theory/</link>
      <pubDate>Thu, 24 Jun 2021 21:23:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/conv-theory/</guid>
      <description>卷积定义 用算子 \(\star\) 表示两个函数的卷积，定义为 $$(f \star h)(t) = \int_{-\infty}^{\infty} f(\tau)h(t-\tau)d\tau.$$ 卷积定理 空间域中两个函数的卷积的傅里叶变换，等于频率域中两个函数傅里叶变换的乘积。反过</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Graph Convolutional Network Hashing (IJCAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn19/</link>
      <pubDate>Thu, 24 Jun 2021 15:26:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn19/</guid>
      <description>Graph Convolutional Network Hashing for Cross-Modal Retrieval (IJCAI 2019) 本文提出一种针对跨模态检索的图卷积网络哈希 (graph convolution network hashing, GCH)，由一个语义编码器、两个特征编码网络和一个基于融合模块的图卷积网</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- ValueError: only one element tensors can be converted to Python scalars 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp5/</link>
      <pubDate>Thu, 24 Jun 2021 00:01:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp5/</guid>
      <description>问题描述 形如以下操作： lst = [] a, b = torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6]) lst.append(a) lst.append(b) converted_lst = torch.tensor(lst) 得到如下报错信息： ValueError: only one element tensors can be converted to Python scalars 原因分析 元素为 tensor 的 list 无法转化为 tensor。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-modal Scene Graph Matching (WACV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn18/</link>
      <pubDate>Wed, 23 Jun 2021 09:36:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn18/</guid>
      <description>Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval (WACV 2020) 出发点 正确的匹配除了要包含相同的目标以外，目标之间的关系也应当相同。 因而，本文使用视觉场景图 (visual scene graph, VSG) 和文本场景图 (textual scene graph, TSG)</description>
    </item>
    
    <item>
      <title>Latex 分段函数的一种实现方式</title>
      <link>http://jonathanwayy.xyz/2021/latex_case/</link>
      <pubDate>Tue, 22 Jun 2021 21:05:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_case/</guid>
      <description>代码实现 $$f(x) = \begin{cases} 2x + 1, \quad if \ x &amp;gt; 1, \\\\ -3x, \quad if \ x \le 1.\end{cases}$$ 呈现效果 $$f(x) = \begin{cases} 2x + 1, \quad if \ x &amp;gt; 1, \\ -3x, \quad if \ x \le 1.\end{cases}$$</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-Modal Center Loss (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn17/</link>
      <pubDate>Tue, 22 Jun 2021 19:53:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn17/</guid>
      <description>Cross-Modal Center Loss for 3D Cross-Modal Retrieval (CVPR 2021) 现有方法的问题 核心思想是最小化由预训练网络提取的多模态特征之间的跨模态差异，而这些预训练网络应当与跨模态数据联合训练 现有的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Deep Cross-Modal Hashing (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn16/</link>
      <pubDate>Tue, 22 Jun 2021 16:33:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn16/</guid>
      <description>Deep Cross-Modal Hashing (CVPR 2017) 哈希的目标 将原始空间数据点映射为汉明空间中的二进制编码，在汉明空间中保留原始空间中的相似度。 两类多模态哈希 (Multi-Modal Hashing, MMH) 多源哈希 (multi-source hashing, MSH) 目的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Self-Supervised Adversarial Hashing Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn15/</link>
      <pubDate>Tue, 22 Jun 2021 10:54:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn15/</guid>
      <description>Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval (CVPR 2018) 当前(当时)跨模态哈希方法的主要不足 直接使用单类标签来衡量跨模态的语义关联，而事实上标准的跨模态数据集中一个图像实例往往能</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] AXM-Net: Cross-Modal Context Sharing Attention Network (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn14/</link>
      <pubDate>Mon, 21 Jun 2021 14:24:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn14/</guid>
      <description>2101.08238 AXM-Net: Cross-Modal Context Sharing Attention Network for Person Re-ID (2021) 主要困难 各模态中与行人相关的信息结构相当不同 关键在于学习一个能够从数据中提取语义的网络，而不是在训练过程中简单记住各行</description>
    </item>
    
    <item>
      <title>Latex 公式中的空格表示</title>
      <link>http://jonathanwayy.xyz/2021/latex_space/</link>
      <pubDate>Mon, 21 Jun 2021 14:11:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_space/</guid>
      <description>类型 代码 效果 备注 两个 quad 空格 a \qquad b \(a \qquad b\) 两个 M 的宽度 quad 空格 a \quad b \(a \quad b\) 一个 M 的宽度 大空格 a\ b \(a \ b\) 1/3 M 的宽度 中等空格 a\;b \(a \; b\) 2/7 M 的宽度 小空格 a\,b</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] FcaNet: Frequency Channel Attention Networks (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn13/</link>
      <pubDate>Sun, 20 Jun 2021 14:25:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn13/</guid>
      <description>2012.11879 FcaNet: Frequency Channel Attention Networks (2020) 利用频率分析重新思索通道注意力，并从数学上证明传统的全局平均池化 (GAP) 是频域中特征分解的一种特殊情况。 GAP 的潜在问题 尽管简洁高效， GAP</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Deep Adversarial Graph Attention Convolution Network (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn12/</link>
      <pubDate>Thu, 17 Jun 2021 20:35:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn12/</guid>
      <description>Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search (MM 2019) 先前工作的问题 孤立对待图像中的局部块，只考虑文本描述中单词级别的上下文关联，因而忽略了图文所包含的结构化语义信息 (structured semantic</description>
    </item>
    
    <item>
      <title>Latex 插入空行</title>
      <link>http://jonathanwayy.xyz/2021/latex_spaceline/</link>
      <pubDate>Wed, 16 Jun 2021 20:38:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_spaceline/</guid>
      <description>有时需要在 Latex 文档中插入一个空行，查阅一些文档并做了一些尝试后，发现了一种较为简单的方法： \\ \hspace*{\fill} \\ 即换行，用空格填充后，再次换行。</description>
    </item>
    
    <item>
      <title>Latex 取消段首缩进</title>
      <link>http://jonathanwayy.xyz/2021/latex_noindent/</link>
      <pubDate>Wed, 16 Jun 2021 20:28:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_noindent/</guid>
      <description>要取消 Latex 段首缩进，可以在需要处理的段落前加上如下代码： \noindent</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TIPCB: A Simple but Effective Part-based Convolutional Baseline</title>
      <link>http://jonathanwayy.xyz/2021/prn11/</link>
      <pubDate>Tue, 15 Jun 2021 13:42:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn11/</guid>
      <description>2105.11628 TIPCB: A Simple but Effective Part-based Convolutional Baseline for Text-based Person Search 视觉特征学习 在视觉 CNN 分支，ResNet-50 第 3 和第 4 个残差块的输出分别作为低级特征图和高级特征图。 用 GMP 聚合低级特</description>
    </item>
    
    <item>
      <title>Matplotlib 颜色表</title>
      <link>http://jonathanwayy.xyz/2021/matplotlib-color/</link>
      <pubDate>Sun, 06 Jun 2021 16:46:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/matplotlib-color/</guid>
      <description>Matplotlib 中的颜色表如下图所示，可以直接通过参数color=&#39;颜色名称&#39;选取对应的颜色。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Reasoning with Heterogeneous Graph Alignment (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn10/</link>
      <pubDate>Thu, 03 Jun 2021 18:30:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn10/</guid>
      <description>Reasoning with Heterogeneous Graph Alignment for Video Question Answering 出发点 需要一个统一的方法同步对模态间和模态内的关联性进行建模与推理。 本文所提到的 “视频段 (video shot)” 指的是一小段能被 3D 卷</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Object-Centric Representation Learning (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn9/</link>
      <pubDate>Tue, 01 Jun 2021 09:48:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn9/</guid>
      <description>2104.05166 Object-Centric Representation Learning for Video Question Answering 模型高训练度带来的问题 这类模型更倾向于捕捉浅层模式 (shallow patterns)，因而会在浅层统计量形成捷径 (creating shortcuts through surface statistic</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Location-Aware Graph Convolutional Networks (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn8/</link>
      <pubDate>Sun, 30 May 2021 14:39:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn8/</guid>
      <description>Location-aware graph convolutional networks for video question answering (AAAI 2020) 与 IQA 相比 VQA 的几个困难 由于视频包含大量帧，其视觉内容更为复杂，尤其是其中一些帧主要被与问题无关的背景内容 (strong background content) 占据 视频通常</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn7/</link>
      <pubDate>Sat, 29 May 2021 14:57:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn7/</guid>
      <description>Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering (AAAI 2019) RNN + Attention 方法问题 耗时 由于 RNN 的特点，难以建模长距离依赖关系 本文提出了一个名为 Positional Self-Attention with Co-attention (PSAC) 的新架构，是首个无需使用 RNN 的模型。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Consensus-Aware Visual-Semantic Embedding (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn6/</link>
      <pubDate>Sat, 29 May 2021 10:55:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn6/</guid>
      <description>2007.08883 Consensus-Aware Visual-Semantic Embedding for Image-Text Matching (ECCV 2020) 当前主流方法 将图像与文本投影到一个公共空间，通常无法充分利用图像中目标以及句子段之间的关系 分块级别的匹配 (fragment-level matching) + 聚合其相似度</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Learnable Aggregating Net with Diversity Learning (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn5/</link>
      <pubDate>Fri, 28 May 2021 19:43:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn5/</guid>
      <description>Learnable Aggregating Net with Diversity Learning for Video Question Answering (MM 2019) V-VQA 三个难点 视频通常包含大量冗余信息 一些视频相关问题涉及多个关键帧，较难定位 有效聚合视频与句子特征以捕捉回答真实分布的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Structured Two-stream Attention Network (AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn4/</link>
      <pubDate>Fri, 28 May 2021 15:21:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn4/</guid>
      <description>Structured two-stream attention network for video question answering (AAAI 2019) 图像 QA 中两种注意力机制 visual attention: &amp;ldquo;where to look&amp;rdquo; question attention: &amp;ldquo;what words to listen to&amp;rdquo; 视频 QA 三个主要困难 考虑长距离时域结构，同时不遗漏重要信息 为了定位相关视频实</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Motion-Appearance Co-Memory Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn3/</link>
      <pubDate>Fri, 28 May 2021 14:06:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn3/</guid>
      <description>Motion-Appearance Co-Memory Networks for Video Question Answering (CVPR 2018) 视频 QA 与 图像 QA 相比三个独有特性 处理较长的图像序列，包含更丰富的信息（数量上及多样性上） 动作与外观信息通常互相关联，能够彼此</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn2/</link>
      <pubDate>Thu, 27 May 2021 13:55:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn2/</guid>
      <description>Video Question Answering via Gradually Refined Attention over Appearance and Motion (MM17) 延伸模型的缺陷 由 video captioning 与 ImageQA 等任务延伸而来的模型容易弱化或忽视视频的时域信息 这些模型将整个问题编码为单一特征，不具有足够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] TGIF-QA (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn1/</link>
      <pubDate>Thu, 27 May 2021 13:49:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn1/</guid>
      <description>Tgif-qa: Toward spatio-temporal reasoning in visual question answering (CVPR 2017) 开源代码传送门 三点重要贡献 提出专为视频 VQA 设计的三种新任务，需要对视频的时空推断(spatio-temporal reaso</description>
    </item>
    
    <item>
      <title>OpenCV 与 PIL.Image 之间的图像通道（channel）转换</title>
      <link>http://jonathanwayy.xyz/2021/opencv-pil-channel/</link>
      <pubDate>Fri, 14 May 2021 19:46:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/opencv-pil-channel/</guid>
      <description>今天有学弟提到了一个打开图像并显示时图像色调变蓝的问题，经历一番周折后最终解决，在此记录。 问题的根本原因在于 OpenCV 默认是以 BGR 的通道顺序打开和显示</description>
    </item>
    
    <item>
      <title>辛格函数 sinc 杂记</title>
      <link>http://jonathanwayy.xyz/2021/sinc/</link>
      <pubDate>Mon, 10 May 2021 13:21:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/sinc/</guid>
      <description>sinc 函数在不同领域有不同的定义，用符号 \(sinc(x)\) 表示，可被定义为归一化的或者非归一化的，不过两种函数都是正弦函数和单调递减函数 \(\frac{1}{x}\) 的乘积。 数字信号处理和</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch view 函数 RuntimeError 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp4/</link>
      <pubDate>Sat, 08 May 2021 18:37:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp4/</guid>
      <description>问题描述 在程序中使用形如 A = X.view(32, -1) 的语句调用 view 时出现如下报错： RuntimeError: view size is not compatible with input tensor&amp;#39;s size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead. 原因分析 view() 需要 Tensor 中元素地址连续，</description>
    </item>
    
    <item>
      <title>ACM 会议论文模板去除 ACM Reference Format 信息</title>
      <link>http://jonathanwayy.xyz/2021/latex_acmtem/</link>
      <pubDate>Fri, 16 Apr 2021 18:48:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_acmtem/</guid>
      <description>在投稿撰文时，可以去掉 ACM 的 latex 模板中会有的 ACM Reference Format 信息。 方法如下： 在 \documentclass[sigconf]{acmart} 下面添加以下几行： \settopmatter{printacmref=false} % Removes citation information below abstract \renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column \pagestyle{plain} % removes running headers</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- GELU 激活函数的 Pytorch 实现</title>
      <link>http://jonathanwayy.xyz/2021/ldp3/</link>
      <pubDate>Thu, 25 Mar 2021 17:48:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp3/</guid>
      <description>Transformers 中提出了一个新的激活函数 GELU，由于比较新，该模块仅在 1.8 以上版本的 Pytorch 中被收录。 要在较低版本的 Pytorch 中使用 GELU，可自行编写实现，代码如下：</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- nvidia-smi指令报错：Failed to initialize NVML 解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp2/</link>
      <pubDate>Fri, 22 Jan 2021 14:27:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp2/</guid>
      <description>问题描述 使用指令 nvidia-smi 时报错： Failed to initialize NVML: Driver/library version mismatch 问题原因 NVIDIA 内核驱动版本与系统驱动不一致。 解决办法 网上有很多调整驱动版本的方法教程，但其实最简单的方法</description>
    </item>
    
    <item>
      <title>BLWL[37] 简单干净卸载 cuda 的方法</title>
      <link>http://jonathanwayy.xyz/2020/blwl37/</link>
      <pubDate>Sat, 19 Dec 2020 21:00:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl37/</guid>
      <description>网上有各种有关如何通过一系列命令卸载 cuda 的教程，但其实 cuda 是自带卸载脚本的。 第一步： 找到 cuda 所在路径 cuda 位于 /usr/local/cuda/bin 目录下。 进入目录后运行卸载脚本： sudo ./uninstall_cuda_10.0.pl 第</description>
    </item>
    
    <item>
      <title>通过 Conda 安装 Python OpenCV</title>
      <link>http://jonathanwayy.xyz/2020/conda-opencv/</link>
      <pubDate>Fri, 18 Dec 2020 00:33:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/conda-opencv/</guid>
      <description>可通过以下命令安装 OpenCV： conda install -c menpo opencv</description>
    </item>
    
    <item>
      <title>BLWL[36] Ubuntu 安装显卡驱动时 No additional drivers available 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl36/</link>
      <pubDate>Mon, 14 Dec 2020 23:50:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl36/</guid>
      <description>新配置的 Ubuntu 炼丹工作站在通过 Software and Updates 中的 Additional Drivers 选项卡安装 GPU 显卡驱动时出现了 No additional drivers available 的问题。 解决方案如下。 sudo add-apt-repository ppa:xorg-edgers/ppa sudo apt-get update 完成后回到 Software and Updates 中的 Additional Drivers 选项卡</description>
    </item>
    
    <item>
      <title>BLWL[35] Ubuntu 上向日葵被连接时闪退问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl35/</link>
      <pubDate>Mon, 14 Dec 2020 23:18:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl35/</guid>
      <description>新配置的 Ubuntu 炼丹工作站上装的向日葵一被连接就闪退，查阅了一些资料后顺利解决了这个问题，具体方法如下。 sudo apt-get update sudo apt-get upgrade sudo apt-get install lightdm 安装 lightdm 的过程中会让选择</description>
    </item>
    
    <item>
      <title>压缩图表空间以调整 Latex 版面</title>
      <link>http://jonathanwayy.xyz/2020/latex_vspace/</link>
      <pubDate>Sun, 06 Dec 2020 23:51:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/latex_vspace/</guid>
      <description>很多会议论文都有特定的模板格式，并且在篇幅上有所限制，为了尽可能地多写一点内容，可以考虑在图像、表格、公式中利用 \vspace{} 来压缩垂直距离。 例如： \begin{figure*}[t] \vspace{-1.0cm}</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- &#39; xsrf&#39; argument missing from POST 解决方法</title>
      <link>http://jonathanwayy.xyz/2020/ldp1/</link>
      <pubDate>Thu, 12 Nov 2020 12:47:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/ldp1/</guid>
      <description>问题描述 Jupyter Notebook 保存时出现 ‘_xsrf’ argument missing from POST 错误，保存失败。 解决方法 刷新 Jupyter Notebook 的 home 界面即可，简单粗暴，亲测有效。</description>
    </item>
    
    <item>
      <title>花书 阅读笔记</title>
      <link>http://jonathanwayy.xyz/2020/flower-book-notes/</link>
      <pubDate>Mon, 05 Oct 2020 19:34:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/flower-book-notes/</guid>
      <description>Chapter 1 硬编码知识体系 —— 知识库方法（Cyc） 从原始数据中提取模式 —— 机器学习 简单的机器学习算法的性能很大程度上以来于给定数据的表示 很难知道该提</description>
    </item>
    
    <item>
      <title>Numpy散记 -- allclose函数的使用</title>
      <link>http://jonathanwayy.xyz/2020/numpy-allclose/</link>
      <pubDate>Tue, 21 Apr 2020 13:09:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/numpy-allclose/</guid>
      <description>函数原型 numpy.allclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False) 参数 a, b：用于比较的两个输入数组 rtol：float型，相对容忍系数（relative tolerance parameter） atol：fl</description>
    </item>
    
    <item>
      <title>Numpy散记 -- clip函数的使用</title>
      <link>http://jonathanwayy.xyz/2020/numpy-clip/</link>
      <pubDate>Tue, 21 Apr 2020 12:54:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/numpy-clip/</guid>
      <description>函数原型 numpy.clip(a, a_min, a_max, out=None, **kwargs) 参数 a：数组 a_max：数组元素最大值 a_min：数组元素最小值 功能 np.clip()函数用于将数组元素的值保持在给定区间</description>
    </item>
    
    <item>
      <title>浅谈激活函数以零为中心的问题</title>
      <link>http://jonathanwayy.xyz/2020/zero-centered-active-function/</link>
      <pubDate>Wed, 15 Apr 2020 13:20:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/zero-centered-active-function/</guid>
      <description>本文主要探讨神经网络中的激活函数不是以零为中心（non-zero-centered）是否会导致神经网络收敛变慢，并讨论其背后的原因。 神经元 如</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 饱和激活函数</title>
      <link>http://jonathanwayy.xyz/2020/dl-notes1/</link>
      <pubDate>Wed, 04 Mar 2020 09:07:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/dl-notes1/</guid>
      <description>饱和激活函数 当自变量趋于正无穷时，若激活函数的导数趋于0,则称之为右饱和。 当自变量趋于负无穷时，若激活函数的导数趋于0,则称之为左饱和。 若一</description>
    </item>
    
    <item>
      <title>基于人脸检测的自动口罩/护目镜佩戴小程序</title>
      <link>http://jonathanwayy.xyz/2020/mask-wearing/</link>
      <pubDate>Wed, 29 Jan 2020 18:56:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/mask-wearing/</guid>
      <description>最近武汉的疫情闹得沸沸扬扬，大家出行都戴上了口罩预防被传染，很多人还给自己的社交媒体头像戴上了口罩。 为了省去P图时来回来去调整的麻烦，这里开</description>
    </item>
    
  </channel>
</rss>
