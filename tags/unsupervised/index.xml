<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>unsupervised on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/tags/unsupervised/</link>
    <description>Recent content in unsupervised on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Wed, 22 Sep 2021 13:14:16 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/tags/unsupervised/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[论文阅读笔记 -- 图像标注] Unsupervised Image Captioning (CVPR 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn99/</link>
      <pubDate>Wed, 22 Sep 2021 13:14:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn99/</guid>
      <description>Unsupervised Image Captioning (CVPR 2019) 开源代码传送门 概述 无监督图像标注任务，即不使用任何标记好的图文对来训练图像标注模型。 三个目标 用文本对抗生成方法，在句子语料上训练一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Aggregation-based Graph Convolutional Hashing (TMM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn92/</link>
      <pubDate>Thu, 09 Sep 2021 13:11:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn92/</guid>
      <description>Aggregation-based Graph Convolutional Hashing for Unsupervised Cross-modal Retrieval (TMM 2021) 概述 本文提出基于聚合的图卷积哈希方法 (Aggregation-based Graph Convolutional Hashing, AGCH)。 模型架构 主要部件 图像编码器 + 图像 GCN 文本编码器 + 文本 GCN 融合模块 生成</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Learning Sufficient Scene Representation(Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn91/</link>
      <pubDate>Wed, 08 Sep 2021 19:36:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn91/</guid>
      <description>Learning Sufficient Scene Representation for Unsupervised Cross-modal Retrieval (Neurocomputing 2021) 背景 此前有工作从统计层面证明分析了跨模态检索的过程，借助变分推断证明了不可能同时最大化模态内与模态间相似度，二者会互相约</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Unsupervised Cross-modal Retrieval through AL (ICME 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn90/</link>
      <pubDate>Tue, 07 Sep 2021 14:45:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn90/</guid>
      <description>Unsupervised Cross-modal Retrieval through Adversarial Learning (ICME 2017) 概述 本文提出基于对抗学习的无监督跨模态检索 (Unsupervised Cross-modal Retrieval with Adversarial, UCAL)。 包含四个部分： 图像特征映射 文本特征映射 模态分类器，生成二元特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Attention-Guided Semantic Hashing (ICME 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn88/</link>
      <pubDate>Thu, 02 Sep 2021 12:29:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn88/</guid>
      <description>Attention-Guided Semantic Hashing for Unsupervised Cross-Modal Retrieval (ICME 2021) 概述 无监督跨模态哈希问题。 本文提出注意力指导的语义哈希模型 (Attention-Guided Semantic Hashing)。 模型架构 特征提取 VGG-16 提取图像特征，unive</description>
    </item>
    
  </channel>
</rss>
