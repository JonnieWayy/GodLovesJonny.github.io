<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ReID on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/tags/reid/</link>
    <description>Recent content in ReID on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Sun, 30 Jan 2022 22:02:51 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/tags/reid/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[论文阅读笔记 -- ReID] Hashing Person Re-ID with Self-distilling Smooth Relaxation (NC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn181/</link>
      <pubDate>Sun, 30 Jan 2022 22:02:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn181/</guid>
      <description>Hashing Person Re-ID with Self-distilling Smooth Relaxation (Neurocomputing 2021) 概述 影响哈希 ReID 表现的两大因素： 特征表征：与非哈希方法的浮点特征相比，哈希编码在表征能力上具有内在的劣势 哈希松弛度：为了能够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Divide-and-Merge the Embedding Space (Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn179/</link>
      <pubDate>Sat, 29 Jan 2022 14:55:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn179/</guid>
      <description>Divide-and-Merge the Embedding Space for Cross-modality Person Search (Neurocomputing 2021) 概述 本文提出一种分治嵌入学习架构 (Divide-and-Merge Embedding Learning Framework, DME)，关注两方面： 如何提取健壮的局部表征，而避免产生无意义信息 如何有效合并多</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Short Range Correlation Transformer for Occluded Person ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn177/</link>
      <pubDate>Mon, 24 Jan 2022 14:16:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn177/</guid>
      <description>2201.01090 Short Range Correlation Transformer for Occluded Person Re-Identification (2022) 概述 Vision Transformer 在有遮挡的情况下并不擅长捕捉局部特征，本文提出一种基于 Vision Transformer 包含三种模块的 PFT 模型，以提升 patch 序列的短距离相关性并提取</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Explainable ReID With Attribute-Guided Metric Distillation (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn175/</link>
      <pubDate>Fri, 21 Jan 2022 14:49:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn175/</guid>
      <description>Explainable Person Re-Identification With Attribute-Guided Metric Distillation (ICCV 2021) 开源代码传送门 概述 旨在借助语义属性学习一个解释器，以回答如下两个问题： 是什么属性使两个人不同？ 各属性对差异有多大的影响？ 本</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parsing-based View-aware Embedding Network for VReID (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn173/</link>
      <pubDate>Tue, 18 Jan 2022 14:44:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn173/</guid>
      <description>Parsing-based View-aware Embedding Network for Vehicle Re-Identification (CVPR 2020) 概述 车辆 ReID 任务。 本文提出一种基于解析的视角可知的嵌入网络 (Parsing-based View-aware Embedding Network, PVEN)，包含三个部分： vehicle part parser view-aware feature alignent common-visible feature enhancement 本文方法 Vehicle Part Parser</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] On Exploring Pose Estimation as an Auxiliary Learning Task (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn172/</link>
      <pubDate>Sun, 16 Jan 2022 20:46:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn172/</guid>
      <description>2201.03859 On Exploring Pose Estimation as an Auxiliary Learning Task for Visible-Infrared Person Re-identification (2022) 开源代码传送门 概述 本文提出一种双分支的 VI-ReID 架构，通过联合学习一个姿态估计的辅助任务和一个行人 ReID 的主任务，提取模态</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Fusion-Attention Network for Person Search with Language (PRL 2018)</title>
      <link>http://jonathanwayy.xyz/2022/prn168/</link>
      <pubDate>Wed, 12 Jan 2022 21:10:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn168/</guid>
      <description>Fusion-Attention Network for Person Search with Free-form Natural Language (PRL 2018) 概述 这个课题上比较早的一篇文章，提出一种描述增强的融合注意力网络 (Description-Strengthened and Fusion-Attention Network, DSFA-Net)，包含一个融合子网络和一个注</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Clustering Active Learning for Person ReID (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn167/</link>
      <pubDate>Wed, 12 Jan 2022 15:46:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn167/</guid>
      <description>2112.13308 Unsupervised Clustering Active Learning for Person Re-identification (BMVC 2021) 概述 本文提出一种无监督聚类主动学习模型 (Unsupervised Clustering Active Learning model, UCAL)，结合无监督学习与主动学习的优势。 基本无监督聚类模型 选择基于 DBSCAN</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Transformer based LP Search with Multiple Region Slicing (TCSVT 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn166/</link>
      <pubDate>Wed, 12 Jan 2022 15:12:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn166/</guid>
      <description>Transformer based Language-Person Search with Multiple Region Slicing (TCSVT 2021) 概述 本文提出一种基于 Transformer 的语言-行人搜索架构，提出两种新的分割方式，分为重叠分割 (Overlapped Slicing, OS) 与基于关键点的分割 (Key-point-based Slicing)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Multi-Domain Joint Training for Person Re-Identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn165/</link>
      <pubDate>Wed, 12 Jan 2022 14:20:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn165/</guid>
      <description>2201.01983 Multi-Domain Joint Training for Person Re-Identification (2022) 概述 本文发现多个域联合训练得到的 ReID 表现比独立训练各个域要差，称为域冲突问题 (domain conflict problem)，域冲突可能来自于三种因素： 数</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Quality-aware Part Models for Occluded Person Re-identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn164/</link>
      <pubDate>Tue, 11 Jan 2022 13:17:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn164/</guid>
      <description>2201.00107 Quality-aware Part Models for Occluded Person Re-identification (2022) 概述 本文提出一种称为 Quality-aware Part Models (QPM) 的方法以解决遮挡 ReID 问题，其包含一个部分特征学习分支和一个全局特征学习分支。 Joint Learning Part Feature and Quality Scores Part Feature Extractor</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Attention Based Instance Discri. Learning (WACV 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn163/</link>
      <pubDate>Mon, 10 Jan 2022 12:09:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn163/</guid>
      <description>Unsupervised Attention Based Instance Discriminative Learning for Person Re-Identification (WACV 2022) 开源代码传送门 概述 本文提出一种组注意力模块 (grouped attention module, GAM) 以处理无监督 ReID 问题。 本文方法 Grouped Attention Module (GAM) 分为通道注意力和空间注意力两部分</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Text-Based Person Search with Limited Data (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn162/</link>
      <pubDate>Sat, 08 Jan 2022 14:00:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn162/</guid>
      <description>2110.10807 Text-Based Person Search with Limited Data (BMVC 2021) 开源代码传送门 概述 关注 TBPS 任务中训练数据缺乏的问题。 本文提出一种跨模态动量对比学习架构 (cross-modal momentum contrasive learning framework, CM-MoCo) 来丰富给定 mini-batch 中的训练数据，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TAGPerson: A Target-Aware Generation Pipeline for Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn161/</link>
      <pubDate>Sat, 08 Jan 2022 13:10:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn161/</guid>
      <description>2112.14239 TAGPerson: A Target-Aware Generation Pipeline for Person Re-identification (2021) 开源代码传送门 概述 本文提出一种目标可知的生成方法 (Target-Aware Generation pipeline, TAGPerson) 用于生成自动标注的合成 ReID 数据集。 本文方法的三点优势： 在渲染过程中</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Specific Person Retrieval via Incomplete Text Description (ICMR 2015)</title>
      <link>http://jonathanwayy.xyz/2022/prn160/</link>
      <pubDate>Fri, 07 Jan 2022 20:57:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn160/</guid>
      <description>Specific Person Retrieval via Incomplete Text Description (ICMR 2015) 概述 Specific Person Retrieval vis Incomplete Text Description 任务。 用户所提供的属性通常是不完整的，本文采用一种线性稀疏重构 (linear sparse reconstruction) 来不全不完整的属性。 本文方法 包含线下</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Improving Person ReID with Temporal Constraints (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn159/</link>
      <pubDate>Fri, 07 Jan 2022 16:16:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn159/</guid>
      <description>Improving Person Re-Identification with Temporal Constraints (WACVW 2022) DAA 数据集传送门 概述 本文构建了一个新的数据集，称为 DAA，旨在关注视觉信息的同时关注时空信息，数据集中含有时间戳信息、帧序号、</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FTN: Foreground-Guided Texture-Focused Person Re-Identification (2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn158/</link>
      <pubDate>Fri, 07 Jan 2022 13:18:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn158/</guid>
      <description>FTN: Foreground-Guided Texture-Focused Person Re-Identification (2020) 概述 本文关注背景干扰 (background interference) 问题，提出一种前景指导下关注纹理的网络 (Foreground-Guided Texture-Focused Network)，其包含一个语义编码器 (S-Enc)、一个紧凑</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Event-Driven Re-Id: Privacy-Preserving Person ReId (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn157/</link>
      <pubDate>Thu, 06 Jan 2022 14:04:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn157/</guid>
      <description>Event-Driven Re-Id: A New Benchmark and Method Towards Privacy-Preserving Person Re-Identification (WACVW 2022) 概述 关注 ReID 系统的隐私保护问题。事件相机 (event cameras) 记录场景的异步亮度变化，称之为事件 (event)。视觉信息被丢弃，只剩下</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] On the Importance of Appearance and Interaction (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn156/</link>
      <pubDate>Wed, 05 Jan 2022 14:24:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn156/</guid>
      <description>On the Importance of Appearance and Interaction Feature Representations for Person Re-Identification (WACVW 2022) 概述 本文认为不止是表征能力强的特征本身，特征之间的交互也在匹配时起到关键作用，交互信息与基于外观的特征互补。 本文</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Adversarial Attribute-Text Embedding for Person Search (TMM 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn155/</link>
      <pubDate>Tue, 04 Jan 2022 10:58:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn155/</guid>
      <description>Adversarial Attribute-Text Embedding for Person Search with Natural Language Query (TMM 2020) 概述 本文提出一种对抗的属性-文本嵌入网络 (adversarial attribute-text embedding network, AATE)。 视觉属性图卷积网络 包含一个视觉注意力模块和一个图卷积网络</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Hybrid Ranking Representation for Person ReID (PR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn152/</link>
      <pubDate>Sun, 02 Jan 2022 14:10:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn152/</guid>
      <description>Learning Hybrid Ranking Representation for Person Re-identification (PR 2022) 概述 本文提出一种双分支的 RANkinG Ensemble (RANGEv2) 方法，联合优化外观特征与排序上下文信息以生成外部排序表征 (external ranking representation)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] A Feature Disentangling Approach via SS Data Augmentation (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn151/</link>
      <pubDate>Sat, 01 Jan 2022 14:25:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn151/</guid>
      <description>A Feature Disentangling Approach for Person Re-identification via Self-supervised Data Augmentation (Applied Soft Computing 2021) 开源代码传送门 概述 本文方法主要的两点改进： 通过打乱图像通道而非常用的 GAN，设计了一个自监督的数据增广方法，并</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Self-supervised Geometric Features Discovery (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn150/</link>
      <pubDate>Wed, 29 Dec 2021 15:30:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn150/</guid>
      <description>Self-supervised Geometric Features Discovery via Interpretable Attention for Vehicle Re-Identification and Beyond (ICCV 2021) 概述 本文提出一种新的架构来学习具有鉴别能力的几何特征 (geometric features)，其借助自监督学习和一个简单但是可解释的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] The Devil is in the Details for Vehicle ReID (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn149/</link>
      <pubDate>Wed, 29 Dec 2021 15:05:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn149/</guid>
      <description>The Devil is in the Details: Self-Supervised Attention for Vehicle Re-Identification (ECCV 2020) 概述 本文提出一种针对车辆 ReID 的自监督注意力 (SAVER)，自动关注车辆图像中的显著区域而无需额外的人工标注。 自监督残</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Barlow Twins: SSL via Redundancy Reduction (ICML 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn146/</link>
      <pubDate>Tue, 28 Dec 2021 13:14:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn146/</guid>
      <description>Barlow Twins: Self-Supervised Learning via Redundancy Reduction (ICML 2021) 开源代码传送门 概述 自监督学习任务 (SSL)。 现有工作的一个共同目标是要学习在不同扰动之下依旧稳定的表征，一种典型做法是最大</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Feature Erasing and Diffusion Network for Occluded ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn145/</link>
      <pubDate>Tue, 28 Dec 2021 10:56:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn145/</guid>
      <description>2112.08740 Feature Erasing and Diffusion Network for Occluded Person Re-Identification (2021) 概述 现实场景下主要存在两种干扰： Non-Pedestrian Occlusion (NPO) Non-Target Pedestrian (NTP) 现有方法更多关注前者而忽略了后者，预训练的姿态估计与行人解析模型在含有多个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] DBPS with Multi-Grained Matching Networks (Displays 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn142/</link>
      <pubDate>Sat, 25 Dec 2021 16:05:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn142/</guid>
      <description>Description-Based Person Search with Multi-Grained Matching Networks (Displays 2021) 概述 本文提出一种多粒度匹配架构 (multi-grained matching framework)。 全局粒度表征 ResNet-50 / BERT 细粒度表征 对行人图像使用 Graphonomy 方法进行 human parsin</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-Modal Knowledge Adaptation for LB Person Search (TIP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn141/</link>
      <pubDate>Sat, 25 Dec 2021 14:59:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn141/</guid>
      <description>Cross-Modal Knowledge Adaptation for Language-Based Person Search (TIP 2021) 概述 本文着眼于公共空间学习时不同模态间表征的不一致性。 文本可用于指导图像特征丰富其重要的新人细节通知避免图像独有信息的干扰</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TBPS via Multi-Granularity Embedding Learning (IJCAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn140/</link>
      <pubDate>Sat, 25 Dec 2021 14:15:45 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn140/</guid>
      <description>Text-based Person Search via Multi-Granularity Embedding Learning (IJCAI 2021) 概述 现有方法多存在嵌入模糊问题 (ambiguity embedding problem)。 本文提出一种多粒度嵌入学习模型 (multi-granularity embedding learning model, MGEL)，从粗到细表征行人，并</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Feature Disentangling for Occluded ReID (AAAI 2022)</title>
      <link>http://jonathanwayy.xyz/2021/prn139/</link>
      <pubDate>Fri, 24 Dec 2021 18:43:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn139/</guid>
      <description>Pose-guided Feature Disentangling for Occluded Person Re-identification Based on Transformer (AAAI 2022) 开源代码传送门 概述 本文试图在不涉及空间对齐的情况下结合额外的姿态信息与 Transformer，提出一种姿态指导的特征</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] PGGANet: Pose Guided Graph Attention Network for ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn138/</link>
      <pubDate>Mon, 20 Dec 2021 17:26:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn138/</guid>
      <description>2111.14411 PGGANet: Pose Guided Graph Attention Network for Person Re-identification (2021) 概述 现有方法多只是将姿态热图与特征图相乘得到局部关键点特征，但这种做法并非最佳选择： backbone 输出的全局特征高度抽象，各个像素</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Stronger Baseline for Person Re-Identification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn137/</link>
      <pubDate>Mon, 20 Dec 2021 16:40:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn137/</guid>
      <description>2112.01059 Stronger Baseline for Person Re-Identification (2021) 概述 由于训练数据较之于分类任务更加有限，ReID 有过高的过拟合风险，为了缓解这一问题主要有两种思路： 设计更加轻量级的网络结构，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Semantic-aligned Feature Representation for TBPS (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn136/</link>
      <pubDate>Mon, 20 Dec 2021 15:56:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn136/</guid>
      <description>2112.06714 Learning Semantic-aligned Feature Representation for Test-based Person Search (2021) 概述 本文提出一种语义对齐嵌入方法 (semantic-aligned embedding method)，自动实现细粒度特征的语义对齐，无需额外模型以及跨模态注意力。 方法 Modality-specific Feature</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning To Know Where To See for Occluded ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn131/</link>
      <pubDate>Tue, 30 Nov 2021 11:50:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn131/</guid>
      <description>Learning To Know Where To See: A Visibility-Aware Approach for Occluded Person Re-Identification (ICCV 2021) 概述 随着姿态估计粒度的细化，其预测误差随之上升。 本文试图找到一种策略，能在不过分依赖姿态信息的情况下处理遮挡问</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 对抗攻击] Multi-Expert AAD Using Context Inconsistency (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn130/</link>
      <pubDate>Mon, 29 Nov 2021 13:39:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn130/</guid>
      <description>Multi-Expert Adversarial Attack Detection in Person Re-Identification Using Context Inconsistency (ICCV 2021) 概述 ReID 属于排序问题而非分类问题，因而现有针对分类问题的防御方法并不适合 ReID 任务。 本文提出多专家对抗攻击检测方法 (Multi-Expert Adversarial Attack Detection,</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Syncretic Modality Collaborative Learning for VI-ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn129/</link>
      <pubDate>Mon, 29 Nov 2021 11:06:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn129/</guid>
      <description>Syncretic Modality Collaborative Learning for Visible Infrared Person Re-Identification (ICCV 2021) 概述 现有借助第三模态方法的缺陷 由可视图像生成，导致新模态和可视模态高度相关，但和红外模态不相关 可视图像与红外图像的特征</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Feature Alignment for Occluded ReID (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn128/</link>
      <pubDate>Sun, 28 Nov 2021 19:56:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn128/</guid>
      <description>Pose-Guided Feature Alignment for Occluded Person Re-Identification (ICCV 2019) 概述 本文最早提出了 Occluded ReID 任务，并构建了 Occluded-DukeMTMC 数据集，query 图像全部带遮挡，而 gallery 图像有完整与遮挡两种情况。 Partial ReID 与 Occluded ReID 问题的对比</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning to Disentangle Scenes for ReID (Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn127/</link>
      <pubDate>Sat, 27 Nov 2021 13:37:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn127/</guid>
      <description>2111.05476 Learning to Disentangle Scenes for Person Re-identification (Neurocomputing 2021) 概述 为了有效分解复杂场景，本文提出一种分治策略 (divide-and-conquer strategy)，主要分析了两种情况： 遮挡 (occlusion) 尺度变化 (scale variation) 对输入的图像采</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Matching on Sets: Conquer OcReID Without Alignment (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn126/</link>
      <pubDate>Fri, 26 Nov 2021 16:19:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn126/</guid>
      <description>Matching on Sets: Conquer Occluded Person Re-Identification Without Alignment (AAAI 2021) 概述 本文提出一种在集合上匹配 (Matching on Sets, MoS) 的方法，从而避免复杂而又容易出错的空间对齐过程。 考虑到卷积特征通道通常会编码视觉模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] View Confusion Feature Learning for Person ReID  (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn125/</link>
      <pubDate>Fri, 26 Nov 2021 15:23:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn125/</guid>
      <description>View Confusion Feature Learning for Person Re-identification (ICCV 2019) 概述 本文提出一种视角混淆特征学习模型 (View Confusion Feature Learning, VCFL)，通过结合 view-generic 与 view-specific 模型学习 view-invariant 的特征。 从三个层面实现视角混淆： 基于分类器</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CMReID via Modality Confusion and Center Aggregation(ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn124/</link>
      <pubDate>Fri, 26 Nov 2021 13:08:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn124/</guid>
      <description>Cross-Modality Person Re-Identification via Modality Confusion and Center Aggregation (ICCV 2021) 概述 本文提出一种端到端的模态混淆学习网络 (Modality Confusion Learning network, MCLNet)，其核心想法在于混淆特征学习过程中的模态鉴别，使得优化显</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] SphereReID: Deep Hypersphere Manifold Embedding for ReID (2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn123/</link>
      <pubDate>Thu, 25 Nov 2021 10:10:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn123/</guid>
      <description>SphereReID: Deep Hypersphere Manifold Embedding for Person Re-identification (2019) 开源代码传送门 概述 本文提出一种 metric-based 的架构，称为 SphereReID，引入一个新的损失函数 Sphere Loss。 Softmax Loss $$L_{softmax} = -\frac{1}{N} \sum_{i= 1}^{N} log \frac{e^{z_{y_{i}}}}{\sum_{j=1}^C e^{e^{z_{j}}}},$$ $$z_{j} =</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] GreyReID: Two-stream Framework with RGB-grey Information (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn122/</link>
      <pubDate>Wed, 24 Nov 2021 12:41:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn122/</guid>
      <description>GreyReID: A Novel Two-stream Deep Framework with RGB-grey Information for Person Re-identification (TOMM 2021) 概述 着重关注不同行人之间色彩信息相似的问题，本文称之为 ReID 的色彩过拟合 (color over-fitting)。 RGB 图像与灰度图</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 频域] HLFNet: High-low Frequency Network for Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn121/</link>
      <pubDate>Tue, 23 Nov 2021 14:29:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn121/</guid>
      <description>HLFNet: High-low Frequency Network for Person Re-Identification (IEEE Signal Processing Letters 2021) 概述 本文提出一种高低频网络 (high-low frequency network, HLFNet)。 Frequency Splitting Module (FSM) 利用 guide filter 将原始图像分为高低频图像： $$I_{l} = \mathcal{G}(I_{o}),$$ $$I_{h} = I_{o} / (I_{l} + eps).$$ 将得到</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Occlude Them All: Occlusion-Aware Attention Network (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn120/</link>
      <pubDate>Mon, 22 Nov 2021 15:13:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn120/</guid>
      <description>Occlude Them All: Occlusion-Aware Attention Network for Occluded Person Re-ID (ICCV 2021) 概述 将遮挡按如下分类 4 locations: top, bottom, left, right 2 areas: half, quarter 本文提出一种遮挡可知的掩码网络 (Occlusion-Aware Mask Network, OAMN)，包含三个主要部件： attention-guided mask module occlusion augmentation</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Occluded ReID With Single-Scale Global Representation (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn119/</link>
      <pubDate>Sat, 20 Nov 2021 17:40:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn119/</guid>
      <description>Occluded Person Re-Identification With Single-Scale Global Representations (ICCV 2021) 数据集传送门（尚未更新） 概述 本文提出一种新的 ReID 模型，学习单尺度全局级别的行人表征 (single-scale global-level pedestrian representations)。 构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Weakly Supervised Text-Based Person Re-Identification (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn118/</link>
      <pubDate>Fri, 19 Nov 2021 16:42:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn118/</guid>
      <description>Weakly Supervised Text-Based Person Re-Identification (ICCV 2021) 开源代码传送门 概述 本文提出弱监督图文 ReID，即在训练阶段没有 ID 标注。 新任务的两个困难 各模态内由于类内差异造成的影响难以处理 跨</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CM-NAS for Visible-Infrared Person Re-Identification (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn117/</link>
      <pubDate>Thu, 18 Nov 2021 09:42:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn117/</guid>
      <description>CM-NAS: Cross-Modality Neural Architecture Search for Visible-Infrared Person Re-Identification (ICCV 2021) 开源代码传送门 概述 Visible-Infrared ReID 任务。 现有工作多是设计一个 two-stream 架构，因而就产生了一个问题：哪些层应当被分为两个分支，哪些层应该共享</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] BV-Person: A Large-Scale Dataset for Bird-View ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn116/</link>
      <pubDate>Wed, 17 Nov 2021 20:40:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn116/</guid>
      <description>BV-Person: A Large-Scale Dataset for Bird-View Person Re-Identification (ICCV 2021) 数据集与开源代码传送门 概述 本文提出一种新的 ReID 任务，即鸟瞰视角下的 ReID，并制作了一个大规模数据集，称为 BV-Perso</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] LapsCore: Language-Guided Search via Color Reasoning (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn115/</link>
      <pubDate>Mon, 15 Nov 2021 11:06:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn115/</guid>
      <description>LapsCore: Language-Guided Person Search via Color Reasoning (ICCV 2021) 概述 现有方法隐式地学习跨模态局部关联。 颜色在检索中至关重要。 本文提出一种基于颜色推理的新方法，称为 LapsCore，通过解</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Joint Generative and Contrastive Learning for UnS. ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn112/</link>
      <pubDate>Tue, 09 Nov 2021 09:03:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn112/</guid>
      <description>Joint Generative and Contrastive Learning for Unsupervised Person Re-identification (CVPR 2021) 开源代码传送门 概述 自监督对比学习方法 对于一张图像，最大化其两个增广视角之间的共识 (agreement between two augmented views)，视角指的是对于某</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Query-Adaptive Convolution and Temporal Lifting (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn111/</link>
      <pubDate>Mon, 08 Nov 2021 12:14:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn111/</guid>
      <description>Interpretable and Generalizable Person Re-Identification with Query-Adaptive Convolution and Temporal Lifting (ECCV 2020) 开源代码传送门 概述 现有的许多 ReID 方法只是在两个表征向量之间简单计算距离，而无视了两张图像真实内容之间的直接关系。 本文</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Knowledge-SV Learning: Knowledge Consensus Constraints (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn110/</link>
      <pubDate>Thu, 04 Nov 2021 11:07:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn110/</guid>
      <description>Knowledge-Supervised Learning: Knowledge Consensus Constraints for Person Re-Identification (MM 2021) 概述 本文旨在利用知识在不引入额外推断成本的基础上，约束同一数据上的多视角共识以提升精度。 行人 ReID 相较于图像分类的特殊性 检索</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Inter- and Intra-part Relational Transformer (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn108/</link>
      <pubDate>Sun, 31 Oct 2021 17:14:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn108/</guid>
      <description>Pose-guided Inter- and Intra-part Relational Transformer for Occluded Person Re-Identification (MM 2021) 开源代码传送门 概述 本文提出一种姿态指导的部件内间关系 Transformer。 姿态指导的特征提取 $$M = GMP(\hat{M}),$$ $$c_{g} = max(M_{g}),$$ $$F_{pose} = GAP((M &amp;gt; \tau)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 数据增强] Cut-Thumbnail: A Novel Data Augmentation for CNN (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn107/</link>
      <pubDate>Fri, 29 Oct 2021 14:34:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn107/</guid>
      <description>Cut-Thumbnail: A Novel Data Augmentation for Convolutional Neural Network (MM 2021) 开源代码传送门 概述 现有的数据增强方法通过改变空间或色彩信息、增加噪音或混合来自不同图像的信息，来提高网络的泛化能力和鲁</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Feature Learning with KD for Occluded ReID (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn106/</link>
      <pubDate>Tue, 26 Oct 2021 22:45:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn106/</guid>
      <description>Pose-Guided Feature Learning with Knowledge Distillation for Occluded Person Re-Identification (MM 2021) 概述 本文提出一种通过知识蒸馏进行基于姿态指导的特征学习架构 (Pose-Guided Feature Learning with Knowledge Distillation network, PGFL-KD) 架构，姿态信息用于约束全局特征的学习而在测</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TBPS in Full Images via Semantic-Driven Proposal Generation (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn105/</link>
      <pubDate>Fri, 15 Oct 2021 16:42:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn105/</guid>
      <description>2109.12965 Text-based Person Search in Full Images via Semantic-Driven Proposal Generation 概述 提出在完整图像中进行行人检索的任务，可视为 Person Detection 和 Text-based Person Retrieval 的结合。 本文提出 Semantic-Driven Region Proposal Net (SDPRN)。 构建了两个新数据集 CUHK-SYSU-TBPS</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Posterior and Prior for Uncertainty Modeling in ReID(2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn103/</link>
      <pubDate>Sat, 25 Sep 2021 15:30:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn103/</guid>
      <description>2007.08785 Learning Posterior and Prior for Uncertainty Modeling in Person Re-Identification (2020) 概述 本文在 ReID 任务中同时学习样本后验与类别先验，以量化输入图像及其相应类别的不确定性。 整体架构 上分支用 GAP 处理特征图得到</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Person Search Challenges and Solutions: A Survey (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn102/</link>
      <pubDate>Fri, 24 Sep 2021 22:10:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn102/</guid>
      <description>2105.01605v1 Person Search Challenges and Solutions: A Survey (2021) 概述 关于 Image-based Person Search 与 Text-based Person Search 的综述。 本文与现有综述的差异 Detection-identification Inconsistency Problem Person Search 研究进展时间线 三个主要挑战 从场景图像学习具有足够鉴别能力的行人</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 人机交互 / 跨模态检索] Interactive Natural Language Person Search (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn101/</link>
      <pubDate>Fri, 24 Sep 2021 19:53:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn101/</guid>
      <description>2002.08434v1 Interactive Natural Language-based Person Search (2020) CUHK-QA 数据集传送门 概述 可以认为本文是换了一种说法，把 Text-based Person Search 称为 Zero-shot re-ID。 将 language-based re-ID 视为一种 VQA 任务，输入为图文对，输出为二值化答案。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Semantically Self-Aligned Network for T2I Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn97/</link>
      <pubDate>Mon, 13 Sep 2021 13:18:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn97/</guid>
      <description>2107.12666v2 Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification (2021) 开源代码传送门 概述 自然语言描述的自由形式带来的两个问题 同一张图像对应的描述可能非常不同 对于身体部件的描述可能以任意顺序呈</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parameter-Efficient Person Re-identification in the 3D Space (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn96/</link>
      <pubDate>Sat, 11 Sep 2021 14:44:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn96/</guid>
      <description>2006.04569 Parameter-Efficient Person Re-identification in the 3D Space (2020) 开源代码传送门 概述 考察 2D 行人外观与 3D 几何结构之间的互补信息。 本文提出 Omni-scale Graph Network (OG-Net)，在 3D 空间中进行 ReID。 模型架</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] PCNET: Parallelly Conquer Large Variance of Person ReId (ICIP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn95/</link>
      <pubDate>Fri, 10 Sep 2021 13:22:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn95/</guid>
      <description>PCNET: Parallelly Conquer the Large Variance of Person Re-Identification (ICIP 2021) 概述 本文提出 Parallelly Conquer Net (PCNet)，主要包含三个部件： Pose Adaptation Module (PAM) Global Alignment Module (GAM) Pixel-Wised Attention Module (PWAM) 用模块聚合单元 (Module Aggregation Unit) 整合各个子模块生成的特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learn 3D Shape Feature for Texture-insensitive Person ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn86/</link>
      <pubDate>Sun, 29 Aug 2021 14:30:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn86/</guid>
      <description>Learning 3D Shape Feature for Texture-insensitive Person Re-identification (CVPR 2021) 开源代码传送门 背景 Person ReID 任务。 研究表明 Person ReID 相当依赖衣着外观纹理 (clothing appearance textures)，大多数现有方法在衣着纹理较迷惑时表现</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / ReID] TransReID: Transformer-based Object Re-Identification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn57/</link>
      <pubDate>Wed, 21 Jul 2021 10:10:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn57/</guid>
      <description>2102.04378v2 TransReID: Transformer-based Object Re-Identification (2021) 开源代码传送门 背景 目标 ReID 尚未很好解决的两个问题 从全局视角提取丰富的结构模式 包含细节信息的细粒度特征提取受到下采样的限制 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Query Attack via Opposite-Direction Feature (2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn33/</link>
      <pubDate>Tue, 06 Jul 2021 15:13:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn33/</guid>
      <description>1809.02681 Query Attack via Opposite-Direction Feature:Towards Robust Image Retrieval (2018) 背景 现有分类攻击方法在在检索场景中的困难 其目标是类别预测，与检索任务不同 检索场景中训练时的类别与测试时通常是不同的 本文针</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 遮挡 ReID] High-Order Information Matters (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn28/</link>
      <pubDate>Thu, 01 Jul 2021 13:01:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn28/</guid>
      <description>High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification (CVPR 2020) 背景 本文研究遮挡 ReID 问题 (Occluded Person Re-Identification)，该问题主要受到遮挡 (occlusion) 和出界 (outliers) 两个问题困扰。大部分现</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Graph Convolutional Network Hashing (IJCAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn19/</link>
      <pubDate>Thu, 24 Jun 2021 15:26:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn19/</guid>
      <description>Graph Convolutional Network Hashing for Cross-Modal Retrieval (IJCAI 2019) 本文提出一种针对跨模态检索的图卷积网络哈希 (graph convolution network hashing, GCH)，由一个语义编码器、两个特征编码网络和一个基于融合模块的图卷积网</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-modal Scene Graph Matching (WACV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn18/</link>
      <pubDate>Wed, 23 Jun 2021 09:36:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn18/</guid>
      <description>Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval (WACV 2020) 出发点 正确的匹配除了要包含相同的目标以外，目标之间的关系也应当相同。 因而，本文使用视觉场景图 (visual scene graph, VSG) 和文本场景图 (textual scene graph, TSG)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-Modal Center Loss (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn17/</link>
      <pubDate>Tue, 22 Jun 2021 19:53:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn17/</guid>
      <description>Cross-Modal Center Loss for 3D Cross-Modal Retrieval (CVPR 2021) 现有方法的问题 核心思想是最小化由预训练网络提取的多模态特征之间的跨模态差异，而这些预训练网络应当与跨模态数据联合训练 现有的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Deep Cross-Modal Hashing (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn16/</link>
      <pubDate>Tue, 22 Jun 2021 16:33:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn16/</guid>
      <description>Deep Cross-Modal Hashing (CVPR 2017) 哈希的目标 将原始空间数据点映射为汉明空间中的二进制编码，在汉明空间中保留原始空间中的相似度。 两类多模态哈希 (Multi-Modal Hashing, MMH) 多源哈希 (multi-source hashing, MSH) 目的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Self-Supervised Adversarial Hashing Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn15/</link>
      <pubDate>Tue, 22 Jun 2021 10:54:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn15/</guid>
      <description>Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval (CVPR 2018) 当前(当时)跨模态哈希方法的主要不足 直接使用单类标签来衡量跨模态的语义关联，而事实上标准的跨模态数据集中一个图像实例往往能</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] AXM-Net: Cross-Modal Context Sharing Attention Network (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn14/</link>
      <pubDate>Mon, 21 Jun 2021 14:24:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn14/</guid>
      <description>2101.08238 AXM-Net: Cross-Modal Context Sharing Attention Network for Person Re-ID (2021) 主要困难 各模态中与行人相关的信息结构相当不同 关键在于学习一个能够从数据中提取语义的网络，而不是在训练过程中简单记住各行</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Deep Adversarial Graph Attention Convolution Network (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn12/</link>
      <pubDate>Thu, 17 Jun 2021 20:35:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn12/</guid>
      <description>Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search (MM 2019) 先前工作的问题 孤立对待图像中的局部块，只考虑文本描述中单词级别的上下文关联，因而忽略了图文所包含的结构化语义信息 (structured semantic</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TIPCB: A Simple but Effective Part-based Convolutional Baseline</title>
      <link>http://jonathanwayy.xyz/2021/prn11/</link>
      <pubDate>Tue, 15 Jun 2021 13:42:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn11/</guid>
      <description>2105.11628 TIPCB: A Simple but Effective Part-based Convolutional Baseline for Text-based Person Search 视觉特征学习 在视觉 CNN 分支，ResNet-50 第 3 和第 4 个残差块的输出分别作为低级特征图和高级特征图。 用 GMP 聚合低级特</description>
    </item>
    
  </channel>
</rss>
