<!DOCTYPE html>
<html lang="zh-cn">
  <head>
  
  <link rel="stylesheet" href="/js/katex/katex.min.css" >
  <script src="/js/katex/katex.min.js" > </script>
  <script src="/js/katex/contrib/auto-render.min.js" ></script>
  <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body);
      });
  </script>

  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Jonathan Wang">
  
  
  
  <link rel="prev" href="http://jonathanwayy.xyz/2021/prn1/" />
  <link rel="next" href="http://jonathanwayy.xyz/2021/prn3/" />
  <link rel="canonical" href="http://jonathanwayy.xyz/2021/prn2/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           [论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017) | Jonathan`s Blog
       
  </title>
  <meta name="title" content="[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017) | Jonathan`s Blog">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "http:\/\/jonathanwayy.xyz"
    },
    "articleSection" : "posts",
    "name" : "[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)",
    "headline" : "[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)",
    "description" : "Video Question Answering via Gradually Refined Attention over Appearance and Motion (MM17) 延伸模型的缺陷 由 video captioning 与 ImageQA 等任务延伸而来的模型容易弱化或忽视视频的时域信息 这些模型将整个问题编码为单一特征，不具有足够",
    "inLanguage" : "zh-cn",
    "author" : "Jonathan Wang",
    "creator" : "Jonathan Wang",
    "publisher": "Jonathan Wang",
    "accountablePerson" : "Jonathan Wang",
    "copyrightHolder" : "Jonathan Wang",
    "copyrightYear" : "2021",
    "datePublished": "2021-05-27 13:55:03 \u002b0800 CST",
    "dateModified" : "2021-05-27 13:55:03 \u002b0800 CST",
    "url" : "http:\/\/jonathanwayy.xyz\/2021\/prn2\/",
    "wordCount" : "696",
    "keywords" : [ "paper reading","cv","notes","vqa", "Jonathan`s Blog"]
}
</script>

  
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    
        <div class="top-scroll-bar"></div>
    
    <div class="container">
        <div class="navbar-header header-logo">
            
            <span class="logo_mark" >></span>
            <a href="http://jonathanwayy.xyz">
                <span class="logo_text" >$ cd /home/ </span>
                <span class="logo_cursor" ></span>
            </a>
            
        </div>
        
            
            
        
        <div class="navbar-right">
                
                <span class="menu">
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                </span>
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     
         <div class="top-scroll-bar"></div>
     
     <div class="container">
        <div class="navbar-header">
            <div class="header-logo">
                
                    <span class="logo_mark">></span>
                    <a href="http://jonathanwayy.xyz">
                        <span class="logo_text">$ cd /home/ </span>
                        <span class="logo_cursor"></span>
                </a>
                
            </div>
            <div class="navbar-right">
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
                <div class="menu-toggle">
                    <span></span><span></span><span></span>
                </div>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>

    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)</h1>
        <div class="post-meta">
                
                Written by <a itemprop="name" href="http://jonathanwayy.xyz" rel="author">Jonathan Wang</a> 
                <span class="post-time">
                on <time datetime=2021-05-27 itemprop="datePublished">May 27, 2021</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="http://jonathanwayy.xyz/categories/paper-reading-notes/"> Paper Reading Notes </a>
                        
                </span>
                <span class="post-word-count">, 696 words</span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          <h1 id="video-question-answering-via-gradually-refined-attention-over-appearance-and-motion-mm17">Video Question Answering via Gradually Refined Attention over Appearance and Motion (MM17)</h1>
<h2 id="延伸模型的缺陷">延伸模型的缺陷</h2>
<ul>
<li>由 video captioning 与 ImageQA 等任务延伸而来的模型容易弱化或忽视视频的时域信息</li>
<li>这些模型将整个问题编码为单一特征，不具有足够的表现能力来揭示问题所包含的全部信息，且粗粒度会遗漏关键词信息</li>
</ul>
<p>每个 clip 包含 16 个连续的帧。</p>
<h2 id="特征提取">特征提取</h2>
<ul>
<li>从帧提取外观特征 (appearance features)，每帧相当于一张静态图像，本文用 VGG 提取特征</li>
<li>从 clips 提取动作特征 (motion features)，本文用 C3D 提取特征</li>
<li>frame-level + clip-level 得到表征视频特征的一系列向量</li>
<li>embedding layer + LSTM 提取文本特征</li>
</ul>
<p><img src="/images/2021/PRN2/1.png" alt="Fig 1"></p>
<h2 id="attention-memory-unit-amu">Attention Memory Unit (AMU)</h2>
<ul>
<li>AMU 以当前时间步的单词嵌入、问题信息以及视频特征作为输入</li>
<li>主要由四种模块构成：Attention (ATT)、Channel Fusion (CF)、Memory (LSTMa)、Refine (REF)</li>
</ul>
<p><img src="/images/2021/PRN2/2.png" alt="Fig 2"></p>
<h3 id="attention-att">Attention (ATT)</h3>
<ul>
<li>对于一个关于视频的问题，只有其中部分帧或 clip 与问题最为相关</li>
<li>对 appearance 和 motion 分别提取</li>
<li>ATT1 强化当前单词的影响，ATT2 强调后续用 LSTMa 隐状态生成第二个注意力权重</li>
</ul>
<h3 id="channel-fusion-cf">Channel Fusion (CF)</h3>
<ul>
<li>对 ATT1 从 appearance 和 motion 得到的特征进行融合</li>
<li>用当前单词嵌入求取权重</li>
</ul>
<h3 id="memory-lstma">Memory (LSTMa)</h3>
<ul>
<li>用于控制 ATT2 的输入，并记住注意力历史</li>
<li>其隐状态包含当前已处理的问题信息</li>
<li>以 CF 得到的中间视频特征、自己的上一个隐状态以及上一个时间步的 refined video representation 作为输入</li>
</ul>
<h3 id="refine-ref">Refine (REF)</h3>
<ul>
<li>ATT1 和 ATT2 得到的注意力权重的均值作为此处权重</li>
</ul>
<h2 id="答案生成-answer-generation">答案生成 (Answer Generation)</h2>
<ul>
<li>最终得到融合后的视频特征、从 AMU 的 memory 隐状态得到的注意力历史以及从 LSTMq 隐状态得到的问题特征</li>
<li>将粗粒度的问题特征与细粒度的单词特征结合利用</li>
<li>用 softmax 分类器解决选择问题，三个特征乘积变换</li>
<li>用 LSTM 生成答案，用两个隐状态对 LSTM 进行初始化，用视频特征最为输入，各个单词可以用与上一项中类似方式得到</li>
</ul>
<p><img src="/images/2021/PRN2/3.png" alt="Fig 3"></p>
<h2 id="两个-trick">两个 trick</h2>
<ul>
<li>对于不包含在 GloVe 中的词，将所有存在的单词的词嵌入取均值作为其词嵌入</li>
<li>注意力的可视化方式值得借鉴，对标量式注意力用条行图表征</li>
</ul>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Jonathan Wang </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=http://jonathanwayy.xyz/2021/prn2/>http://jonathanwayy.xyz/2021/prn2/</span>
            </p>
            <p>
                <span>Ads:</span>
                <span>欢迎参与<a href="https://www.didiyun.com" target="_blank" style="text-decoration:underline">滴滴云AI大师活动</a>购买 GPU / vGPU / 机器学习产品，使用我的滴滴AI大师码 <b style="color:red">0724</b> 可享受 <b>9 折</b>优惠！</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="http://jonathanwayy.xyz/tags/paper-reading/">
                    #paper reading</a></span>
            
            <span class="tag"><a href="http://jonathanwayy.xyz/tags/cv/">
                    #cv</a></span>
            
            <span class="tag"><a href="http://jonathanwayy.xyz/tags/notes/">
                    #notes</a></span>
            
            <span class="tag"><a href="http://jonathanwayy.xyz/tags/vqa/">
                    #vqa</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="http://jonathanwayy.xyz">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="http://jonathanwayy.xyz/2021/prn1/" class="prev" rel="prev" title="[论文阅读笔记 -- VQA] TGIF-QA (CVPR 2017)"><i class="iconfont icon-left"></i>&nbsp;[论文阅读笔记 -- VQA] TGIF-QA (CVPR 2017)</a>
         
        
        <a href="http://jonathanwayy.xyz/2021/prn3/" class="next" rel="next" title="[论文阅读笔记 -- VQA] Motion-Appearance Co-Memory Networks (CVPR 2018)">[论文阅读笔记 -- VQA] Motion-Appearance Co-Memory Networks (CVPR 2018)&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
    <h5 id="wc" style="font-size: 1rem;text-align: center;">700 Words|Read in about 2 Min|本文总阅读量<span id="busuanzi_value_page_pv"></span>次</h5>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2020 - 2022</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="http://jonathanwayy.xyz">Jonathan Wang</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
          <span id="busuanzi_container_site_pv">
              本站访问量：<span id="busuanzi_value_site_pv"></span>次
          </span>
    </div>
</footer>













    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  






     </div>
  </body>
</html>
