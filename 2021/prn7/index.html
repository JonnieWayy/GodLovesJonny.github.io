<!DOCTYPE html>
<html lang="zh-cn">
  <head>
  
  <link rel="stylesheet" href="/js/katex/katex.min.css" >
  <script src="/js/katex/katex.min.js" > </script>
  <script src="/js/katex/contrib/auto-render.min.js" ></script>
  <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body);
      });
  </script>

  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Jonathan Wang">
  
  
  
  <link rel="prev" href="http://wzj.life/2021/prn6/" />
  <link rel="next" href="http://wzj.life/2021/prn8/" />
  <link rel="canonical" href="http://wzj.life/2021/prn7/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           [论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019) | Zijie Wang`s Blog
       
  </title>
  <meta name="title" content="[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019) | Zijie Wang`s Blog">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "http:\/\/wzj.life"
    },
    "articleSection" : "posts",
    "name" : "[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019)",
    "headline" : "[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019)",
    "description" : "Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering (AAAI 2019) RNN \u002b Attention 方法问题 耗时 由于 RNN 的特点，难以建模长距离依赖关系 本文提出了一个名为 Positional Self-Attention with Co-attention (PSAC) 的新架构，是首个无需使用 RNN 的模型。",
    "inLanguage" : "zh-cn",
    "author" : "Jonathan Wang",
    "creator" : "Jonathan Wang",
    "publisher": "Jonathan Wang",
    "accountablePerson" : "Jonathan Wang",
    "copyrightHolder" : "Jonathan Wang",
    "copyrightYear" : "2021",
    "datePublished": "2021-05-29 14:57:33 \u002b0800 CST",
    "dateModified" : "2021-05-29 14:57:33 \u002b0800 CST",
    "url" : "http:\/\/wzj.life\/2021\/prn7\/",
    "wordCount" : "423",
    "keywords" : [ "paper reading","cv","notes","vqa", "Zijie Wang`s Blog"]
}
</script>

  
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    
        <div class="top-scroll-bar"></div>
    
    <div class="container">
        <div class="navbar-header header-logo">
            
            <span class="logo_mark" >></span>
            <a href="http://wzj.life">
                <span class="logo_text" >$ cd /home/ </span>
                <span class="logo_cursor" ></span>
            </a>
            
        </div>
        
            
            
        
        <div class="navbar-right">
                
                <span class="menu">
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                </span>
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     
         <div class="top-scroll-bar"></div>
     
     <div class="container">
        <div class="navbar-header">
            <div class="header-logo">
                
                    <span class="logo_mark">></span>
                    <a href="http://wzj.life">
                        <span class="logo_text">$ cd /home/ </span>
                        <span class="logo_cursor"></span>
                </a>
                
            </div>
            <div class="navbar-right">
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
                <div class="menu-toggle">
                    <span></span><span></span><span></span>
                </div>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>

    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019)</h1>
        <div class="post-meta">
                
                Written by <a itemprop="name" href="http://wzj.life" rel="author">Jonathan Wang</a> 
                <span class="post-time">
                on <time datetime=2021-05-29 itemprop="datePublished">May 29, 2021</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="http://wzj.life/categories/paper-reading-notes/"> Paper Reading Notes </a>
                        
                </span>
                <span class="post-word-count">, 423 words</span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          <h1 id="beyond-rnns-positional-self-attention-with-co-attention-for-video-question-answering-aaai-2019">Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering (AAAI 2019)</h1>
<h2 id="rnn--attention-方法问题">RNN + Attention 方法问题</h2>
<ul>
<li>耗时</li>
<li>由于 RNN 的特点，难以建模长距离依赖关系</li>
</ul>
<p>本文提出了一个名为 Positional Self-Attention with Co-attention (PSAC) 的新架构，是首个无需使用 RNN 的模型。</p>
<p><img src="/images/2021/PRN7/1.png" alt="Fig 1"></p>
<h2 id="positional-self-attention-block">Positional Self-Attention Block</h2>
<p>取代 RNN 以更好捕捉长距离依赖关系和位置信息。</p>
<p>将序列化的特征 \(F \in \mathbb{R}^{n \times d_{}}\)同时视作 query、key 和 value，采用如下的 scaled dot product attention:</p>
<p>\[SPDA(F^Q, F^K, F^V) = softmax(\frac{F^K(F^Q)^T}{\sqrt{d_k}}) F^V.\]</p>
<p>而后再加上跳连和 layer normalization。</p>
<p>自注意力能够确保计算效率并建模长距离依赖关系，但是忽略了输入序列的位置信息。为了弥补这一缺陷，本文定义了一个位置矩阵 \(P \in \mathbb{R}^{n \times d_{k}}\)，对 \(F\) 的位置信息进行编码:</p>
<p>\[P_{pos, 2j} = sin(pos/10000^{2j/d_{k}}),\]</p>
<p>\[P_{pos, 2j+1} = cos(pos/10000^{2j/d_{k}}).\]</p>
<p>最终特征由 P 和 layer normalization 输出相加后经两个卷积层和一个中间的 ReLU 层处理得到。</p>
<p>由上述方法可直接得到视频的位置自注意力特征，文本方面则可按两种层级描述信息：word + character，C 卷积后与 W 拼接得到问题编码，进而用 depthwise 卷及层进一步融合，最后得到位置自注意力特征。</p>
<p>其中各个单词得到 300-D 向量，各个字符得到 64-D 向量。</p>
<h2 id="video-question-co-attention-layer">Video-Question Co-Attention Layer</h2>
<p>两个方向，与 Co-attention 类似。</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Jonathan Wang </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=http://wzj.life/2021/prn7/>http://wzj.life/2021/prn7/</span>
            </p>
            <p>
                <span>Ads:</span>
                <span>欢迎参与<a href="https://www.didiyun.com" target="_blank" style="text-decoration:underline">滴滴云AI大师活动</a>购买 GPU / vGPU / 机器学习产品，使用我的滴滴AI大师码 <b style="color:red">0724</b> 可享受 <b>9 折</b>优惠！</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="http://wzj.life/tags/paper-reading/">
                    #paper reading</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/cv/">
                    #cv</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/notes/">
                    #notes</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/vqa/">
                    #vqa</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="http://wzj.life">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="http://wzj.life/2021/prn6/" class="prev" rel="prev" title="[论文阅读笔记 -- 跨模态检索] Consensus-Aware Visual-Semantic Embedding (ECCV 2020)"><i class="iconfont icon-left"></i>&nbsp;[论文阅读笔记 -- 跨模态检索] Consensus-Aware Visual-Semantic Embedding (ECCV 2020)</a>
         
        
        <a href="http://wzj.life/2021/prn8/" class="next" rel="next" title="[论文阅读笔记 -- VQA] Location-Aware Graph Convolutional Networks (AAAI 2020)">[论文阅读笔记 -- VQA] Location-Aware Graph Convolutional Networks (AAAI 2020)&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
    <h5 id="wc" style="font-size: 1rem;text-align: center;">500 Words|Read in about 1 Min|本文总阅读量<span id="busuanzi_value_page_pv"></span>次</h5>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2020 - 2023</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="http://wzj.life">Jonathan Wang</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
          <span id="busuanzi_container_site_pv">
              本站访问量：<span id="busuanzi_value_site_pv"></span>次
          </span>
    </div>
</footer>













    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  






     </div>
  </body>
</html>
