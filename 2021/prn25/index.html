<!DOCTYPE html>
<html lang="zh-cn">
  <head>
  
  <link rel="stylesheet" href="/js/katex/katex.min.css" >
  <script src="/js/katex/katex.min.js" > </script>
  <script src="/js/katex/contrib/auto-render.min.js" ></script>
  <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body);
      });
  </script>

  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Jonathan Wang">
  
  
  
  <link rel="prev" href="http://wzj.life/2021/prn24/" />
  <link rel="next" href="http://wzj.life/2021/bg24/" />
  <link rel="canonical" href="http://wzj.life/2021/prn25/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           [论文阅读笔记 -- 频域 / 图网络] Spectral Graph Attention Network (2020) | Zijie Wang`s Blog
       
  </title>
  <meta name="title" content="[论文阅读笔记 -- 频域 / 图网络] Spectral Graph Attention Network (2020) | Zijie Wang`s Blog">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "http:\/\/wzj.life"
    },
    "articleSection" : "posts",
    "name" : "[论文阅读笔记 -- 频域 \/ 图网络] Spectral Graph Attention Network (2020)",
    "headline" : "[论文阅读笔记 -- 频域 \/ 图网络] Spectral Graph Attention Network (2020)",
    "description" : "2003.07450 Spectral Graph Attention Network (2020) 背景 图注意力网络 (Graph Attention Network, GAT) 通过引入注意力机制优化 GCN 的卷积过程。具体来说，在节点聚合 (node aggregation) 阶段，GAT 赋予各边一个自注意力权重，用于捕",
    "inLanguage" : "zh-cn",
    "author" : "Jonathan Wang",
    "creator" : "Jonathan Wang",
    "publisher": "Jonathan Wang",
    "accountablePerson" : "Jonathan Wang",
    "copyrightHolder" : "Jonathan Wang",
    "copyrightYear" : "2021",
    "datePublished": "2021-06-28 19:34:36 \u002b0800 CST",
    "dateModified" : "2021-06-28 19:34:36 \u002b0800 CST",
    "url" : "http:\/\/wzj.life\/2021\/prn25\/",
    "wordCount" : "2294",
    "keywords" : [ "paper reading","cv","notes","frequency","graph", "Zijie Wang`s Blog"]
}
</script>

  
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    
        <div class="top-scroll-bar"></div>
    
    <div class="container">
        <div class="navbar-header header-logo">
            
            <span class="logo_mark" >></span>
            <a href="http://wzj.life">
                <span class="logo_text" >$ cd /home/ </span>
                <span class="logo_cursor" ></span>
            </a>
            
        </div>
        
            
            
        
        <div class="navbar-right">
                
                <span class="menu">
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                </span>
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     
         <div class="top-scroll-bar"></div>
     
     <div class="container">
        <div class="navbar-header">
            <div class="header-logo">
                
                    <span class="logo_mark">></span>
                    <a href="http://wzj.life">
                        <span class="logo_text">$ cd /home/ </span>
                        <span class="logo_cursor"></span>
                </a>
                
            </div>
            <div class="navbar-right">
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
                <div class="menu-toggle">
                    <span></span><span></span><span></span>
                </div>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
        </div>
    </div>
</nav>

    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">[论文阅读笔记 -- 频域 / 图网络] Spectral Graph Attention Network (2020)</h1>
        <div class="post-meta">
                
                Written by <a itemprop="name" href="http://wzj.life" rel="author">Jonathan Wang</a> 
                <span class="post-time">
                on <time datetime=2021-06-28 itemprop="datePublished">June 28, 2021</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="http://wzj.life/categories/paper-reading-notes/"> Paper Reading Notes </a>
                        
                </span>
                <span class="post-word-count">, 2294 words</span>
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          <h1 id="200307450-spectral-graph-attention-network-2020">2003.07450 Spectral Graph Attention Network (2020)</h1>
<p><img src="/images/2021/PRN25/1.png" alt="Fig 1"></p>
<h2 id="背景">背景</h2>
<p>图注意力网络 (Graph Attention Network, GAT) 通过引入注意力机制优化 GCN 的卷积过程。具体来说，在节点聚合 (node aggregation) 阶段，GAT 赋予各边一个自注意力权重，用于捕捉与邻居节点之间的局部相似度。</p>
<p>GAT 及其相关变体以一种直接的方式考虑注意力，即在空域中学习边注意力。在这种情况下，这类注意力能够捕捉到图的局部结构，即来自邻居节点的信息，但其无法显式编码图的全局结构。此外为每条边计算注意力权重很低效，尤其是图较大的时候。</p>
<p>在计算机视觉中，一张自然图像可以被分解为低频成分和高频成分。低频成分包含变化平滑的结构，如背景部分；而高频成分描述变化较快的细节，如轮廓。</p>
<p>在图表征学习 (graph representation learning) 中，由于图信号处理 (graph signal processing, GSP) 提供了一种基于图中拉普拉斯矩阵升序特征值 (ascending ordered eigenvalues of Laplacian in graphs) 的方法，可以直接分解高低频成分，这一分解可以被更自然地观察到。</p>
<p>小的特征值对应的特征向量包含平滑变化的信号，使得邻居节点共享相似的值。相反，大的特征值对应的特征向量包含沿着边剧烈变化的信号。只用低频成分构建时，图倾向于保留簇 (cluster) 内信息；而只用高频成分构建时，图倾向于保留簇之间的信息。频域中的低频与高频成分可能正相应反应了图在空域中的局部与全局结构信息。</p>
<p>本文设计了一种频谱图注意力网络 (Spectral Graph Attention Network, SpGAT)，将注意力机制拓展到图的频域空间，从全局视角显式编码图的结构信息。</p>
<p>SpGAT 中选择图小波 (graph wavelets) 作为频谱的基 (spectral bases) 根据其索引分解为低频与高频成分。接着根据低频与高频成分分别构建两个卷积核，在卷积核上引入注意力机制捕捉其相应的重要性。最后用池化函数与激活函数产生输入。<br>
进而使用切比雪夫多项式逼近 (Chebyshev Polynomial approximation) 计算图的谱小波 (spectral wavelets of graphs)，并提出在大型图上更加高效的变体模型 SpGAT-Cheby。</p>
<p><img src="/images/2021/PRN25/2.png" alt="Fig 2"></p>
<p>除了理解为空域上的邻居节点聚合，原始的 GCN 也可以被看作是在频域上的图信号处理 (GSP)：</p>
<p>$$g_{\theta} \star x = Bg_{\theta}B^Tx,$$</p>
<p>其中 \(x\) 是每个节点上的信号，\(B = \{b_{1}, \cdots, b_{n}\}\) 是从图中提取的频谱基 (spectral bases)，\(g_{\theta} = diag(\theta)\) 是以 \(\theta\) 为参数的对角过滤器 (diagonal filter)。</p>
<p>基于上式，GCN 可以视为基于在一阶切比雪夫多项式逼近图上的傅利叶变换的谱图卷积 (spectral graph convolution based on the Fourier transform on graphs with first-order Chebyshev polynomial approximations)。</p>
<p>谱图卷积进一步分为两个阶段：</p>
<p>$$feature \ transformation: \ X = H\Theta^T,$$
$$graph \ convolution: \ H&rsquo; = \sigma(BFB^TX),$$</p>
<p>其中 \(F\) 是作为图卷积核的对角矩阵。在这个例子中 \(F = diag(\lambda_{1}, \cdots, \lambda_{n})\)，\(\{\lambda_{i}\}_{i=1}^n\) 是规范化图拉普拉斯矩阵 \(L = I - \hat{A}\) 的升序特征值，频谱基 \(B\) 为相应的特征向量。</p>
<h2 id="spgat-层的构建">SpGAT 层的构建</h2>
<p>从 GSP 视角，\(F\) 中的对角化值 \((f_{1}, \cdots, f_{n})\) 可以被看作图上的频率，将这些值根据其索引的小/大标记为低/高频。同时，\(B\) 中相应的频谱基即为低/高频成分。</p>
<p>首先将频谱基分成两组并改写上述两阶段公式：</p>
<p>$$feature \ transformation: \ X_{L} = H\Theta_{L}^T, \ X_{H} = H\Theta_{H}^T,$$
$$graph \ convolution: \ H&rsquo; = \sigma(AGG(B_{L}F_{L}B_{L}^TX_{L}, B_{H}F_{H}B_{H}^TX_{H})),$$</p>
<p>其中 \(B_{L} = \{b_{1}, \cdots, b_{d}\}, B_{H} = \{b_{d+1}, \cdots, b_{n}\}\) 分别为低/高频成分。式中的 \(F_{L}\) 和 \(F_{H}\) 可以被视为低/高频的重要性，因而本文通过采用再参数化技巧 (re-parameterization trick) 进一步引入可学习的注意力权重：</p>
<p>$$H&rsquo; = \sigma(AGG(B_{L}\alpha_{L}B_{L}^TX_{L}, B_{H}\alpha_{H}B_{H}^TX_{H})),$$</p>
<p>式中 \(\alpha_{*} = diag(\alpha_{*}, \cdots, \alpha_{*})\) 是两个由可学习注意力 \(\alpha_{L}\) 和 \(\alpha_{H}\) 参数化的对角矩阵 (等号左侧是矩阵，右侧是标量，写到这里发现有必要涉及符号加粗但是懒得改了所以标注一下)。为确保 \(\alpha_{*}\) 为正且可以比较，用 softmax 对齐进行归一化。</p>
<p>理论上有很多再参数化的方式，如关于频谱基的自注意力等。但是这类方法无法反应高低频成分的本质，而且会引入过多额外需要学习的参数。</p>
<h2 id="频谱基的选取">频谱基的选取</h2>
<p>频谱基的选取是 SpGAT 另一个重要问题。本文选择图小波作为频谱基，而非较为常见的傅里叶基。</p>
<p>谱图小波 \(\psi_{si}(\lambda)\) 定义为以节点 \(i\) 为中心的信号 \(x\) 在频域中调制产生的信号。对于一张图 \(G\)，图小波变换使用一组小波 \(\Psi_{s} = (\psi_{s1}(\lambda_{1}), \psi_{s2}(\lambda_{2}), \cdots, \psi_{sn}(\lambda_{n}))\) 作为基，谱图小波变换定义如下：</p>
<p>$$\Psi_{s}(\lambda) = Ug_{s}(\lambda)U^T,$$</p>
<p>其中 \(U\) 为归一化图拉普拉斯矩阵 \(L = I - \hat{A}\) 的特征向量，\(g_{s}(\lambda) = diag(g_{s}(\lambda_{1}), \cdots, g_{s}(\lambda_{n}))\) 是带有由超参数 \(s\) 控制尺度热核 (heat kernel) 的放缩矩阵 (scaling matrix)。</p>
<p>图小波的逆 \(\Psi_{s}^{-1}\) 可以通过将 \(\Psi_{s}(\lambda)\) 中的 \(g_{s}(\lambda)\) 替换为 \(g_{s}(-\lambda)\) 得到。图小波中较小的索引对应低频成分，反之亦然。</p>
<h3 id="谱图小波基相比傅里叶基的三个好处">谱图小波基相比傅里叶基的三个好处</h3>
<ul>
<li>对于现实场景中稀疏的网络，图小波基通常远比傅里叶基稀疏，悉数性使其在使用中计算效率更高。</li>
<li>在谱图小波中，由热核滤波器 (heat kernel filter) 得到的信号 \(\Psi_{s}\) 通常处于图上以及频域中的局部，可以通过调整 \(s\) 方便地控制局部邻域的范围，\(s\) 越小邻域越小。</li>
<li>由于在构建小波的过程中，特征值 \(\lambda\) 的信息会隐式包含在小波中，不会在再参数化过程中遇到信息损失问题。</li>
</ul>
<p>因而，使用图小波基 \(\Psi_{s}\) 的 SpGAT 层架构可以写作：</p>
<p>$$X = H\Theta^T,$$
$$H&rsquo; = \sigma(AGG(\Psi_{sL}\alpha_{L}\Psi_{sL}^{-1}X, \Psi_{sL}\alpha_{L}\Psi_{sL}^{-1}X)).$$</p>
<p>在上式中为了进一步降低参数复杂度，特征变换阶段的参数进行了共享，即令 \(\Theta_{L} = \Theta_{H} = \Theta\)。</p>
<p>通过显式地结合高低频特征，SpGAT 可以更好地处理全局信息。</p>
<h2 id="利用切比雪夫多项式对谱小波快速逼近">利用切比雪夫多项式对谱小波快速逼近</h2>
<p>上一节中图谱小波变换的计算复杂度较高，因而采用切比雪夫多项式在不做特征分解的情况下快速逼近谱图小波。</p>
<h3 id="一条引理">一条引理</h3>
<p>\(s\) 为热核滤波器 \(g_{s}(\lambda) = e^{-\lambda s}\) 固定的放缩参数，\(M\) 是对放缩的小波所做切比雪夫多项式逼近的度 (\(M\) 越大逼近精度越高，但同时计算复杂度也越高)，图小波如下得到：</p>
<p>$$\Psi_{s}(\lambda) = \frac{1}{2}c_{0,s} + \sum_{i=1}^M c_{i,s}T_{i}(\widetilde{L}),$$
$$c_{i,s} = 2e^{-s}J_{i}(-s),$$</p>
<p>其中 \(\widetilde{L} = \frac{2}{\lambda_{max}}L - I_{n}\)，\(T_{i}(\widetilde{L})\) 是第 \(i\) 阶切比雪夫多项式逼近，\(J_{i}(-s)\) 是第一类 Bessel 函数。</p>
<p>为了进一步加速计算，为 Bessel 函数 \(J_{i}(s)\) 构建一张查询表。将使用到切比雪夫多项式逼近的 SpGAT 称为 SpGAT-Cheby。</p>
<p><img src="/images/2021/PRN25/3.png" alt="Fig 3"></p>
<h2 id="高低频边界-d-的选取">高低频边界 \(d\) 的选取</h2>
<p>由图 3 可以看出在几个数据集上做好的表现都在 \(d\) 较小时得到，换句话说 SpGAT 中只有一小部分频率成分需要为处理为低频成分。</p>
<h2 id="高低频成分的影响">高低频成分的影响</h2>
<p>文中通过在测试阶段人为将 \(\alpha_{L}\) 或 \(\alpha_{H}\) 设为 0 观察图中高低频成分对分类精度的影响。</p>
<p><img src="/images/2021/PRN25/T3.png" alt="Tab 3"></p>
<h2 id="特征可视化">特征可视化</h2>
<p><img src="/images/2021/PRN25/4.png" alt="Fig 4"></p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Jonathan Wang </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=http://wzj.life/2021/prn25/>http://wzj.life/2021/prn25/</span>
            </p>
            <p>
                <span>Ads:</span>
                <span>欢迎参与<a href="https://www.didiyun.com" target="_blank" style="text-decoration:underline">滴滴云AI大师活动</a>购买 GPU / vGPU / 机器学习产品，使用我的滴滴AI大师码 <b style="color:red">0724</b> 可享受 <b>9 折</b>优惠！</span>
            </p>
            
             
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="http://wzj.life/tags/paper-reading/">
                    #paper reading</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/cv/">
                    #cv</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/notes/">
                    #notes</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/frequency/">
                    #frequency</a></span>
            
            <span class="tag"><a href="http://wzj.life/tags/graph/">
                    #graph</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="http://wzj.life">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="http://wzj.life/2021/prn24/" class="prev" rel="prev" title="[论文阅读笔记 -- 带噪跨模态检索] Learning Cross-Modal Retrieval With Noisy Labels (CVPR 2021)"><i class="iconfont icon-left"></i>&nbsp;[论文阅读笔记 -- 带噪跨模态检索] Learning Cross-Modal Retrieval With Noisy Labels (CVPR 2021)</a>
         
        
        <a href="http://wzj.life/2021/bg24/" class="next" rel="next" title="壁纸分享[24]">壁纸分享[24]&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
    <h5 id="wc" style="font-size: 1rem;text-align: center;">2300 Words|Read in about 5 Min|本文总阅读量<span id="busuanzi_value_page_pv"></span>次</h5>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2020 - 2023</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i> 
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="http://wzj.life">Jonathan Wang</a> | </span> 
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
          <span id="busuanzi_container_site_pv">
              本站访问量：<span id="busuanzi_value_site_pv"></span>次
          </span>
    </div>
</footer>













    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  






     </div>
  </body>
</html>
