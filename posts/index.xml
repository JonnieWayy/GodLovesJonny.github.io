<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jonathan`s Blog</title>
    <link>http://jonathanwayy.xyz/posts/</link>
    <description>Recent content in Posts on Jonathan`s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>All rights reserved - 2020</copyright>
    <lastBuildDate>Mon, 07 Mar 2022 23:17:29 +0800</lastBuildDate><atom:link href="http://jonathanwayy.xyz/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[KLI] Klingon Vocabulary</title>
      <link>http://jonathanwayy.xyz/2020/kliv/</link>
      <pubDate>Fri, 24 Jan 2020 22:35:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kliv/</guid>
      <description>   Kli Eng     HISlaH yes   ghobe&#39; no   je and   &amp;lsquo;ej and   &amp;lsquo;ach but   DaH now   wa&amp;rsquo;leS tomorrow   DaHjaj today   wa&amp;rsquo;Hu&amp;rsquo; yesterday   vay&amp;rsquo; anyone, anybody   pagh no one, nobody   &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash; &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-   tlhIngan Klingon   tera&amp;rsquo;ngan Terran   Hol language   batlh honor   Qapla&#39; success   pong name   puq child   loD man   be&#39; woman   Duj ship   qach building   Dlvl&#39; English, federation, the Federation   Suvwl&#39; fighter, warroir   jagh enemy   mang soldier   muSwl&#39; hater   qoq robot   yuch chocolate   mu&#39; word   paq book   ram night   nagh stone   Ha&amp;rsquo;DIbaH meat, animal   Sargh sark   &amp;lsquo;avwl&amp;rsquo; guard   &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash; &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-   &amp;lsquo;oH is   jatlh speak   Qong sleep   qet run   yIt walk   Sup jump   yIn live, be alive   Hegh die   vum work   yaj understand   Suv fight   Ho&amp;rsquo; admire   vuv respect   HoH kill   legh see   voq trust   muS hate   plch blame   tl&#39; repair   Hub&#39; defend   Qal swim   ghaj have   laD read   &amp;lsquo;ol verify   SaH care   ghov recognize   Qoy hear   Suj disturb   boQ assist   &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash; &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-   mach little, small   tIn big   woch tall   val smart   Qlp stupid   Qup young   maw&amp;rsquo; crazy   Daj interesting   &amp;lsquo;IH beautiful, handsome   Dun wonderful, great   HoS strong   chuS noisy    </description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning by Aligning: VI ReID Using CM Correspondences (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn206/</link>
      <pubDate>Mon, 07 Mar 2022 23:17:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn206/</guid>
      <description>Learning by Aligning: Visible-Infrared Person Re-Identification Using Cross-Modal Correspondences (ICCV 2021) 开源代码传送门 概述 本文旨在利用跨模态图像之间的密集相关性。 本文方法 特征提取 浅层参数独立，深层参数共享。 CMAlign Module 用于双向对齐</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Multi-Scale Body-Part Mask Guided Attention for ReID (CVPRW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn205/</link>
      <pubDate>Mon, 07 Mar 2022 17:40:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn205/</guid>
      <description>Multi-Scale Body-Part Mask Guided Attention for Person Re-identification (CVPRW 2019) 概述 本文提出一种 Multi-scale Body-part Mask Guided Attention Network (MMGA) 架构。 整体架构 注意力模块 可视化示例</description>
    </item>
    
    <item>
      <title>壁纸分享[51]</title>
      <link>http://jonathanwayy.xyz/2022/bg51/</link>
      <pubDate>Mon, 07 Mar 2022 17:36:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg51/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Complementary Features Learning for ATReID (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn204/</link>
      <pubDate>Sun, 06 Mar 2022 12:56:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn204/</guid>
      <description>Pose-Guided Complementary Features Learning for Amur Tiger Re-Identification (ICCVW 2019) 开源代码传送门 概述 本文将老虎的姿态简化为头部朝右和头部朝左两种，将姿态分类作为子任务引入 ReID 特征学习架构。 提出一种多分支结</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Part-Pose Guided Amur Tiger Re-Identification (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn203/</link>
      <pubDate>Sat, 05 Mar 2022 22:07:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn203/</guid>
      <description>Part-Pose Guided Amur Tiger Re-Identification (ICCVW 2019) 开源代码传送门 概述 老虎重识别，2019 Computer Vision for Wild life Conservation Challenge (CVWC2019) Plain ReID 和 Wild ReID 赛道第一名。 Tiger ReID 相比 Person ReID 的差异 姿态变化更多 遮挡更多，复杂的自然</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] A Strong Baseline for Tiger Re-ID and its Bag of Tricks (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn202/</link>
      <pubDate>Sat, 05 Mar 2022 18:20:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn202/</guid>
      <description>A Strong Baseline for Tiger Re-ID and its Bag of Tricks (ICCVW 2019) 开源代码传送门 概述 老虎重识别任务，CVWC 2019 挑战赛 Plain ReID 赛道第三名。 本文方法 图像变换到 \(256 \times 256\)，分别对特征图做</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] ATRW: A Benchmark for Amur Tiger ReID in the Wild (MM 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn201/</link>
      <pubDate>Sat, 05 Mar 2022 15:49:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn201/</guid>
      <description>1906.05586 ATRW: A Benchmark for Amur Tiger Re-identification in the Wild (MM 2020) 数据集传送门 概述 老虎重识别任务，构建了 Amur Tiger Re-identification in the Wild (ATRW) 数据集。 通过条纹信息分辨 ID，将不同侧的老虎视为不同的样本。 数</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose Guided Gated Fusion for Person Re-identification (WACV 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn200/</link>
      <pubDate>Fri, 04 Mar 2022 18:14:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn200/</guid>
      <description>Pose Guided Gated Fusion for Person Re-identification (WACV 2020) 概述 本文提出一种新的 ReID 架构，包含一个外观学习分支和一个姿态估计分支，二者由一个门控融合网络整合到一起，从骨架网络中间层动态</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FD-GAN: Pose-guided Feature Distilling GAN (NeurIPS 2018)</title>
      <link>http://jonathanwayy.xyz/2022/prn199/</link>
      <pubDate>Fri, 04 Mar 2022 17:06:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn199/</guid>
      <description>FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification (NeurIPS 2018) 开源代码传送门 概述 本文提出一种特征蒸馏对抗生成网络 (Feature Distilling Generative Adversarial Network, FD-GAN)，在姿态变换情况下保留身份信息而不增加推断时</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Copy And Paste Method Based on Pose for Re-identification (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn198/</link>
      <pubDate>Fri, 04 Mar 2022 14:56:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn198/</guid>
      <description>2107.10479 Copy And Paste Method Based on Pose for Re-identification (2021) 概述 本文提出 Multiple Scenarios ReID 任务，有更复杂的背景、遮挡和姿态。 本文设计了一种基于姿态的复制粘帖方法 (Copy and Paste method based on Pose, CPP)，用于构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Visible Part Matching for Occluded ReID (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn197/</link>
      <pubDate>Thu, 03 Mar 2022 17:36:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn197/</guid>
      <description>Pose-guided Visible Part Matching for Occluded Person ReID (CVPR 2020) 开源代码传送门 概述 本文提出一种姿态指导的可见部分匹配网络 (Pose-guided Visible Part Matching network, PVPM)，以自学习形式挖掘可见分数，包含两个主要部件</description>
    </item>
    
    <item>
      <title>壁纸分享[50]</title>
      <link>http://jonathanwayy.xyz/2022/bg50/</link>
      <pubDate>Tue, 01 Mar 2022 19:46:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg50/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[43] Linux 命令出现 Argument List Too Long 问题的两种解决办法</title>
      <link>http://jonathanwayy.xyz/2022/blwl43/</link>
      <pubDate>Sun, 27 Feb 2022 15:47:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/blwl43/</guid>
      <description>问题描述 Linux 下在使用 cp、mv、rm 等命令时出现 Argument list too long 错误，命令执行失败。 问题原因 命令涉及的文件数目过多，导致命令参数列表过长，无法执行。 解</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Efficient Online Label Consistent Hashing (ICME 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn196/</link>
      <pubDate>Thu, 24 Feb 2022 23:10:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn196/</guid>
      <description>Efficient Online Label Consistent Hashing for Large-Scale Cross-Modal Retrieval (ICME 2021) 概述 本文关注在线跨模态哈希问题，提出一种在线标签一致哈希方法 (Online Label Consistent Hashing approach, OLCH)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] HAVANA: Hierarchical and Variation-Normalized Autoencoder (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn195/</link>
      <pubDate>Tue, 22 Feb 2022 10:05:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn195/</guid>
      <description>2101.02568 HAVANA: Hierarchical and Variation-Normalized Autoencoder for Person Re-identification (2021) 概述 ReID 任务的一大困难在于同 ID 行人图像之间存在的差异，本文提出 HierArchical and VAriation-Normalized Autoencoder (HAVANA) 架构，在无需额外数据标注的情况下处理这一问题，其包</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Robust Person ReID by Modelling Feature Uncertainty (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn194/</link>
      <pubDate>Mon, 21 Feb 2022 12:55:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn194/</guid>
      <description>Robust Person Re-identification by Modelling Feature Uncertainty (ICCV 2019) 开源代码传送门 概述 本文关注如何用带噪训练数据学习一个健壮的 ReID 模型，数据噪声可以分为两类： Label Noise Data Outliers 本文提出 DistributionNet 以应对这两种噪声</description>
    </item>
    
    <item>
      <title>壁纸分享[49]</title>
      <link>http://jonathanwayy.xyz/2022/bg49/</link>
      <pubDate>Mon, 21 Feb 2022 12:50:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg49/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ASR / 终身学习] Towards Lifelong Learning of End-to-end ASR (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn193/</link>
      <pubDate>Sat, 19 Feb 2022 21:06:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn193/</guid>
      <description>2104.01616 Towards Lifelong Learning of End-to-end ASR (2021) 概述 终身学习 (LLL) 可分为三类： Regularization-based Methods: 通过在损失函数中加入正则化项来加固模型中的关键参数 Architecture-based Methods: 为各任务分配一定的模型容量，或扩展模型以</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 增量学习] Striking a Balance between Stability-Plasticity for CIL (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn192/</link>
      <pubDate>Sat, 19 Feb 2022 16:12:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn192/</guid>
      <description>Striking a Balance between Stability and Plasticity for Class-Incremental Learning (ICCV 2021) 概述 类增量学习任务 (Class-Incremental Learning, CIL)。 适应新类要求模型具有可塑性 (plasticity)，而不忘记学到的旧类别要求稳定性 (</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Adaptive CM Prototypes for Cross-Domain VLR (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn191/</link>
      <pubDate>Wed, 16 Feb 2022 22:09:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn191/</guid>
      <description>Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval (CVPR 2021) 概述 将在带标签源域上学习到的模型迁移到不带标签的目标域的任务被称为无监督域自适应 (UDA)，本文研究 UDA 设定下的跨模态检索问</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Generalising without Forgetting for Lifelong Person ReID (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn190/</link>
      <pubDate>Tue, 15 Feb 2022 15:53:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn190/</guid>
      <description>Generalising without Forgetting for Lifelong Person Re-Identification (AAAI 2021) 概述 本文关注 Lifelong ReID 任务，与传统终身学习任务相比有三个主要的不同及困难： 训练与测试类别不重叠，属于 ZSL 问题 数据序列来自不同的域 各</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Object ReID Using Teacher-Like and Light Students (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn189/</link>
      <pubDate>Tue, 15 Feb 2022 13:35:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn189/</guid>
      <description>Object Re-identification Using Teacher-Like and Light Students (BMVC 2021) 概述 本文提出一种联合蒸馏与剪枝方法 (Joint Distillation and Pruning method, JDP) 以学习与教师相似且轻量的学生模型 (Teacher-Like and Light students, TTL students)，其结合了知识蒸</description>
    </item>
    
    <item>
      <title>壁纸分享[48]</title>
      <link>http://jonathanwayy.xyz/2022/bg48/</link>
      <pubDate>Mon, 14 Feb 2022 23:24:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg48/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Lifelong ReID via Adaptive Knowledge Accumulation (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn188/</link>
      <pubDate>Sun, 13 Feb 2022 20:25:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn188/</guid>
      <description>Lifelong Person Re-Identification via Adaptive Knowledge Accumulation (CVPR 2021) 开源代码传送门 概述 本文提出终身行人重识别任务 (Lifelong Person Re-identification, LReID)，设计了一种自适应知识积累架构 (Adaptive Knowledge Accumulation framework, AKA)，从旧的域持续</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Continual Learning in Cross-modal Retrieval (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn187/</link>
      <pubDate>Sun, 13 Feb 2022 15:51:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn187/</guid>
      <description>Continual Learning in Cross-modal Retrieval (CVPRW 2021) 概述 本文将终身学习与跨模态检索相结合。 终身学习的一个困境在于所谓的灾难性遗忘 (catastrophic forgetting)，当前一种主流方法是给损失</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Multi-level Alignment Network for DA CMR (NC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn186/</link>
      <pubDate>Sat, 12 Feb 2022 18:05:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn186/</guid>
      <description>Multi-level Alignment Network for Domain Adaptive Cross-modal Retrieval (Neurocomputing 2021) 概述 本文关注域自适应跨模态检索问题，提出一种多级对齐网络 (Multi-level Alignment Network, MAN)，其包含一个视觉编码器、一个文本编码器和一个公共空</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-Modal Cross-Domain Moment Alignment Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn185/</link>
      <pubDate>Fri, 11 Feb 2022 15:51:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn185/</guid>
      <description>Cross-Modal Cross-Domain Moment Alignment Network for Person Search (CVPR 2020) 概述 本文最早提出跨模态跨域的文本行人检索任务，设计了一种时刻对齐网络 (Moment Alignment Network, MAN)，其包含三种对齐模块： Domain Alignment (DA) Cross-modal Alignment (CA) Exemplar Alignment</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Person Search by Text Attribute Query as ZSL (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn184/</link>
      <pubDate>Thu, 10 Feb 2022 13:47:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn184/</guid>
      <description>Person Search by Text Attribute Query as Zero-Shot Learning (ICCV 2019) 概述 本文最早将基于文本属性的行人检索任务定义为零样本学习问题，其 ZSL 设定上的主要困难在于粒度更细、图像噪声更多、行人类别</description>
    </item>
    
    <item>
      <title>壁纸分享[47]</title>
      <link>http://jonathanwayy.xyz/2022/bg47/</link>
      <pubDate>Tue, 08 Feb 2022 17:40:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg47/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] MVB: A Large-Scale Dataset for Baggage ReID (PRCV 2019)</title>
      <link>http://jonathanwayy.xyz/2022/prn183/</link>
      <pubDate>Sun, 06 Feb 2022 18:08:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn183/</guid>
      <description>MVB: A Large-Scale Dataset for Baggage Re-Identification and Merged Siamese Networks (PRCV 2019) 开源代码传送门 概述 行李 ReID 任务，本文构建了一个大规模的新数据集，称为 MVB (Multi View Baggage)，并提出一种基线模型，称为</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 哈希] Faster Person Re-Identification (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn182/</link>
      <pubDate>Fri, 04 Feb 2022 16:55:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn182/</guid>
      <description>Faster Person Re-Identification (ECCV 2020) 开源代码传送门 概述 ReID 任务与一般的图像任务相比具有其特殊性，属于开放集合中实例级别的匹配，训练集与测试集的类别 (ID) 不同，这导致了需要很</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch 修改官方预训练模型输入通道数</title>
      <link>http://jonathanwayy.xyz/2022/ldp_pytorch_resnet_input/</link>
      <pubDate>Thu, 03 Feb 2022 15:48:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/ldp_pytorch_resnet_input/</guid>
      <description>有时需要修改预训练模型的输入通道数，在此记录一下一种可行的方法。 首先加载需要修改的预训练模型，查看一下模型的第一层，以 ResNet-50 为例： import torchvision.models as models backbone = models.resnet101(pretrained=False)</description>
    </item>
    
    <item>
      <title>壁纸分享[46]</title>
      <link>http://jonathanwayy.xyz/2022/bg46/</link>
      <pubDate>Tue, 01 Feb 2022 14:42:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg46/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Hashing Person Re-ID with Self-distilling Smooth Relaxation (NC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn181/</link>
      <pubDate>Sun, 30 Jan 2022 22:02:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn181/</guid>
      <description>Hashing Person Re-ID with Self-distilling Smooth Relaxation (Neurocomputing 2021) 概述 影响哈希 ReID 表现的两大因素： 特征表征：与非哈希方法的浮点特征相比，哈希编码在表征能力上具有内在的劣势 哈希松弛度：为了能够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像检索] Self-Supervised Product Quantization for Uns. IR (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn180/</link>
      <pubDate>Sun, 30 Jan 2022 14:47:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn180/</guid>
      <description>Self-Supervised Product Quantization for Deep Unsupervised Image Retrieval (ICCV 2021) 开源代码传送门 概述 本文提出首个无监督端到端基于量化的图像检索方法，称为 Self-supervised Product Quantization (SPQ) Network，联合学习特征提取器和编码。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Divide-and-Merge the Embedding Space (Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn179/</link>
      <pubDate>Sat, 29 Jan 2022 14:55:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn179/</guid>
      <description>Divide-and-Merge the Embedding Space for Cross-modality Person Search (Neurocomputing 2021) 概述 本文提出一种分治嵌入学习架构 (Divide-and-Merge Embedding Learning Framework, DME)，关注两方面： 如何提取健壮的局部表征，而避免产生无意义信息 如何有效合并多</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Tiled SE: Channel Att. With Local Spatial Context (ICCVW 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn178/</link>
      <pubDate>Thu, 27 Jan 2022 18:06:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn178/</guid>
      <description>Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context (ICCVW 2021) 概述 旨在分析有效的通道注意力所需的最小空间上下文。 本文基于 SENet 提出一种 Tiled Squeeze-and-Excite (TSE) 注意力。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Short Range Correlation Transformer for Occluded Person ReID (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn177/</link>
      <pubDate>Mon, 24 Jan 2022 14:16:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn177/</guid>
      <description>2201.01090 Short Range Correlation Transformer for Occluded Person Re-Identification (2022) 概述 Vision Transformer 在有遮挡的情况下并不擅长捕捉局部特征，本文提出一种基于 Vision Transformer 包含三种模块的 PFT 模型，以提升 patch 序列的短距离相关性并提取</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 知识蒸馏] SimReg: Regression as a Simple Yet Effective Tool (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn176/</link>
      <pubDate>Sun, 23 Jan 2022 14:22:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn176/</guid>
      <description>2201.05131 SimReg: Regression as a Simple Yet Effective Tool for Self-supervised Knowledge Distillation (BMVC 2021) 开源代码传送门 概述 本文关注自监督模型的蒸馏，发现 backbone 输出的特征比预测头最后一层输出的特征能更好地与教师模型相匹配</description>
    </item>
    
    <item>
      <title>壁纸分享[45]</title>
      <link>http://jonathanwayy.xyz/2022/bg45/</link>
      <pubDate>Sat, 22 Jan 2022 20:16:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg45/</guid>
      <description></description>
    </item>
    
    <item>
      <title>炼丹杂记 -- GeM Pooling 的 Pytorch 实现</title>
      <link>http://jonathanwayy.xyz/2022/ldp_gempooling/</link>
      <pubDate>Fri, 21 Jan 2022 23:21:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/ldp_gempooling/</guid>
      <description>记录一下 Generalized Mean Pooling (GeM 池化) 的一种 PyTorch 实现方式。 定义 GeM 池化公式定义如下： $$f_{g, c} = (\frac{1}{hw} \sum_{(i, j)} f_{4, (c, i, j)}^p)^{1/p}_{c = 1, 2, \dots, C},$$ 其中超参数 \(p &amp;gt; 0\)，默认设为 3.0，\(f_</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Explainable ReID With Attribute-Guided Metric Distillation (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn175/</link>
      <pubDate>Fri, 21 Jan 2022 14:49:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn175/</guid>
      <description>Explainable Person Re-Identification With Attribute-Guided Metric Distillation (ICCV 2021) 开源代码传送门 概述 旨在借助语义属性学习一个解释器，以回答如下两个问题： 是什么属性使两个人不同？ 各属性对差异有多大的影响？ 本</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像检索] DOLG: Deep Orthogonal Fusion of Local Global Feat. (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn174/</link>
      <pubDate>Thu, 20 Jan 2022 17:48:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn174/</guid>
      <description>DOLG: Single-Stage Image Retrieval With Deep Orthogonal Fusion of Local and Global Features (ICCV 2021) 开源代码传送门 (PaddlePaddle) 概述 本文提出一种深度正交局部与全局特征融合模型 (Deep Orthogonal Local and Global feature fusion model, DOLG)，由一个局部分支和一个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parsing-based View-aware Embedding Network for VReID (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn173/</link>
      <pubDate>Tue, 18 Jan 2022 14:44:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn173/</guid>
      <description>Parsing-based View-aware Embedding Network for Vehicle Re-Identification (CVPR 2020) 概述 车辆 ReID 任务。 本文提出一种基于解析的视角可知的嵌入网络 (Parsing-based View-aware Embedding Network, PVEN)，包含三个部分： vehicle part parser view-aware feature alignent common-visible feature enhancement 本文方法 Vehicle Part Parser</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] On Exploring Pose Estimation as an Auxiliary Learning Task (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn172/</link>
      <pubDate>Sun, 16 Jan 2022 20:46:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn172/</guid>
      <description>2201.03859 On Exploring Pose Estimation as an Auxiliary Learning Task for Visible-Infrared Person Re-identification (2022) 开源代码传送门 概述 本文提出一种双分支的 VI-ReID 架构，通过联合学习一个姿态估计的辅助任务和一个行人 ReID 的主任务，提取模态</description>
    </item>
    
    <item>
      <title>壁纸分享[44]</title>
      <link>http://jonathanwayy.xyz/2022/bg44/</link>
      <pubDate>Sat, 15 Jan 2022 20:40:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg44/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 人脸识别] End2End OFR by Masking Corrupted Features (TPAMI 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn171/</link>
      <pubDate>Fri, 14 Jan 2022 16:38:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn171/</guid>
      <description>End2End Occluded Face Recognition by Masking Corrupted Features (TPAMI 2021) 开源代码传送门 概述 本文关注带遮挡的人脸识别问题。 主要有两类应对遮挡的思路： 恢复 (Recovering): 先恢复被遮挡的面部，再进行识别，但恢复面</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Masking Modalities for Cross-modal Video Retrieval (WACV 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn170/</link>
      <pubDate>Thu, 13 Jan 2022 14:33:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn170/</guid>
      <description>Masking Modalities for Cross-modal Video Retrieval (WACV 2022) 概述 通过自然语言检索视频。 本文提出一种新的预训练策略，从教学视频中学习多模态融合。预训练过程中使用一种模态掩码策略 (modality masking str</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Integrating Information Theory and Advers. Learning (PR 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn169/</link>
      <pubDate>Thu, 13 Jan 2022 13:21:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn169/</guid>
      <description>Integrating Information Theory and Adversarial Learning for Cross-modal Retrieval (PR 2021) 概述 本文将香农信息论与对抗学习相结合，以对抗的方式结合信息熵预测器与模态分类器。 本文方法 信息熵与模态不确定性 用信息熵衡</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Fusion-Attention Network for Person Search with Language (PRL 2018)</title>
      <link>http://jonathanwayy.xyz/2022/prn168/</link>
      <pubDate>Wed, 12 Jan 2022 21:10:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn168/</guid>
      <description>Fusion-Attention Network for Person Search with Free-form Natural Language (PRL 2018) 概述 这个课题上比较早的一篇文章，提出一种描述增强的融合注意力网络 (Description-Strengthened and Fusion-Attention Network, DSFA-Net)，包含一个融合子网络和一个注</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Clustering Active Learning for Person ReID (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn167/</link>
      <pubDate>Wed, 12 Jan 2022 15:46:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn167/</guid>
      <description>2112.13308 Unsupervised Clustering Active Learning for Person Re-identification (BMVC 2021) 概述 本文提出一种无监督聚类主动学习模型 (Unsupervised Clustering Active Learning model, UCAL)，结合无监督学习与主动学习的优势。 基本无监督聚类模型 选择基于 DBSCAN</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Transformer based LP Search with Multiple Region Slicing (TCSVT 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn166/</link>
      <pubDate>Wed, 12 Jan 2022 15:12:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn166/</guid>
      <description>Transformer based Language-Person Search with Multiple Region Slicing (TCSVT 2021) 概述 本文提出一种基于 Transformer 的语言-行人搜索架构，提出两种新的分割方式，分为重叠分割 (Overlapped Slicing, OS) 与基于关键点的分割 (Key-point-based Slicing)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Multi-Domain Joint Training for Person Re-Identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn165/</link>
      <pubDate>Wed, 12 Jan 2022 14:20:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn165/</guid>
      <description>2201.01983 Multi-Domain Joint Training for Person Re-Identification (2022) 概述 本文发现多个域联合训练得到的 ReID 表现比独立训练各个域要差，称为域冲突问题 (domain conflict problem)，域冲突可能来自于三种因素： 数</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Quality-aware Part Models for Occluded Person Re-identification (2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn164/</link>
      <pubDate>Tue, 11 Jan 2022 13:17:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn164/</guid>
      <description>2201.00107 Quality-aware Part Models for Occluded Person Re-identification (2022) 概述 本文提出一种称为 Quality-aware Part Models (QPM) 的方法以解决遮挡 ReID 问题，其包含一个部分特征学习分支和一个全局特征学习分支。 Joint Learning Part Feature and Quality Scores Part Feature Extractor</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Unsupervised Attention Based Instance Discri. Learning (WACV 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn163/</link>
      <pubDate>Mon, 10 Jan 2022 12:09:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn163/</guid>
      <description>Unsupervised Attention Based Instance Discriminative Learning for Person Re-Identification (WACV 2022) 开源代码传送门 概述 本文提出一种组注意力模块 (grouped attention module, GAM) 以处理无监督 ReID 问题。 本文方法 Grouped Attention Module (GAM) 分为通道注意力和空间注意力两部分</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Text-Based Person Search with Limited Data (BMVC 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn162/</link>
      <pubDate>Sat, 08 Jan 2022 14:00:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn162/</guid>
      <description>2110.10807 Text-Based Person Search with Limited Data (BMVC 2021) 开源代码传送门 概述 关注 TBPS 任务中训练数据缺乏的问题。 本文提出一种跨模态动量对比学习架构 (cross-modal momentum contrasive learning framework, CM-MoCo) 来丰富给定 mini-batch 中的训练数据，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TAGPerson: A Target-Aware Generation Pipeline for Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn161/</link>
      <pubDate>Sat, 08 Jan 2022 13:10:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn161/</guid>
      <description>2112.14239 TAGPerson: A Target-Aware Generation Pipeline for Person Re-identification (2021) 开源代码传送门 概述 本文提出一种目标可知的生成方法 (Target-Aware Generation pipeline, TAGPerson) 用于生成自动标注的合成 ReID 数据集。 本文方法的三点优势： 在渲染过程中</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Specific Person Retrieval via Incomplete Text Description (ICMR 2015)</title>
      <link>http://jonathanwayy.xyz/2022/prn160/</link>
      <pubDate>Fri, 07 Jan 2022 20:57:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn160/</guid>
      <description>Specific Person Retrieval via Incomplete Text Description (ICMR 2015) 概述 Specific Person Retrieval vis Incomplete Text Description 任务。 用户所提供的属性通常是不完整的，本文采用一种线性稀疏重构 (linear sparse reconstruction) 来不全不完整的属性。 本文方法 包含线下</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Improving Person ReID with Temporal Constraints (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn159/</link>
      <pubDate>Fri, 07 Jan 2022 16:16:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn159/</guid>
      <description>Improving Person Re-Identification with Temporal Constraints (WACVW 2022) DAA 数据集传送门 概述 本文构建了一个新的数据集，称为 DAA，旨在关注视觉信息的同时关注时空信息，数据集中含有时间戳信息、帧序号、</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] FTN: Foreground-Guided Texture-Focused Person Re-Identification (2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn158/</link>
      <pubDate>Fri, 07 Jan 2022 13:18:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn158/</guid>
      <description>FTN: Foreground-Guided Texture-Focused Person Re-Identification (2020) 概述 本文关注背景干扰 (background interference) 问题，提出一种前景指导下关注纹理的网络 (Foreground-Guided Texture-Focused Network)，其包含一个语义编码器 (S-Enc)、一个紧凑</description>
    </item>
    
    <item>
      <title>壁纸分享[43]</title>
      <link>http://jonathanwayy.xyz/2022/bg43/</link>
      <pubDate>Fri, 07 Jan 2022 11:03:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg43/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Event-Driven Re-Id: Privacy-Preserving Person ReId (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn157/</link>
      <pubDate>Thu, 06 Jan 2022 14:04:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn157/</guid>
      <description>Event-Driven Re-Id: A New Benchmark and Method Towards Privacy-Preserving Person Re-Identification (WACVW 2022) 概述 关注 ReID 系统的隐私保护问题。事件相机 (event cameras) 记录场景的异步亮度变化，称之为事件 (event)。视觉信息被丢弃，只剩下</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] On the Importance of Appearance and Interaction (WACVW 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn156/</link>
      <pubDate>Wed, 05 Jan 2022 14:24:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn156/</guid>
      <description>On the Importance of Appearance and Interaction Feature Representations for Person Re-Identification (WACVW 2022) 概述 本文认为不止是表征能力强的特征本身，特征之间的交互也在匹配时起到关键作用，交互信息与基于外观的特征互补。 本文</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Adversarial Attribute-Text Embedding for Person Search (TMM 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn155/</link>
      <pubDate>Tue, 04 Jan 2022 10:58:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn155/</guid>
      <description>Adversarial Attribute-Text Embedding for Person Search with Natural Language Query (TMM 2020) 概述 本文提出一种对抗的属性-文本嵌入网络 (adversarial attribute-text embedding network, AATE)。 视觉属性图卷积网络 包含一个视觉注意力模块和一个图卷积网络</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Person Tube Retrieval via Language Description (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2022/prn154/</link>
      <pubDate>Mon, 03 Jan 2022 20:17:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn154/</guid>
      <description>Person Tube Retrieval via Language Description (AAAI 2020) 概述 应该是开了一个新坑。 Person tube 指的是视频中包含一个行人的一系列 bounding box，其中的行人被较好框出而无需进行额外的行人检测。 本文提出</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] DRSL: Deep Relational Similarity Learning for CMR (INS 2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn153/</link>
      <pubDate>Sun, 02 Jan 2022 15:11:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn153/</guid>
      <description>DRSL: Deep Relational Similarity Learning for Cross-modal Retrieval (Information Sciences 2021) 概述 学习公共空间的方法大多假设跨模态学习过程中的信息量是对等的，但通常各模态的信息量是不平衡的。 本文提出一种深度关系相</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Hybrid Ranking Representation for Person ReID (PR 2022)</title>
      <link>http://jonathanwayy.xyz/2022/prn152/</link>
      <pubDate>Sun, 02 Jan 2022 14:10:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn152/</guid>
      <description>Learning Hybrid Ranking Representation for Person Re-identification (PR 2022) 概述 本文提出一种双分支的 RANkinG Ensemble (RANGEv2) 方法，联合优化外观特征与排序上下文信息以生成外部排序表征 (external ranking representation)。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] A Feature Disentangling Approach via SS Data Augmentation (2021)</title>
      <link>http://jonathanwayy.xyz/2022/prn151/</link>
      <pubDate>Sat, 01 Jan 2022 14:25:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/prn151/</guid>
      <description>A Feature Disentangling Approach for Person Re-identification via Self-supervised Data Augmentation (Applied Soft Computing 2021) 开源代码传送门 概述 本文方法主要的两点改进： 通过打乱图像通道而非常用的 GAN，设计了一个自监督的数据增广方法，并</description>
    </item>
    
    <item>
      <title>壁纸分享[42]</title>
      <link>http://jonathanwayy.xyz/2022/bg42/</link>
      <pubDate>Sat, 01 Jan 2022 13:17:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2022/bg42/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Self-supervised Geometric Features Discovery (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn150/</link>
      <pubDate>Wed, 29 Dec 2021 15:30:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn150/</guid>
      <description>Self-supervised Geometric Features Discovery via Interpretable Attention for Vehicle Re-Identification and Beyond (ICCV 2021) 概述 本文提出一种新的架构来学习具有鉴别能力的几何特征 (geometric features)，其借助自监督学习和一个简单但是可解释的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] The Devil is in the Details for Vehicle ReID (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn149/</link>
      <pubDate>Wed, 29 Dec 2021 15:05:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn149/</guid>
      <description>The Devil is in the Details: Self-Supervised Attention for Vehicle Re-Identification (ECCV 2020) 概述 本文提出一种针对车辆 ReID 的自监督注意力 (SAVER)，自动关注车辆图像中的显著区域而无需额外的人工标注。 自监督残</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Self-Supervised Visual Representations for CMR (ICMR 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn148/</link>
      <pubDate>Wed, 29 Dec 2021 12:48:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn148/</guid>
      <description>Self-Supervised Visual Representations for Cross-Modal Retrieval (ICMR 2019) 概述 本文提出一种自监督的跨模态检索架构，利用图文之间的相关性作为监督信号，以学习能够有效迁移到其他 CV 任务上的视觉特征。 监督学</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Cross and Learn: Cross-Modal Self-Supervision (GCPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn147/</link>
      <pubDate>Wed, 29 Dec 2021 12:06:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn147/</guid>
      <description>Cross and Learn: Cross-Modal Self-Supervision (GCPR 2018) 开源代码传送门 概述 本文关注自监督学习任务，常用的流程是在一个需要语义理解的代理任务上预训练一个网络，本文利用跨模态信息作为监督</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 自监督学习] Barlow Twins: SSL via Redundancy Reduction (ICML 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn146/</link>
      <pubDate>Tue, 28 Dec 2021 13:14:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn146/</guid>
      <description>Barlow Twins: Self-Supervised Learning via Redundancy Reduction (ICML 2021) 开源代码传送门 概述 自监督学习任务 (SSL)。 现有工作的一个共同目标是要学习在不同扰动之下依旧稳定的表征，一种典型做法是最大</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Feature Erasing and Diffusion Network for Occluded ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn145/</link>
      <pubDate>Tue, 28 Dec 2021 10:56:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn145/</guid>
      <description>2112.08740 Feature Erasing and Diffusion Network for Occluded Person Re-Identification (2021) 概述 现实场景下主要存在两种干扰： Non-Pedestrian Occlusion (NPO) Non-Target Pedestrian (NTP) 现有方法更多关注前者而忽略了后者，预训练的姿态估计与行人解析模型在含有多个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 视觉对话] RAN with Reinforced Generator for Visual Dialog (TOMM 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn144/</link>
      <pubDate>Mon, 27 Dec 2021 17:59:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn144/</guid>
      <description>Recurrent Attention Network with Reinforced Generator for Visual Dialog (TOMM 2020) 概述 视觉对话 (Visual Dialog) 任务，代理 (agent) 根据所提供的图像与对话历史，回答关于图像中视觉内容的一系列具有时序关系的自然语言问题。 两个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] FGITR via Discriminative Latent Space Learning (SPL 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn143/</link>
      <pubDate>Sun, 26 Dec 2021 15:06:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn143/</guid>
      <description>Fine-Grained Image-Text Retrieval via Discriminative Latent Space Learning (SPL 2021) 概述 本文关注细粒度图文检索，提出一种有鉴别力的潜在空间学习方法 (Discriminative Latent Space Learning, DLSL)。 图文编码 分别用 ResNet-50 和词袋模型编码图文数据</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] DBPS with Multi-Grained Matching Networks (Displays 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn142/</link>
      <pubDate>Sat, 25 Dec 2021 16:05:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn142/</guid>
      <description>Description-Based Person Search with Multi-Grained Matching Networks (Displays 2021) 概述 本文提出一种多粒度匹配架构 (multi-grained matching framework)。 全局粒度表征 ResNet-50 / BERT 细粒度表征 对行人图像使用 Graphonomy 方法进行 human parsin</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Cross-Modal Knowledge Adaptation for LB Person Search (TIP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn141/</link>
      <pubDate>Sat, 25 Dec 2021 14:59:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn141/</guid>
      <description>Cross-Modal Knowledge Adaptation for Language-Based Person Search (TIP 2021) 概述 本文着眼于公共空间学习时不同模态间表征的不一致性。 文本可用于指导图像特征丰富其重要的新人细节通知避免图像独有信息的干扰</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TBPS via Multi-Granularity Embedding Learning (IJCAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn140/</link>
      <pubDate>Sat, 25 Dec 2021 14:15:45 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn140/</guid>
      <description>Text-based Person Search via Multi-Granularity Embedding Learning (IJCAI 2021) 概述 现有方法多存在嵌入模糊问题 (ambiguity embedding problem)。 本文提出一种多粒度嵌入学习模型 (multi-granularity embedding learning model, MGEL)，从粗到细表征行人，并</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Feature Disentangling for Occluded ReID (AAAI 2022)</title>
      <link>http://jonathanwayy.xyz/2021/prn139/</link>
      <pubDate>Fri, 24 Dec 2021 18:43:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn139/</guid>
      <description>Pose-guided Feature Disentangling for Occluded Person Re-identification Based on Transformer (AAAI 2022) 开源代码传送门 概述 本文试图在不涉及空间对齐的情况下结合额外的姿态信息与 Transformer，提出一种姿态指导的特征</description>
    </item>
    
    <item>
      <title>壁纸分享[41]</title>
      <link>http://jonathanwayy.xyz/2021/bg41/</link>
      <pubDate>Thu, 23 Dec 2021 20:27:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg41/</guid>
      <description></description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 去除 plt.savefig() 保存图像时的白边</title>
      <link>http://jonathanwayy.xyz/2021/ldp_plt_savefig_nowhite/</link>
      <pubDate>Wed, 22 Dec 2021 17:01:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_plt_savefig_nowhite/</guid>
      <description>在用 plt 保存图像时发现图像带有白边，查阅文档后解决了这一问题，在此记录一下。 将语句写成如下形式即可： plt.savefig(&#39;xxx.png&#39;, dpi=500, bbox_inches=&#39;tight&#39;, pad_inches=0.0) 其中将 pad_inches 参数置零即可去除白边，而将</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] PGGANet: Pose Guided Graph Attention Network for ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn138/</link>
      <pubDate>Mon, 20 Dec 2021 17:26:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn138/</guid>
      <description>2111.14411 PGGANet: Pose Guided Graph Attention Network for Person Re-identification (2021) 概述 现有方法多只是将姿态热图与特征图相乘得到局部关键点特征，但这种做法并非最佳选择： backbone 输出的全局特征高度抽象，各个像素</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Stronger Baseline for Person Re-Identification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn137/</link>
      <pubDate>Mon, 20 Dec 2021 16:40:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn137/</guid>
      <description>2112.01059 Stronger Baseline for Person Re-Identification (2021) 概述 由于训练数据较之于分类任务更加有限，ReID 有过高的过拟合风险，为了缓解这一问题主要有两种思路： 设计更加轻量级的网络结构，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Semantic-aligned Feature Representation for TBPS (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn136/</link>
      <pubDate>Mon, 20 Dec 2021 15:56:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn136/</guid>
      <description>2112.06714 Learning Semantic-aligned Feature Representation for Test-based Person Search (2021) 概述 本文提出一种语义对齐嵌入方法 (semantic-aligned embedding method)，自动实现细粒度特征的语义对齐，无需额外模型以及跨模态注意力。 方法 Modality-specific Feature</description>
    </item>
    
    <item>
      <title>壁纸分享[40]</title>
      <link>http://jonathanwayy.xyz/2021/bg40/</link>
      <pubDate>Wed, 15 Dec 2021 12:43:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg40/</guid>
      <description></description>
    </item>
    
    <item>
      <title>炼丹杂记 -- PyTorch 报错 Got 3 and 1 in dimension 1 的一种解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_got3and1/</link>
      <pubDate>Mon, 13 Dec 2021 17:34:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_got3and1/</guid>
      <description>问题描述 在 dataloader 相关部分出现如下报错： RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 1 in dimension 1 at /pytorch/aten/src/TH/generic/THTensorMath.c:3586 原因分析 RGB 图像中混有单通道的灰度图，导致堆叠时无法对齐。 解决办</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 报错 RuntimeError: ... is at version 2; expected version 1 ... 的一种解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_loss_grad/</link>
      <pubDate>Sun, 12 Dec 2021 17:35:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_loss_grad/</guid>
      <description>问题描述 模型训练时遇到如下报错： RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [50, 76, 512]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True). 一种解决办法 将原先的</description>
    </item>
    
    <item>
      <title>Latex 调整表格宽度与高度</title>
      <link>http://jonathanwayy.xyz/2021/latex_resizebox/</link>
      <pubDate>Thu, 09 Dec 2021 12:01:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_resizebox/</guid>
      <description>有时会遇到表格超出页面正常宽度的情况，可使用 \resizebox 命令进行调整。 \begin{table} \centering \resizebox{\columnwidth}{20mm}{ \begin{tabular}{l|ccc} \toprule Method &amp;amp; Top-1 &amp;amp; Top-5 &amp;amp; Top-10 \\ \midrule DSSL \small{$_{MM21}$} \tiny{\cite{dssl}} &amp;amp; 59.98 &amp;amp; 80.41 &amp;amp; \textbf{87.56} \\ \bottomrule \end{tabular}} \caption{xxxxxxxx.} \label{tab:example} \end{table} 注：命令加在 tabular 外一层，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 知识蒸馏 / 互学习] Deep Mutual Learning (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn135/</link>
      <pubDate>Tue, 07 Dec 2021 12:32:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn135/</guid>
      <description>Deep Mutual Learning (CVPR 2018) 开源代码传送门 1 开源代码传送门 2 概述 本文提出互学习 (mutual learning) 的概念，在若干个学生模型之间进行知识蒸馏。 深度互学习 定义 由两个网络分别计算得</description>
    </item>
    
    <item>
      <title>壁纸分享[39]</title>
      <link>http://jonathanwayy.xyz/2021/bg39/</link>
      <pubDate>Sun, 05 Dec 2021 20:33:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg39/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] GroupBERT: Enhanced TF with Efficient Grouped Structures (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn134/</link>
      <pubDate>Thu, 02 Dec 2021 21:15:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn134/</guid>
      <description>2106.05822 GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures (2021) 概述 本文对 Transformer 曾的结构进行了一些改进： 增加一个卷积模块作为自注意力模块的补充，分解局部与全局关系的学习 引入 grouped transformeation 以降低前馈层</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] MetaFormer is Actually What You Need for Vision (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn133/</link>
      <pubDate>Thu, 02 Dec 2021 20:43:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn133/</guid>
      <description>2111.11418 MetaFormer is Actually What You Need for Vision (2021) 开源代码传送门 概述 Transformer 中的编码器包含两部分，其一是注意力模块，用于混合 token 之间的信息，本文称之为 token mixer；其二是其余的模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Learning LocFeat with Multiple Dynamic Attention (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn132/</link>
      <pubDate>Wed, 01 Dec 2021 10:57:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn132/</guid>
      <description>Learning Deep Local Features With Multiple Dynamic Attentions for Large-Scale Image Retrieval (ICCV 2021) 开源代码传送门 概述 由于图像内容的多样性，只提取一张注意力图难以有效捕捉所有潜在的语义模式。 本文提出一个新架构，使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning To Know Where To See for Occluded ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn131/</link>
      <pubDate>Tue, 30 Nov 2021 11:50:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn131/</guid>
      <description>Learning To Know Where To See: A Visibility-Aware Approach for Occluded Person Re-Identification (ICCV 2021) 概述 随着姿态估计粒度的细化，其预测误差随之上升。 本文试图找到一种策略，能在不过分依赖姿态信息的情况下处理遮挡问</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 对抗攻击] Multi-Expert AAD Using Context Inconsistency (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn130/</link>
      <pubDate>Mon, 29 Nov 2021 13:39:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn130/</guid>
      <description>Multi-Expert Adversarial Attack Detection in Person Re-Identification Using Context Inconsistency (ICCV 2021) 概述 ReID 属于排序问题而非分类问题，因而现有针对分类问题的防御方法并不适合 ReID 任务。 本文提出多专家对抗攻击检测方法 (Multi-Expert Adversarial Attack Detection,</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Syncretic Modality Collaborative Learning for VI-ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn129/</link>
      <pubDate>Mon, 29 Nov 2021 11:06:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn129/</guid>
      <description>Syncretic Modality Collaborative Learning for Visible Infrared Person Re-Identification (ICCV 2021) 概述 现有借助第三模态方法的缺陷 由可视图像生成，导致新模态和可视模态高度相关，但和红外模态不相关 可视图像与红外图像的特征</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Feature Alignment for Occluded ReID (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn128/</link>
      <pubDate>Sun, 28 Nov 2021 19:56:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn128/</guid>
      <description>Pose-Guided Feature Alignment for Occluded Person Re-Identification (ICCV 2019) 概述 本文最早提出了 Occluded ReID 任务，并构建了 Occluded-DukeMTMC 数据集，query 图像全部带遮挡，而 gallery 图像有完整与遮挡两种情况。 Partial ReID 与 Occluded ReID 问题的对比</description>
    </item>
    
    <item>
      <title>壁纸分享[38]</title>
      <link>http://jonathanwayy.xyz/2021/bg38/</link>
      <pubDate>Sun, 28 Nov 2021 16:54:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg38/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning to Disentangle Scenes for ReID (Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn127/</link>
      <pubDate>Sat, 27 Nov 2021 13:37:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn127/</guid>
      <description>2111.05476 Learning to Disentangle Scenes for Person Re-identification (Neurocomputing 2021) 概述 为了有效分解复杂场景，本文提出一种分治策略 (divide-and-conquer strategy)，主要分析了两种情况： 遮挡 (occlusion) 尺度变化 (scale variation) 对输入的图像采</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Matching on Sets: Conquer OcReID Without Alignment (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn126/</link>
      <pubDate>Fri, 26 Nov 2021 16:19:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn126/</guid>
      <description>Matching on Sets: Conquer Occluded Person Re-Identification Without Alignment (AAAI 2021) 概述 本文提出一种在集合上匹配 (Matching on Sets, MoS) 的方法，从而避免复杂而又容易出错的空间对齐过程。 考虑到卷积特征通道通常会编码视觉模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] View Confusion Feature Learning for Person ReID  (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn125/</link>
      <pubDate>Fri, 26 Nov 2021 15:23:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn125/</guid>
      <description>View Confusion Feature Learning for Person Re-identification (ICCV 2019) 概述 本文提出一种视角混淆特征学习模型 (View Confusion Feature Learning, VCFL)，通过结合 view-generic 与 view-specific 模型学习 view-invariant 的特征。 从三个层面实现视角混淆： 基于分类器</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CMReID via Modality Confusion and Center Aggregation(ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn124/</link>
      <pubDate>Fri, 26 Nov 2021 13:08:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn124/</guid>
      <description>Cross-Modality Person Re-Identification via Modality Confusion and Center Aggregation (ICCV 2021) 概述 本文提出一种端到端的模态混淆学习网络 (Modality Confusion Learning network, MCLNet)，其核心想法在于混淆特征学习过程中的模态鉴别，使得优化显</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] SphereReID: Deep Hypersphere Manifold Embedding for ReID (2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn123/</link>
      <pubDate>Thu, 25 Nov 2021 10:10:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn123/</guid>
      <description>SphereReID: Deep Hypersphere Manifold Embedding for Person Re-identification (2019) 开源代码传送门 概述 本文提出一种 metric-based 的架构，称为 SphereReID，引入一个新的损失函数 Sphere Loss。 Softmax Loss $$L_{softmax} = -\frac{1}{N} \sum_{i= 1}^{N} log \frac{e^{z_{y_{i}}}}{\sum_{j=1}^C e^{e^{z_{j}}}},$$ $$z_{j} =</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] GreyReID: Two-stream Framework with RGB-grey Information (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn122/</link>
      <pubDate>Wed, 24 Nov 2021 12:41:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn122/</guid>
      <description>GreyReID: A Novel Two-stream Deep Framework with RGB-grey Information for Person Re-identification (TOMM 2021) 概述 着重关注不同行人之间色彩信息相似的问题，本文称之为 ReID 的色彩过拟合 (color over-fitting)。 RGB 图像与灰度图</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID / 频域] HLFNet: High-low Frequency Network for Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn121/</link>
      <pubDate>Tue, 23 Nov 2021 14:29:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn121/</guid>
      <description>HLFNet: High-low Frequency Network for Person Re-Identification (IEEE Signal Processing Letters 2021) 概述 本文提出一种高低频网络 (high-low frequency network, HLFNet)。 Frequency Splitting Module (FSM) 利用 guide filter 将原始图像分为高低频图像： $$I_{l} = \mathcal{G}(I_{o}),$$ $$I_{h} = I_{o} / (I_{l} + eps).$$ 将得到</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Occlude Them All: Occlusion-Aware Attention Network (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn120/</link>
      <pubDate>Mon, 22 Nov 2021 15:13:24 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn120/</guid>
      <description>Occlude Them All: Occlusion-Aware Attention Network for Occluded Person Re-ID (ICCV 2021) 概述 将遮挡按如下分类 4 locations: top, bottom, left, right 2 areas: half, quarter 本文提出一种遮挡可知的掩码网络 (Occlusion-Aware Mask Network, OAMN)，包含三个主要部件： attention-guided mask module occlusion augmentation</description>
    </item>
    
    <item>
      <title>壁纸分享[37]</title>
      <link>http://jonathanwayy.xyz/2021/bg37/</link>
      <pubDate>Sun, 21 Nov 2021 10:15:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg37/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Occluded ReID With Single-Scale Global Representation (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn119/</link>
      <pubDate>Sat, 20 Nov 2021 17:40:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn119/</guid>
      <description>Occluded Person Re-Identification With Single-Scale Global Representations (ICCV 2021) 数据集传送门（尚未更新） 概述 本文提出一种新的 ReID 模型，学习单尺度全局级别的行人表征 (single-scale global-level pedestrian representations)。 构</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Weakly Supervised Text-Based Person Re-Identification (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn118/</link>
      <pubDate>Fri, 19 Nov 2021 16:42:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn118/</guid>
      <description>Weakly Supervised Text-Based Person Re-Identification (ICCV 2021) 开源代码传送门 概述 本文提出弱监督图文 ReID，即在训练阶段没有 ID 标注。 新任务的两个困难 各模态内由于类内差异造成的影响难以处理 跨</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] CM-NAS for Visible-Infrared Person Re-Identification (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn117/</link>
      <pubDate>Thu, 18 Nov 2021 09:42:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn117/</guid>
      <description>CM-NAS: Cross-Modality Neural Architecture Search for Visible-Infrared Person Re-Identification (ICCV 2021) 开源代码传送门 概述 Visible-Infrared ReID 任务。 现有工作多是设计一个 two-stream 架构，因而就产生了一个问题：哪些层应当被分为两个分支，哪些层应该共享</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] BV-Person: A Large-Scale Dataset for Bird-View ReID (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn116/</link>
      <pubDate>Wed, 17 Nov 2021 20:40:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn116/</guid>
      <description>BV-Person: A Large-Scale Dataset for Bird-View Person Re-Identification (ICCV 2021) 数据集与开源代码传送门 概述 本文提出一种新的 ReID 任务，即鸟瞰视角下的 ReID，并制作了一个大规模数据集，称为 BV-Perso</description>
    </item>
    
    <item>
      <title>壁纸分享[36]</title>
      <link>http://jonathanwayy.xyz/2021/bg36/</link>
      <pubDate>Tue, 16 Nov 2021 10:09:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg36/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] LapsCore: Language-Guided Search via Color Reasoning (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn115/</link>
      <pubDate>Mon, 15 Nov 2021 11:06:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn115/</guid>
      <description>LapsCore: Language-Guided Person Search via Color Reasoning (ICCV 2021) 概述 现有方法隐式地学习跨模态局部关联。 颜色在检索中至关重要。 本文提出一种基于颜色推理的新方法，称为 LapsCore，通过解</description>
    </item>
    
    <item>
      <title>Latex 表格中绘制经过指定列的水平线</title>
      <link>http://jonathanwayy.xyz/2021/latex_cline/</link>
      <pubDate>Sat, 13 Nov 2021 14:47:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_cline/</guid>
      <description>在用 Latex 绘制表格的过程中，有时需要绘制不完全贯穿整行的水平线，可用如下命令指定需要贯穿的列： \cline{起始列-终止列} 此命令中列从 1 开始排</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Escaping the Big Data Paradigm with Compact Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn114/</link>
      <pubDate>Thu, 11 Nov 2021 20:39:25 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn114/</guid>
      <description>2104.05704 Escaping the Big Data Paradigm with Compact Transformers (2021) 开源代码传送门 概述 针对 Transformer 模型的数据饥饿 (data hungry) 传统观点，尝试弥合 Transformer 和 CNN 两种架构之间的鸿沟，结合二者优势，使得基于 Transformer 的模型能够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Structured MM Feature Embedding and Alignment (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn113/</link>
      <pubDate>Wed, 10 Nov 2021 19:27:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn113/</guid>
      <description>Structured Multi-modal Feature Embedding and Alignment for Image-Sentence Retrieval (MM 2021) 概述 现有细粒度方法的问题 忽略了模态内的上下文语义以及部件之间的结构化关系，导致无法有效捕获语义 以多对多匹配范式隐式建模</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Joint Generative and Contrastive Learning for UnS. ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn112/</link>
      <pubDate>Tue, 09 Nov 2021 09:03:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn112/</guid>
      <description>Joint Generative and Contrastive Learning for Unsupervised Person Re-identification (CVPR 2021) 开源代码传送门 概述 自监督对比学习方法 对于一张图像，最大化其两个增广视角之间的共识 (agreement between two augmented views)，视角指的是对于某</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Query-Adaptive Convolution and Temporal Lifting (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn111/</link>
      <pubDate>Mon, 08 Nov 2021 12:14:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn111/</guid>
      <description>Interpretable and Generalizable Person Re-Identification with Query-Adaptive Convolution and Temporal Lifting (ECCV 2020) 开源代码传送门 概述 现有的许多 ReID 方法只是在两个表征向量之间简单计算距离，而无视了两张图像真实内容之间的直接关系。 本文</description>
    </item>
    
    <item>
      <title>壁纸分享[35]</title>
      <link>http://jonathanwayy.xyz/2021/bg35/</link>
      <pubDate>Sun, 07 Nov 2021 20:31:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg35/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Knowledge-SV Learning: Knowledge Consensus Constraints (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn110/</link>
      <pubDate>Thu, 04 Nov 2021 11:07:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn110/</guid>
      <description>Knowledge-Supervised Learning: Knowledge Consensus Constraints for Person Re-Identification (MM 2021) 概述 本文旨在利用知识在不引入额外推断成本的基础上，约束同一数据上的多视角共识以提升精度。 行人 ReID 相较于图像分类的特殊性 检索</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] MCCN: Multimodal Coordinated Clustering Network (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn109/</link>
      <pubDate>Tue, 02 Nov 2021 19:54:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn109/</guid>
      <description>MCCN: Multimodal Coordinated Clustering Network for Large-Scale Cross-modal Retrieval (MM 2021) 概述 本文关注大规模多个模态应用场景下的模态不平衡的跨模态检索问题，提出一种多模态协同的聚类网络 (Multimodal Coordinated Clustering Network, MCCN)。 MCCN 包</description>
    </item>
    
    <item>
      <title>壁纸分享[34]</title>
      <link>http://jonathanwayy.xyz/2021/bg34/</link>
      <pubDate>Mon, 01 Nov 2021 20:53:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg34/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-guided Inter- and Intra-part Relational Transformer (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn108/</link>
      <pubDate>Sun, 31 Oct 2021 17:14:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn108/</guid>
      <description>Pose-guided Inter- and Intra-part Relational Transformer for Occluded Person Re-Identification (MM 2021) 开源代码传送门 概述 本文提出一种姿态指导的部件内间关系 Transformer。 姿态指导的特征提取 $$M = GMP(\hat{M}),$$ $$c_{g} = max(M_{g}),$$ $$F_{pose} = GAP((M &amp;gt; \tau)</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 数据增强] Cut-Thumbnail: A Novel Data Augmentation for CNN (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn107/</link>
      <pubDate>Fri, 29 Oct 2021 14:34:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn107/</guid>
      <description>Cut-Thumbnail: A Novel Data Augmentation for Convolutional Neural Network (MM 2021) 开源代码传送门 概述 现有的数据增强方法通过改变空间或色彩信息、增加噪音或混合来自不同图像的信息，来提高网络的泛化能力和鲁</description>
    </item>
    
    <item>
      <title>Latex 旋转文字方向</title>
      <link>http://jonathanwayy.xyz/2021/latex_rotatebox/</link>
      <pubDate>Thu, 28 Oct 2021 12:34:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_rotatebox/</guid>
      <description>有时在 Latex 表格中需要改变文字方向，可以用如下语句实现： \rotatebox{角度}{文本}</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Pose-Guided Feature Learning with KD for Occluded ReID (MM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn106/</link>
      <pubDate>Tue, 26 Oct 2021 22:45:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn106/</guid>
      <description>Pose-Guided Feature Learning with Knowledge Distillation for Occluded Person Re-Identification (MM 2021) 概述 本文提出一种通过知识蒸馏进行基于姿态指导的特征学习架构 (Pose-Guided Feature Learning with Knowledge Distillation network, PGFL-KD) 架构，姿态信息用于约束全局特征的学习而在测</description>
    </item>
    
    <item>
      <title>壁纸分享[33]</title>
      <link>http://jonathanwayy.xyz/2021/bg33/</link>
      <pubDate>Sun, 17 Oct 2021 21:58:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg33/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] TBPS in Full Images via Semantic-Driven Proposal Generation (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn105/</link>
      <pubDate>Fri, 15 Oct 2021 16:42:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn105/</guid>
      <description>2109.12965 Text-based Person Search in Full Images via Semantic-Driven Proposal Generation 概述 提出在完整图像中进行行人检索的任务，可视为 Person Detection 和 Text-based Person Retrieval 的结合。 本文提出 Semantic-Driven Region Proposal Net (SDPRN)。 构建了两个新数据集 CUHK-SYSU-TBPS</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 报错 RuntimeError: CUDA error: invalid device ordinal 解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_invalid_device_ordinal/</link>
      <pubDate>Wed, 13 Oct 2021 23:06:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_invalid_device_ordinal/</guid>
      <description>问题描述 在涉及 to(device) 操作时出现如下报错： RuntimeError: CUDA error: invalid device ordinal 解决办法 在该操作前指定可选的 GPU 卡： import os os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &amp;quot;0,1,2,3,4,5,6,7&amp;quot;</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch 取矩阵对角线元素</title>
      <link>http://jonathanwayy.xyz/2021/ldp_pytorch_diag/</link>
      <pubDate>Tue, 12 Oct 2021 19:13:06 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_pytorch_diag/</guid>
      <description>在 Pytorch 中，可以用 torch.diag 取矩阵的对角线元素，返回的是一个向量；使用 torch.diag_embed 可将向量变换为以该向量为对角线的方阵。 In [1]: import torch In [2]: A = torch.randn(3, 3) In [3]: A Out[3]: tensor([[ 0.1808, 0.2905, -2.2199], [-0.8913, 1.1296, 0.6261],</description>
    </item>
    
    <item>
      <title>壁纸分享[32]</title>
      <link>http://jonathanwayy.xyz/2021/bg32/</link>
      <pubDate>Fri, 01 Oct 2021 21:53:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg32/</guid>
      <description></description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 读取 pkl 文件报错 ValueError: unsupported pickle protocol: 5 解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_pickle_protocol_5/</link>
      <pubDate>Sun, 26 Sep 2021 21:00:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_pickle_protocol_5/</guid>
      <description>问题描述 使用 Python 读取 .pkl 文件时报错如下： ValueError: unsupported pickle protocol: 5 原因分析 Python 3.8 以上版本在保存 .pkl 文件时使用的协议号为 5，即 protocol 关键字为 5，若在读取时使用低于 3.8 版本的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像分解] Blind Image Decomposition (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn104/</link>
      <pubDate>Sun, 26 Sep 2021 17:07:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn104/</guid>
      <description>2108.11364 Blind Image Decomposition (2021) 开源代码传送门 概述 本文提出提出盲图像分解 (Blind Image Decomposition, BID) 任务，并设计了 Blind Image Decomposition Network (BIDeN)。 BID 的特点 不固定源部件数目，只设定一个潜在源部</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learning Posterior and Prior for Uncertainty Modeling in ReID(2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn103/</link>
      <pubDate>Sat, 25 Sep 2021 15:30:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn103/</guid>
      <description>2007.08785 Learning Posterior and Prior for Uncertainty Modeling in Person Re-Identification (2020) 概述 本文在 ReID 任务中同时学习样本后验与类别先验，以量化输入图像及其相应类别的不确定性。 整体架构 上分支用 GAP 处理特征图得到</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Person Search Challenges and Solutions: A Survey (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn102/</link>
      <pubDate>Fri, 24 Sep 2021 22:10:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn102/</guid>
      <description>2105.01605v1 Person Search Challenges and Solutions: A Survey (2021) 概述 关于 Image-based Person Search 与 Text-based Person Search 的综述。 本文与现有综述的差异 Detection-identification Inconsistency Problem Person Search 研究进展时间线 三个主要挑战 从场景图像学习具有足够鉴别能力的行人</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 人机交互 / 跨模态检索] Interactive Natural Language Person Search (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn101/</link>
      <pubDate>Fri, 24 Sep 2021 19:53:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn101/</guid>
      <description>2002.08434v1 Interactive Natural Language-based Person Search (2020) CUHK-QA 数据集传送门 概述 可以认为本文是换了一种说法，把 Text-based Person Search 称为 Zero-shot re-ID。 将 language-based re-ID 视为一种 VQA 任务，输入为图文对，输出为二值化答案。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 风格迁移] Style Transfer with Adaptive Instance Normalization (ICCV 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn100/</link>
      <pubDate>Thu, 23 Sep 2021 16:48:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn100/</guid>
      <description>Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization (ICCV 2017) 概述 本文基于 instance normalization (IN) 提出 adaptive instance normalization (AdaIN)，解决风格迁移任务中的灵活性-速度困境。 Adaptive Instance Normalization (AdaIN) $$AdaIN(x, y) = \sigma (y) (\frac{x - \mu (x)}{\sigma (x)}) + \mu (y).$$ 风</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像标注] Unsupervised Image Captioning (CVPR 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn99/</link>
      <pubDate>Wed, 22 Sep 2021 13:14:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn99/</guid>
      <description>Unsupervised Image Captioning (CVPR 2019) 开源代码传送门 概述 无监督图像标注任务，即不使用任何标记好的图文对来训练图像标注模型。 三个目标 用文本对抗生成方法，在句子语料上训练一</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- PyTorch 出现 NotImplementedError 报错的一种可能情况</title>
      <link>http://jonathanwayy.xyz/2021/ldp_torch_notimplementederror/</link>
      <pubDate>Tue, 21 Sep 2021 23:36:45 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_torch_notimplementederror/</guid>
      <description>问题描述 PyTorch 一使用网络进行计算即出现如下报错： raise NotImplementedErrorh 问题原因 经过反复的调试和检查后，发现是 forward 函数的问题，网络模型类中的 def forward 一行多缩进了一个 Tab 位，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] SDMCH: Supervised Discrete Manifold-Embeded (IJCAI 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn98/</link>
      <pubDate>Thu, 16 Sep 2021 15:23:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn98/</guid>
      <description>SDMCH: Supervised Discrete Manifold-Embedded Cross-Modal Hashing (IJCAI 2018) 概述 本文提出离散流形嵌入跨模态哈希方法 (Discrete Manifold-Embedded Cross-Modal Hashing, SDMCH)。 既挖掘数据的非线性流形结构，也在多模态之间构建相关性。 流形结构学</description>
    </item>
    
    <item>
      <title>壁纸分享[31]</title>
      <link>http://jonathanwayy.xyz/2021/bg31/</link>
      <pubDate>Wed, 15 Sep 2021 19:28:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg31/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Semantically Self-Aligned Network for T2I Person ReID (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn97/</link>
      <pubDate>Mon, 13 Sep 2021 13:18:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn97/</guid>
      <description>2107.12666v2 Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification (2021) 开源代码传送门 概述 自然语言描述的自由形式带来的两个问题 同一张图像对应的描述可能非常不同 对于身体部件的描述可能以任意顺序呈</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Windows 环境下 Python 2 可用的一个 Tensorflow 轮子</title>
      <link>http://jonathanwayy.xyz/2021/ldp_py2_win_tf/</link>
      <pubDate>Sun, 12 Sep 2021 20:39:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_py2_win_tf/</guid>
      <description>Tensorflow 在 Windows 环境下不支持 Python 2，但是最近需要在一台 Windows 系统的工作站上给基于 Python 2.7 的虚拟环境配置 Tensorflow。 记录一下找到的一个可用的轮子： https://github.com/fo40225/tensorflow-windows-wheel 下载</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 2 安装 grpcio 的一个可用版本</title>
      <link>http://jonathanwayy.xyz/2021/ldp_py2_grpcio/</link>
      <pubDate>Sun, 12 Sep 2021 20:25:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_py2_grpcio/</guid>
      <description>在一台 Windows 工作站上需要配置一个基于 Python 2.7 的 TF 虚拟环境，安装一个依赖包 grpcio 时遇到了问题。 分析以后应该是由于新版本的 grpcio 不支持 Python 2.7 了，直接用 pip 安装不行，</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Windows 下使用 pip 安装 opendr</title>
      <link>http://jonathanwayy.xyz/2021/ldp_win_opendr/</link>
      <pubDate>Sun, 12 Sep 2021 15:35:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_win_opendr/</guid>
      <description>问题描述 直接使用 pip install opendr 会报一个 failed with exit code 1181 的错误。 解决办法 首先安装 glfw，是 opengl 的一个框架： pip install glfw 在这里下载 opendr 后构建并安装： &amp;gt; git clone https://github.com/polmorenoc/opendr.git &amp;gt; cd ./opendr/opendr &amp;gt; python</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Python 2 安装 opencv-python 包出错解决办法</title>
      <link>http://jonathanwayy.xyz/2021/ldp_python2_opencv/</link>
      <pubDate>Sat, 11 Sep 2021 21:46:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_python2_opencv/</guid>
      <description>问题描述 在为使用 Python 2.7 的虚拟环境使用如下命令安装 OpenCV 时 pip2 install opencv-python 出现了如下报错： TypeError: &#39;NoneType&#39; object is not iterable 原因分析 出现这种情况是因为最新版的 OpenCV 不再支持 Python 2.7，而</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Parameter-Efficient Person Re-identification in the 3D Space (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn96/</link>
      <pubDate>Sat, 11 Sep 2021 14:44:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn96/</guid>
      <description>2006.04569 Parameter-Efficient Person Re-identification in the 3D Space (2020) 开源代码传送门 概述 考察 2D 行人外观与 3D 几何结构之间的互补信息。 本文提出 Omni-scale Graph Network (OG-Net)，在 3D 空间中进行 ReID。 模型架</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] PCNET: Parallelly Conquer Large Variance of Person ReId (ICIP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn95/</link>
      <pubDate>Fri, 10 Sep 2021 13:22:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn95/</guid>
      <description>PCNET: Parallelly Conquer the Large Variance of Person Re-Identification (ICIP 2021) 概述 本文提出 Parallelly Conquer Net (PCNet)，主要包含三个部件： Pose Adaptation Module (PAM) Global Alignment Module (GAM) Pixel-Wised Attention Module (PWAM) 用模块聚合单元 (Module Aggregation Unit) 整合各个子模块生成的特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 3D 跨模态检索] Cross-Modal Center Loss for 3D CM Retrieval (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn94/</link>
      <pubDate>Thu, 09 Sep 2021 22:52:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn94/</guid>
      <description>Cross-Modal Center Loss for 3D Cross-Modal Retrieval (CVPR 2021) 概述 现有方法的问题 核心想法是最小化由预训练模型提取的特征之间的跨模态差异，预训练模型没有参与训练或进行微调 现有的损失函数主</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Modality-Specific and Shared GAN (PR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn93/</link>
      <pubDate>Thu, 09 Sep 2021 21:42:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn93/</guid>
      <description>Modality-Specific and Shared Generative Adversarial Network for Cross-modal Retrieval (PR 2020) 概述 本文提出 Modality-Specific and Shared Generative Adversarial Network (\(MS^2GAN\))。 生成模型 标签预测 将模态中特征与公共空间特征拼接后用于预测标签，采用</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Aggregation-based Graph Convolutional Hashing (TMM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn92/</link>
      <pubDate>Thu, 09 Sep 2021 13:11:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn92/</guid>
      <description>Aggregation-based Graph Convolutional Hashing for Unsupervised Cross-modal Retrieval (TMM 2021) 概述 本文提出基于聚合的图卷积哈希方法 (Aggregation-based Graph Convolutional Hashing, AGCH)。 模型架构 主要部件 图像编码器 + 图像 GCN 文本编码器 + 文本 GCN 融合模块 生成</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Learning Sufficient Scene Representation(Neurocomputing 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn91/</link>
      <pubDate>Wed, 08 Sep 2021 19:36:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn91/</guid>
      <description>Learning Sufficient Scene Representation for Unsupervised Cross-modal Retrieval (Neurocomputing 2021) 背景 此前有工作从统计层面证明分析了跨模态检索的过程，借助变分推断证明了不可能同时最大化模态内与模态间相似度，二者会互相约</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Unsupervised Cross-modal Retrieval through AL (ICME 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn90/</link>
      <pubDate>Tue, 07 Sep 2021 14:45:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn90/</guid>
      <description>Unsupervised Cross-modal Retrieval through Adversarial Learning (ICME 2017) 概述 本文提出基于对抗学习的无监督跨模态检索 (Unsupervised Cross-modal Retrieval with Adversarial, UCAL)。 包含四个部分： 图像特征映射 文本特征映射 模态分类器，生成二元特</description>
    </item>
    
    <item>
      <title>IEEE 论文模板选择与下载工具</title>
      <link>http://jonathanwayy.xyz/2021/sharp5/</link>
      <pubDate>Sat, 04 Sep 2021 00:21:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/sharp5/</guid>
      <description>IEEE 论文模板选择与下载工具，记录一下方便自己找。 传送门：IEEE Template Selector 按照流程依次选择自己所需选项即可，Latex 和 Word 都有。</description>
    </item>
    
    <item>
      <title>BLWL[42] Manjaro pacman 更新提示 failed to synchronize all databases 解决方案</title>
      <link>http://jonathanwayy.xyz/2021/blwl42/</link>
      <pubDate>Fri, 03 Sep 2021 15:05:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/blwl42/</guid>
      <description>问题描述 在运行 sudo pacman -Sy 进行更新时遇到如下报错： :: 正在同步软件包数据库... 错误：failed to synchronize all databases (无法锁定数据库) 问题分析 Pacman 数据库因之前的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Contextual Transformer Networks for Visual Recognition (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn89/</link>
      <pubDate>Thu, 02 Sep 2021 21:44:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn89/</guid>
      <description>2107.12292 Contextual Transformer Networks for Visual Recognition (CVPRW 2021) 开源代码传送门 概述 现有 ViT 方法的问题 只是基于各位置上孤立的 key 和 query 求得注意力矩阵，忽略了相邻 key 之间丰富的上下文信息。 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Attention-Guided Semantic Hashing (ICME 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn88/</link>
      <pubDate>Thu, 02 Sep 2021 12:29:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn88/</guid>
      <description>Attention-Guided Semantic Hashing for Unsupervised Cross-Modal Retrieval (ICME 2021) 概述 无监督跨模态哈希问题。 本文提出注意力指导的语义哈希模型 (Attention-Guided Semantic Hashing)。 模型架构 特征提取 VGG-16 提取图像特征，unive</description>
    </item>
    
    <item>
      <title>壁纸分享[30]</title>
      <link>http://jonathanwayy.xyz/2021/bg30/</link>
      <pubDate>Tue, 31 Aug 2021 11:53:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg30/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Learning Omni-frequency Region-adaptive Representations (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn87/</link>
      <pubDate>Mon, 30 Aug 2021 11:13:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn87/</guid>
      <description>Learning Omni-frequency Region-adaptive Representations for Real Image Super-Resolution (AAAI 2021) 概述 本文提出 Omni-frequency Region-adaptive Network (ORNet) 解决真实图像超分问题。 模型架构 频率分解模块 (Frequency Decomposition Module, FD) FD 模块由两个阶段组成： 频率分解阶段 频率增强阶段 频率</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ReID] Learn 3D Shape Feature for Texture-insensitive Person ReID (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn86/</link>
      <pubDate>Sun, 29 Aug 2021 14:30:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn86/</guid>
      <description>Learning 3D Shape Feature for Texture-insensitive Person Re-identification (CVPR 2021) 开源代码传送门 背景 Person ReID 任务。 研究表明 Person ReID 相当依赖衣着外观纹理 (clothing appearance textures)，大多数现有方法在衣着纹理较迷惑时表现</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Frequency Separation for Real-World Super-Resolution (ICCVW 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn85/</link>
      <pubDate>Fri, 27 Aug 2021 13:40:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn85/</guid>
      <description>1911.07850 Frequency Separation for Real-World Super-Resolution (ICCVW 2019) 开源代码传送门 速览 速读一篇文献，主要关注一下频域相关的处理。 下采样操作去除了高频信息而保留低频信息。 因而本文对高低频信息进行</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Focal Frequency Loss for Image Reconstruction (ICCV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn84/</link>
      <pubDate>Thu, 26 Aug 2021 20:50:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn84/</guid>
      <description>2012.12821 Focal Frequency Loss for Image Reconstruction and Synthesis (ICCV 2021) 开源代码传送门 项目主页传送门 背景 Image Reconstruction And Synthesis 任务。 本文提出一种 Focal Frequency Loss，直接在频域中优化生成模型。 Focal Frequency Loss 由 2D DFT 的公式表</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] HAL: Mitigating Visual Semantic Hubs (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn83/</link>
      <pubDate>Thu, 26 Aug 2021 12:55:43 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn83/</guid>
      <description>HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs (AAAI 2020) 背景 本文主要针对图文匹配任务中的枢纽点问题 (Hubness Problem) 进行研究。 由于图文匹配中的嵌入空间是由联合建模视觉和语言得到的，通常将其</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 枢纽点问题 (Hubness Problem)</title>
      <link>http://jonathanwayy.xyz/2021/ldp_hubness_problem/</link>
      <pubDate>Wed, 25 Aug 2021 18:08:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp_hubness_problem/</guid>
      <description>当特征嵌入空间是一个高维空间时，容易出现枢纽点问题 (Hubness Problem)。 问题定义 在高维空间中，一部分测试集的类别可能会成为很多数据点的 K 近邻 (</description>
    </item>
    
    <item>
      <title>Latex 使用 longtable 实现多页显示长表格</title>
      <link>http://jonathanwayy.xyz/2021/latex_longtable/</link>
      <pubDate>Wed, 25 Aug 2021 12:41:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_longtable/</guid>
      <description>在使用 Latex 写论文时，有时会出现表格过长超出一页的情况，可以通过 longtable 包实现表格的多页显示。 首先引入宏包 \usepackage{longtable} 使用 longtable 首先删去 \begin{table} 和 \end{table}，</description>
    </item>
    
    <item>
      <title>编译 Latex 遇到 File ended while scanning use of 
ewlbel 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/latex_newlbel/</link>
      <pubDate>Wed, 25 Aug 2021 12:23:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_newlbel/</guid>
      <description>问题描述 编译 Latex 时出现如下报错： File ended while scanning use of \@newl@bel... 解决办法 将目录中除了 .tex 文件以及图像、参考文献等文件其外的其余文件均删除后重新编译即可。</description>
    </item>
    
    <item>
      <title>Coder 实用小工具大合集 tools.fun</title>
      <link>http://jonathanwayy.xyz/2021/sharp4/</link>
      <pubDate>Tue, 24 Aug 2021 23:02:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/sharp4/</guid>
      <description>推荐一个使用小工具合集网站。 网站传送门</description>
    </item>
    
    <item>
      <title>壁纸分享[29]</title>
      <link>http://jonathanwayy.xyz/2021/bg29/</link>
      <pubDate>Tue, 24 Aug 2021 21:41:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg29/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Step-Wise Hierarchical Alignment Network (IJCAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn82/</link>
      <pubDate>Mon, 23 Aug 2021 14:43:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn82/</guid>
      <description>Step-Wise Hierarchical Alignment Network for Image-Text Matching (IJCAI 2021) 背景 现有方法的问题 根据明显差异来鉴别图文对，可能会因而无法区分具有微小上下文信息差异但是语义内容相似的样本。 本文提出一种逐</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Probabilistic Embeddings for Cross-Modal Retrieval (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn81/</link>
      <pubDate>Thu, 19 Aug 2021 11:43:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn81/</guid>
      <description>Probabilistic Embeddings for Cross-Modal Retrieval (CVPR 2021) 开源代码传送门 背景 一张图像可能与多条不同的文本相匹配，一条文本也可能对应多张不同的图像。 本文提出一种概率跨模态嵌入模型 (Probabilistic Cross-Modal Embedding, P</description>
    </item>
    
    <item>
      <title>BLWL[41] Linux 通过 tar 进行系统备份与恢复</title>
      <link>http://jonathanwayy.xyz/2021/blwl41/</link>
      <pubDate>Wed, 18 Aug 2021 14:36:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/blwl41/</guid>
      <description>记录一下如何使用 tar 工具进行 Linux 系统的备份与恢复。 1. 安装 tar 工具 &amp;gt; sudo pacman -S tar 2. 新建一个存放备份文件的目录 &amp;gt; mkdir -p backup_dir backup_dir 目录可根据自己的设备情况选择。 3. 执</description>
    </item>
    
    <item>
      <title>Latex 表格使用 toprule、midrule 及 bottomrule 时出现 undefined control sequence 报错解决方案</title>
      <link>http://jonathanwayy.xyz/2021/latex_booktabs/</link>
      <pubDate>Tue, 17 Aug 2021 20:24:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_booktabs/</guid>
      <description>问题描述 在 Latex 表格中，使用 \toprule、\midrule 以及 \bottomrule 时报错 “undefined control sequence”。 解决办法 缺少相应宏包，导入即</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图网络 / Ad-hoc 检索] A Graph-based Relevance Matching Model (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn80/</link>
      <pubDate>Tue, 17 Aug 2021 15:53:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn80/</guid>
      <description>2101.11873 A Graph-based Relevance Matching Model for Ad-hoc Retrieval (AAAI 2021) 背景 query-document 检索任务。 两类架构 representation-based matching interaction-based matching 两种重要关系 term-level query-document interaction document-level word relationships 一个问题 用来检索的短语可能并不连续出现在文档中，可能相隔甚远。</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- PyTorch 特征傅利叶变换幅度相位分离与重建</title>
      <link>http://jonathanwayy.xyz/2021/fft-ap/</link>
      <pubDate>Mon, 16 Aug 2021 17:57:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/fft-ap/</guid>
      <description>简单记录一下如何使用 PyTorch 对做过傅利叶变换后的特征进行幅度与相位的分离与重建。 In [1]: import torch In [2]: import numpy as np # 生成一个张量作为特征 In [3]: feat = torch.rand((3,10)) In [4]: feat Out[4]: tensor([[3.7899e-01, 2.9198e-01, 6.4575e-01,</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] FDA: Fourier Domain Adaptation (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn79/</link>
      <pubDate>Mon, 16 Aug 2021 16:19:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn79/</guid>
      <description>FDA: Fourier Domain Adaptation for Semantic Segmentation (CVPR 2020) 开源代码传送门 概述 提出傅里叶域自适应 (FDA)。 FFT ==&amp;gt; 用目标图像的低频成分替换源图像低频成分 ==&amp;gt; iFFT FDA 设计了一个外圈置零的掩码：</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Phase Consistent Ecological Domain Adaptation (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn78/</link>
      <pubDate>Sun, 15 Aug 2021 12:28:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn78/</guid>
      <description>Phase Consistent Ecological Domain Adaptation (CVPR 2020) 开源代码传送门 概述 无监督域适应 (Unsupervised Domain Adaptation, UDA) 任务。 通常的 UDA 方法 学习一个从源分布到目标分布的映射 训练一个对域变化不敏感的骨架网络 本文引</description>
    </item>
    
    <item>
      <title>壁纸分享[28]</title>
      <link>http://jonathanwayy.xyz/2021/bg28/</link>
      <pubDate>Sat, 14 Aug 2021 23:45:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg28/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] CAT: Cross Attention in Vision Transformer (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn77/</link>
      <pubDate>Thu, 12 Aug 2021 16:00:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn77/</guid>
      <description>2106.05786 CAT: Cross Attention in Vision Transformer (2021) 开源代码传送门 核心 设计了一种在单通道特征图上做注意力的方法，提出交叉注意力。 结合 Transformer 和 CNN 的优点构建 CAT。 Patch 内自注意力块 (IPSA) 与 Patch</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图网络] Graph Reasoning Networks on a Similarity Pyramid (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn76/</link>
      <pubDate>Wed, 11 Aug 2021 15:46:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn76/</guid>
      <description>Fashion Retrieval via Graph Reasoning Networks on a Similarity Pyramid (ICCV 2019) 概述 Fashion Retrieval 任务。 一个问题在于对应位置的局部块通常是失配的，因此需要在同尺度所有局部之间遍历匹配。 设计了一种基于相似度金</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Attention in Attention Network for Image Super-Resolution (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn75/</link>
      <pubDate>Tue, 10 Aug 2021 11:12:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn75/</guid>
      <description>2104.09497 Attention in Attention Network for Image Super-Resolution (2021) 开源代码传送门 概览 图像超分任务。 提出一种 attention in attention 块 (\(A^2B\))，并设计了 \(A^2N\) 架构。 出发点 两个问题 图像的哪一部分倾向于有</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] CCNet: Criss-Cross Attention (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn74/</link>
      <pubDate>Mon, 09 Aug 2021 12:11:40 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn74/</guid>
      <description>CCNet: Criss-Cross Attention for Semantic Segmentation (ICCV 2019) 开源代码传送门 概述 提出十字注意力 (Criss-Cross Attention)，将参数量从非局部注意力的 \(H \times W\) 减少到了 \(H + W -1\)。 为了捕捉全图依</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Learning Joint Embedding of Food Images and Recipes (TMM 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn73/</link>
      <pubDate>Sun, 08 Aug 2021 20:31:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn73/</guid>
      <description>Cross-Modal Food Retrieval: Learning a Joint Embedding of Food Images and Recipes with Semantic Consistency and Attention Mechanism (TMM 2021) 核心 相同食物的数据表征可能不同，而不同食物的数据表征可能相似，从而导致食物数据有较大的类内方差与较小</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Attentional Feature Fusion (WACV 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn72/</link>
      <pubDate>Fri, 06 Aug 2021 14:50:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn72/</guid>
      <description>2009.14082 Attentional Feature Fusion (WACV 2021) 开源代码传送门 概述 本文研究特征融合 (feature fusion)，提出注意力特征融合模块 (attentional feature fusion module, AFF)。 为了缓解由于尺度变化以及小目标引起的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Context-Aware Attention Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn71/</link>
      <pubDate>Wed, 04 Aug 2021 19:43:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn71/</guid>
      <description>Context-Aware Attention Network for Image-Text Retrieval (CVPR 2020) 背景 现有方法的问题 不同的局部块有不同重要性 忽略同模态中各局部之间的语义相关性 一个单词或一个图像区域在不同的全局上下文中可能有</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Transformer in Convolutional Neural Networks (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn70/</link>
      <pubDate>Tue, 03 Aug 2021 12:09:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn70/</guid>
      <description>2106.03180 Transformer in Convolutional Neural Networks (2021) 开源代码传送门 概览 本文提出层级化的多头注意力 (H-MHSA)。 为了结合 CNN 与 Transformer 的优势，提出 Transformer in Convolutional Neural Networks (TransCNN) 的概念，TransCNN 直</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希 / 图网络] Determining the Semantic Graph Connectivity (IJCAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn69/</link>
      <pubDate>Tue, 03 Aug 2021 11:07:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn69/</guid>
      <description>Set and Rebase: Determining the Semantic Graph Connectivity for Unsupervised Cross-Modal Hashing (IJCAI 2020) 概述 两类无监督跨模态哈系 跨模态量化，最小化二进制编码与原始数据低维投影之间的鸿沟 跨模态相似度搜索 三个主要问题 在没</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Adapted Graph Reasoning and Filtration (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn68/</link>
      <pubDate>Mon, 02 Aug 2021 16:52:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn68/</guid>
      <description>Adapted Graph Reasoning and Filtration for Description-Image Retrieval (SIGIR 2021) 概述 本文处理更加抽象的文本描述。 提出一种自适应的图推理与过滤网络 (Adapted Graph Reasoning and Filtration network, AGRF)，包含两大主要部件： 自适应图推理网</description>
    </item>
    
    <item>
      <title>壁纸分享[27]</title>
      <link>http://jonathanwayy.xyz/2021/bg27/</link>
      <pubDate>Sun, 01 Aug 2021 21:27:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg27/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Wavelet Pooling for Convolutional Neural Networks (ICLR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn67/</link>
      <pubDate>Sat, 31 Jul 2021 19:43:38 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn67/</guid>
      <description>Wavelet Pooling for Convolutional Neural Networks (ICLR 2018) 概述 本文提出一种小波池化算法，使用二阶小波分解对特征进行子采样，放弃了最近临插值方法，而采用了一种子带方法，从而得以使用更少</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Wavelet-enhanced Convolutional Neural Network (2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn66/</link>
      <pubDate>Fri, 30 Jul 2021 21:55:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn66/</guid>
      <description>Wavelet-enhanced Convolutional Neural Network: A New Idea in A Deep Learning Paradigm (2018) 概览 结合 CNN 与小波变换提升分割任务表现。 小波变换在图像处理中的主要作用在于其能够将图像分解为含有不同级别细节的不同尺</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Wavelet Integrated CNNs for Noise-Robust Img Classification(CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn65/</link>
      <pubDate>Fri, 30 Jul 2021 19:49:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn65/</guid>
      <description>Wavelet Integrated CNNs for Noise-Robust Image Classification (CVPR 2020) 开源代码传送门 概述 CNN 对噪声的鲁棒性较差，随机噪声大多为高频成分，CNN 在下采样之前缺少滤波步骤，可能会导致高低频成分的混叠</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Retrieve Fast Rerank Smart: Cooperative and Joint Approaches (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn64/</link>
      <pubDate>Fri, 30 Jul 2021 11:12:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn64/</guid>
      <description>2103.11920v1 Retrieve Fast, Rerank Smart: Cooperative and Joint Approaches for Improved Cross-Modal Retrieval (2021) 开源代码传送门 核心想法 要在计算效率和模型精度上找到平衡。 四种模型 Cross-Encoders 如图 1(a) 所示。 二分类问题，将 \([CLS]\) token 输入分类器，用交</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TIED: A Cycle Consistent Encoder-Decoder Model (CVPRW 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn63/</link>
      <pubDate>Thu, 29 Jul 2021 11:27:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn63/</guid>
      <description>TIED: A Cycle Consistent Encoder-Decoder Model for Text-to-Image Retrieval (CVPRW 2021) 概览 Natural Language (NL) based Vehicle Track Retrieval 任务，对时间也有要求。 本文提出一种文本到图像的编码器解码器网络 (Text-to-Image Encoder-Decoder network, TIED)，将图文映射到潜在空间</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 联邦学习 / 跨模态检索] FedCMR: Federated Cross-Modal Retrieval (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn62/</link>
      <pubDate>Wed, 28 Jul 2021 14:36:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn62/</guid>
      <description>FedCMR: Federated Cross-Modal Retrieval (SIGIR 2021) 概述 基于深度学习的方法需要大量高质量的多模态数据，而现实中，多模态数据由许多不同用户 (client) 分别生成。 本文研究联邦跨模态检索 (Federated Cross-Modal Retrieval, Fe</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / 跨模态检索] Revamping Cross-Modal Recipe Retrieval (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn61/</link>
      <pubDate>Wed, 28 Jul 2021 10:41:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn61/</guid>
      <description>Revamping Cross-Modal Recipe Retrieval with Hierarchical Transformers and Self-supervised Learning (CVPR 2021) 开源代码传送门 图像编码器 \(\phi_{img}\) ResNet-50 / ResNeXt / ViT 菜谱编码器 \(\phi_{rec}\) 三类数据要处理 标题 成分 指导 用三个独立的基于 Transformer 的编码器分别处理三种数据</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Early Convolutions Help Transformers See Better (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn60/</link>
      <pubDate>Tue, 27 Jul 2021 11:07:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn60/</guid>
      <description>2106.14881 Early Convolutions Help Transformers See Better (2021) ViT 模型对超参数敏感，不好优化；而 CNN 更容易优化。 本文认为问题在于 ViT 的前期视觉处理 (early visual processing)，通常是 patchify stem，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Fine-grained Video-Text Retrieval with HGR (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn59/</link>
      <pubDate>Mon, 26 Jul 2021 11:53:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn59/</guid>
      <description>Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning (CVPR 2020) 开源代码传送门 核心 提出一种层级式的图推理模型 (Hierarchical Graph Reasoning model, HGR)，将视频-文本匹配分解为三级语义： 全局事件，在文本中对应整个句</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] A Deep Local and Global Scene-Graph Matching (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn58/</link>
      <pubDate>Sun, 25 Jul 2021 11:30:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn58/</guid>
      <description>2106.02400 A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval (2021) 核心 提出一种局部与全局场景图匹配 (Local and Global Scene Graph Matching, LGSGM) 方法。 视觉图编码器 文本编码器 图嵌入 用多尺度节点注意力将图嵌入为向量。 附</description>
    </item>
    
    <item>
      <title>壁纸分享[26]</title>
      <link>http://jonathanwayy.xyz/2021/bg26/</link>
      <pubDate>Thu, 22 Jul 2021 20:38:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg26/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / ReID] TransReID: Transformer-based Object Re-Identification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn57/</link>
      <pubDate>Wed, 21 Jul 2021 10:10:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn57/</guid>
      <description>2102.04378v2 TransReID: Transformer-based Object Re-Identification (2021) 开源代码传送门 背景 目标 ReID 尚未很好解决的两个问题 从全局视角提取丰富的结构模式 包含细节信息的细粒度特征提取受到下采样的限制 本文提出一</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] CMT: Convolutional Neural Networks Meet Vision Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn56/</link>
      <pubDate>Tue, 20 Jul 2021 14:32:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn56/</guid>
      <description>2107.06263 CMT: Convolutional Neural Networks Meet Vision Transformers (2021) 核心 本文设计了一种 CNN 与 transformer 的交集，即 CMT 架构。 CMT 块 Local Perception Unit (LPU) 绝对的位置编码破坏了平移不变性，忽视了 patch 中的局部关联与结构信息。 $$LPU(X) =</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Incorporating Convolution Designs into Visual Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn55/</link>
      <pubDate>Tue, 20 Jul 2021 10:06:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn55/</guid>
      <description>2103.11816 Incorporating Convolution Designs into Visual Transformers (2021) 核心 设计一种通过卷积增强的图像 Transformer (Convolution-enhanced image Transformer, CeiT)，将 CNN 提取低级特征、强化局部性与 Transformer 提取长程依赖的优势相结合。 Image-to-Tokens 模块 $$x&#39; = I2T(x) = MaxPool(BN(Conv(x))).$$</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Heterogeneous Attention Network (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn54/</link>
      <pubDate>Sun, 18 Jul 2021 19:39:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn54/</guid>
      <description>Heterogeneous Attention Network for Effective and Efficient Cross-modal Retrieval (SIGIR 2021) 背景 联合嵌入 (joint embedding) 方法的问题 只进行全局匹配 文本与图像只在匹配阶段有交互 多模态的 Transformer 系方法能够在较早的阶段实现跨模态交互，但</description>
    </item>
    
    <item>
      <title>Latex 中矩阵的几种实现方式</title>
      <link>http://jonathanwayy.xyz/2021/latex_matrix/</link>
      <pubDate>Sun, 18 Jul 2021 16:20:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_matrix/</guid>
      <description>记录一下 Latex 中实现矩阵的几种方式。 1. 无括号 代码 \begin{matrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{matrix} 效果 $$\begin{matrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{matrix}$$ 2. 圆括号 代码 \begin{pmatrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{pmatrix} % 或 \left(\begin{matrix} 0 &amp;amp; 1 \\ 2 &amp;amp; 3 \end{matrix}\right) 效果</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Cross-Graph Attention Model (SIGIR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn53/</link>
      <pubDate>Sun, 18 Jul 2021 11:25:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn53/</guid>
      <description>Cross-Graph Attention Enhanced Multi-Modal Correlation Learning for Fine-Grained Image-Text Retrieval (SIGIR 2021) 背景 SIGIR 2021 短文。 现有三类跨模态检索方法 全局相关性学习 局部相关性学习 高阶语义概念学习 在模态特定的语义概念 (modality-specific semantic concepts) 之外，还应</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Graph Structured Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn52/</link>
      <pubDate>Sun, 18 Jul 2021 10:10:07 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn52/</guid>
      <description>2004.00277 Graph Structured Network for Image-Text Matching (CVPR 2020) 开源代码传送门 总览 本文提出一种图结构匹配网络 (Graph Structured Matching Network, GSMN)，对目标、关系与属性显式建模。 以下两组相关性互相促进 细粒度目</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / ViT] M2TR: Multi-modal Multi-scale Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn51/</link>
      <pubDate>Sat, 17 Jul 2021 14:34:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn51/</guid>
      <description>2104.09770 M2TR: Multi-modal Multi-scale Transformers for Deepfake Detection (2021) 背景 Deepfake 检测任务。 本文提出一种多模态多尺度 Transformer (Multi-modal Multi-scale Transformer, M2TR)，包含一个多尺度 Transformer 模块 (MT) 和一个跨模态融合模块 (CMF)，利用频域</description>
    </item>
    
    <item>
      <title>Latex 添加无编号脚注</title>
      <link>http://jonathanwayy.xyz/2021/latex_footnote_without_number/</link>
      <pubDate>Sat, 17 Jul 2021 11:53:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_footnote_without_number/</guid>
      <description>在使用 Latex 的过程中，有时需要添加不带编号的脚注，目前尝试过有效的有两种办法，记录如下。 方法一 \renewcommand{\thefootnote}{} \footnotetext{脚注内容} 方法二 \l</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Frequency learning for image classification (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn50/</link>
      <pubDate>Fri, 16 Jul 2021 21:04:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn50/</guid>
      <description>2006.15476 Frequency learning for image classification (2020) 核心问题 如果一个神经网络完全设计成在频域进行操作会怎么样？ 本文设计了 FreqNet 研究上述问题。 本文方法 图像分块 对图像层级式地分块以提取多</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Global Filter Networks for Image Classification (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn49/</link>
      <pubDate>Fri, 16 Jul 2021 19:50:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn49/</guid>
      <description>2107.00645 Global Filter Networks for Image Classification (2021) 开源代码传送门 核心方法 本文提出一种全局滤波器网络 (Global Filter Network, GFNet)，在频域中学习空间位置之间的相互关系。 不同于视觉 transformer 中的自注</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Improving Image Classification With Frequency Domain Layers (MLSP 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn48/</link>
      <pubDate>Fri, 16 Jul 2021 15:02:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn48/</guid>
      <description>Improving image classification with frequency domain layers for feature extraction (MLSP 2017) 核心 研究从频域提取的特征对深度网络架构的作用。 提出频率特征提取层。 方法 对输入图像层级式分块以提取多粒度信息，对各块使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] High-Frequency Component Explain Generalization of CNNs (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn47/</link>
      <pubDate>Fri, 16 Jul 2021 10:29:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn47/</guid>
      <description>High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks (CVPR 2020) 背景 从数据视角研究 CNN 的泛化表现。 CNN 挖掘高频成分 将原始数据分解为高低频成分，\(x = \{x_{l}, x_{h}\}\)，分别简写为 LFC</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 人脸伪造检测] Spatial-Phase Shallow Learning (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn46/</link>
      <pubDate>Thu, 15 Jul 2021 21:12:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn46/</guid>
      <description>Spatial-Phase Shallow Learning: Rethinking Face Forgery Detection in Frequency Domain (CVPR 2021) 背景 人脸伪造检测 (face forgery detection) 任务。 在合成假脸过程中使用上采样，该操作通常会在频域留下痕迹。 核心方法与观点 本文提出一种空间-</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Multi-Modality Cross Attention Network (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn45/</link>
      <pubDate>Wed, 14 Jul 2021 10:42:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn45/</guid>
      <description>Multi-Modality Cross Attention Network for Image and Sentence Matching (CVPR 2020) 出发点 既考虑模态间关联，也考虑模态内关联。 提出多模态交叉注意力网络 (Multi-Modality Cross Attention Network)，主要由自注意力模块与交叉注意</description>
    </item>
    
    <item>
      <title>壁纸分享[25]</title>
      <link>http://jonathanwayy.xyz/2021/bg25/</link>
      <pubDate>Tue, 13 Jul 2021 14:27:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg25/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 图像去噪] NBNet: Noise Basis Learning with Subspace Projection (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn44/</link>
      <pubDate>Mon, 12 Jul 2021 21:56:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn44/</guid>
      <description>2012.15028 NBNet: Noise Basis Learning for Image Denoising with Subspace Projection (CVPR 2021) 核心思想 通过图像投影，利用非局部的图像信息。 由输入图像生成一组图像基向量 (image basis vectors)，接着在这些基向量张成</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] Non-Local Neural Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn43/</link>
      <pubDate>Mon, 12 Jul 2021 15:09:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn43/</guid>
      <description>Non-Local Neural Networks (CVPR 2018) 开源代码传送门 核心内容 提出非局部操作用于捕捉长距离依赖关系，通过输入特征图所有位置上特征的加权和计算各位置的响应值 (respons</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] CAMP: Cross-Modal Adaptive Message Passing (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn42/</link>
      <pubDate>Mon, 12 Jul 2021 10:58:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn42/</guid>
      <description>CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval (ICCV 2019) 开源代码传送门 背景 现有方法的问题 现有方法通常学习一个公共的嵌入空间，在其中衡量特征相似度，使用 ranking loss 进行训练。 这类方法没有</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 风格迁移] Photorealistic Style Transfer via Wavelet Transforms (ICCV 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn41/</link>
      <pubDate>Mon, 12 Jul 2021 10:12:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn41/</guid>
      <description>Photorealistic Style Transfer via Wavelet Transforms (ICCV 2019) 开源代码传送门 背景 风格迁移任务。 模型应当在不损伤图像细节的情况下实现风格迁移。 本文提出一种基于白化与色彩变换的小波矫正迁移 (wavelet</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Channel Shuffle 操作的 PyTorch 实现</title>
      <link>http://jonathanwayy.xyz/2021/channel-shuffle/</link>
      <pubDate>Sun, 11 Jul 2021 14:26:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/channel-shuffle/</guid>
      <description>在 ShuffleNet、SA-Net 以及一系列模型中涉及到了一种 Channel Shuffle 操作，用于在沿着通道维分组运算后保证各组特征之间能够有信息交互。 Channel Shuffle 的机</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] SA-Net: Shuffle Attention for Deep CNNs (ICASSP 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn40/</link>
      <pubDate>Sun, 11 Jul 2021 10:53:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn40/</guid>
      <description>2102.00240v1 SA-Net: Shuffle Attention for Deep Convolutional Neural Networks (ICASSP 2021) 开源代码传送门 背景 设计了 Shuffle Attention (SA) 模块，将特征沿着通道维分组，对每个子特征用 Shuffle 单元同时计算通道注意力与空间注意力。 Shuffle Attention (SA) 特</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 图像恢复] Multi-level Wavelet-CNN for Image Restoration (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn39/</link>
      <pubDate>Sat, 10 Jul 2021 16:41:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn39/</guid>
      <description>Multi-level Wavelet-CNN for Image Restoration (CVPR 2018) 背景 图像恢复 (Image Restoration) 的目的 从观测到的较差图像 \(y\) 恢复潜在的干净图像 \(x\)。 本文设计了一种多级小波 CNN (multi-level wavelet CNN, MWCNN) 模型，增大感受野，改善</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / Transformer] FNet: Mixing Tokens with Fourier Transforms (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn38/</link>
      <pubDate>Sat, 10 Jul 2021 15:34:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn38/</guid>
      <description>2105.03824 FNet: Mixing Tokens with Fourier Transforms (2021) 开源代码传送门 出发点 用更简单的 token 混合机制取代自注意力层。 最终选择傅利叶变换，设计了 FNet 模型。 离散傅利叶变换 (Discrete Fourier Transform, DFT) 傅利叶变换将</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT / 跨模态检索] Fine-grained Visual Textual Alignment (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn37/</link>
      <pubDate>Sat, 10 Jul 2021 11:14:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn37/</guid>
      <description>2008.05231 Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders (2020) 背景 在分类任务上预训练的 CNN 网络所提取的特征通常只能捕捉到图像的全局描述，而忽视了重要的局部细节。 现有方法的问题 由于交</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 多模态预训练] Unicoder-VL (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn36/</link>
      <pubDate>Sat, 10 Jul 2021 10:00:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn36/</guid>
      <description>Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training (AAAI 2020) 背景 尚未出现能够够直接处理跨模态任务与数据的预训练模型。 本文基于多层 Transformer 提出一种通用视觉语言编码器 (Universal Encoder for Vision And Language, Uni</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] Swin Transformer (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn35/</link>
      <pubDate>Fri, 09 Jul 2021 10:54:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn35/</guid>
      <description>2103.14030 Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (2021) 开源代码传送门 背景 Transformer 在视觉任务上的主要困难 视觉元素的尺度可能相当不同，但是当前工作中 token 都固定尺度 图像具有更高的像素分辨率</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Generating Adversarial Examples with Adversarial Networks (IJCAI 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn34/</link>
      <pubDate>Wed, 07 Jul 2021 11:06:29 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn34/</guid>
      <description>Generating Adversarial Examples with Adversarial Networks (IJCAI 2018) AdvGAN 模型架构 $$\mathcal{L}_{GAN} = \mathbb{E}_{x} log \mathcal{D}(x) + \mathbb{E}_{x} log(1 - \mathcal{D}(x + \mathcal{G}(x))),$$ $$\mathcal{L}_{adv}^{f} = \mathbb{E}_{x}\mathcal{l}_f(x + \mathcal{G}(x), t),$$ $$\mathcal{L}_{hinge} = \mathbb{E}_{x} max(0, ||\mathcal{G}(x)||_{2} - c),$$ $$\mathcal{L} = \mathcal{L}_{adv}^{f} + \alpha \mathcal{L}_{GAN} + \beta \mathcal{L}_{hinge}.$$ 样本可视化</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Query Attack via Opposite-Direction Feature (2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn33/</link>
      <pubDate>Tue, 06 Jul 2021 15:13:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn33/</guid>
      <description>1809.02681 Query Attack via Opposite-Direction Feature:Towards Robust Image Retrieval (2018) 背景 现有分类攻击方法在在检索场景中的困难 其目标是类别预测，与检索任务不同 检索场景中训练时的类别与测试时通常是不同的 本文针</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Nyquist 频率与 Nyquist 间隔</title>
      <link>http://jonathanwayy.xyz/2021/ldp9/</link>
      <pubDate>Tue, 06 Jul 2021 11:36:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp9/</guid>
      <description>若带限信号 \(x(t)\) 的最高角频率为 \(\omega_{m}\)，则在一定条件下，信号 \(x(t)\) 可以用等间隔 \(T\) 的抽样值唯一表示。 抽样间隔 \(T\) 需满足： $$T \le \frac{\pi}{\omega_{m}} = \frac{1}{2f_{m}},$$ 或</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 时域抽样定理</title>
      <link>http://jonathanwayy.xyz/2021/ldp8/</link>
      <pubDate>Tue, 06 Jul 2021 11:24:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp8/</guid>
      <description>时域抽样定理 设 \(X(j\omega)\) 和 \(X(e^{j\Omega})\) 分别表示连续时间信号 \(x(t)\) 和离散时间信号 \(x[k]\) 的频谱，即 $$X(j\omega) = \int_{-\infty}^{\infty}x(t)e^{-j\omega t}dt, \ X(e^{j\Omega}) = \sum_{-\infty}^{\infty} x[k]e^{-j\Omega k}.$$ 若存在 $$x[k] = x(t)|_{t = kT},$$ 则有 $$X(e^{j\Omega}) = \frac{1}{T}\sum_{-\infty}^{+\infty} X[j(\omega - n\omega_{sam})], \quad \omega_{sam} = 2\pi/T, \quad \Omega = \omega T.$$ 表</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- ViT] XCiT: Cross-Covariance Image Transformers (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn32/</link>
      <pubDate>Mon, 05 Jul 2021 12:59:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn32/</guid>
      <description>2106.09681 XCiT: Cross-Covariance Image Transformers (2021) 开源代码传送门 背景 Transformers 中自注意力模块计算复杂度高。 本文用一种转置的注意力 (transposed attention) 取代自注意力，称为交叉协方差注意力 (cross-covariance attention, XCA)，其对于</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索 / 图网络] Similarity Reasoning and Filtration (AAAI 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn31/</link>
      <pubDate>Sat, 03 Jul 2021 21:00:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn31/</guid>
      <description>2101.01368 Similarity Reasoning and Filtration for Image-Text Matching (AAAI 2021) 开源代码传送门 先前方法的缺陷 在局部特征之间计算基于标量的余弦相似度，可能并不足以表征区域与单词之间的关联模式 大多数方法使</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 注意力机制] VOLO: Vision Outlooker for Visual Recognition (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn30/</link>
      <pubDate>Sat, 03 Jul 2021 16:23:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn30/</guid>
      <description>2106.13112v2 VOLO: Vision Outlooker for Visual Recognition (2021) 背景 制约 ViT 不如 CNN 的一个主要因素 ViT 在将细粒度特征以及上下文编码成 token 时效率较低。 本文设计了一种简单轻量的注意力机制，称为 Outl</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本 / ReID] Vulnerability of Person Re-Identification Models (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn29/</link>
      <pubDate>Fri, 02 Jul 2021 11:05:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn29/</guid>
      <description>Vulnerability of Person Re-Identification Models to Metric Adversarial Attacks (CVPR 2020) 背景 闭集 (closed-set) 任务，即训练与测试使用同样类别的任务上对抗样本已经有了较广泛的研究，开集 (open-set) 任务如 ReID 上的相关研究较少。 为了骗过</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 遮挡 ReID] High-Order Information Matters (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn28/</link>
      <pubDate>Thu, 01 Jul 2021 13:01:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn28/</guid>
      <description>High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification (CVPR 2020) 背景 本文研究遮挡 ReID 问题 (Occluded Person Re-Identification)，该问题主要受到遮挡 (occlusion) 和出界 (outliers) 两个问题困扰。大部分现</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 文本对抗样本] Seq2Sick: Evaluating Robustness of Seq2Seq Models (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn27/</link>
      <pubDate>Tue, 29 Jun 2021 21:36:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn27/</guid>
      <description>Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples (AAAI 2020) 开源代码传送门 背景 对抗攻击可用于衡量 DNN 的鲁棒性，对抗样本越容易生成则模型越健壮。 攻击图像比攻击文本容易得多，因为图像</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 图网络] Beyond Low-frequency Information in GCNs (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn26/</link>
      <pubDate>Tue, 29 Jun 2021 12:00:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn26/</guid>
      <description>2101.00797 Beyond Low-frequency Information in Graph Convolutional Networks 背景 当前一些研究认为平滑信号，即低频信息是 GNN 成功的关键。 本文重点思考是否低频信息就能完全满足需求，以及其他信息在 GNN 中扮演着怎</description>
    </item>
    
    <item>
      <title>壁纸分享[24]</title>
      <link>http://jonathanwayy.xyz/2021/bg24/</link>
      <pubDate>Tue, 29 Jun 2021 11:39:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg24/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 图网络] Spectral Graph Attention Network (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn25/</link>
      <pubDate>Mon, 28 Jun 2021 19:34:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn25/</guid>
      <description>2003.07450 Spectral Graph Attention Network (2020) 背景 图注意力网络 (Graph Attention Network, GAT) 通过引入注意力机制优化 GCN 的卷积过程。具体来说，在节点聚合 (node aggregation) 阶段，GAT 赋予各边一个自注意力权重，用于捕</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 带噪跨模态检索] Learning Cross-Modal Retrieval With Noisy Labels (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn24/</link>
      <pubDate>Mon, 28 Jun 2021 11:45:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn24/</guid>
      <description>Learning Cross-Modal Retrieval With Noisy Labels (CVPR 2021) 背景 为了应对较高的数据标注成本，大规模数据会用到一些非专业的标注资源，从而不可避免地在标签中引入了噪音信息。 由图 2 可以看出，</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] Cross-Modal Learning with Adversarial Samples (NeurIPS 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn23/</link>
      <pubDate>Sun, 27 Jun 2021 13:29:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn23/</guid>
      <description>Cross-Modal Learning with Adversarial Samples (NeurIPS 2019) 文中主要以跨模态哈希检索为例，其搜索空间大致可分为四个部分：T2T、I2I、I2T/T2I、NR (not relevant)。 理想的针</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 对抗样本] AI-GAN: Attack-Inspired Generation of Adversarial Examples (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn22/</link>
      <pubDate>Sat, 26 Jun 2021 15:10:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn22/</guid>
      <description>2002.02196 AI-GAN: Attack-Inspired Generation of Adversarial Examples (2020) 本文设计了一种新的 GAN 的变体，称为 Attack-Inspired GAN (AI-GAN) 用于生成对抗扰动。 AI-GAN 的训练包含两个阶段： 第一阶段，联合训练一个生成器、一个鉴别器和一个</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域 / 迁移学习] FSDR: Frequency Space Domain Randomization (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn21/</link>
      <pubDate>Sat, 26 Jun 2021 11:27:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn21/</guid>
      <description>FSDR: Frequency Space Domain Randomization for Domain Generalization (CVPR 2021) 背景 语义分割受限于数据标注的难度，因此带有自动生成标签的合成图像成了缓解这一问题的一个选择。 但是这类模型由于域偏置与偏移</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 低版本 PyTorch 中 pack_padded_sequence 缺少 enforce_sorted 参数问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp7/</link>
      <pubDate>Sat, 26 Jun 2021 10:35:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp7/</guid>
      <description>背景 近期用到了一台新的堡垒机，上面的驱动环境比较老只能用 1.0.0 版本的 PyTorch。 调试了代码以后发现大体上没有遇到什么问题，唯一就是涉及到 GRU 的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] Learning in the Frequency Domain (CVPR 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn20/</link>
      <pubDate>Fri, 25 Jun 2021 15:44:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn20/</guid>
      <description>Learning in the Frequency Domain (CVPR 2020) 出发点 受计算资源与内存限制，大多数 CNN 模型只用低分辨率的 RGB 图像作为输入，处理现实中高分辨率图像时要先缩小尺寸，而这一过程难免带来</description>
    </item>
    
    <item>
      <title>Latex 希腊字母</title>
      <link>http://jonathanwayy.xyz/2021/latex_greeceletter/</link>
      <pubDate>Fri, 25 Jun 2021 11:30:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_greeceletter/</guid>
      <description>记录一下 Latex 中的希腊字母实现，以备查用。 小写 代码 大写 代码 \(\alpha\) \alpha \(\Alpha\) \(A\) \Alpha A \(\beta\) \beta \(\Beta\) \(B\) \Beta B \(\gamma\) \gamma \(\Gamma\) \Gamma \(\delta\) \delta \(\Delta\) \Delta \(\epsilon\) \(\varepsilon\) \epsilon \varepsilon \(\Epsilon\) \(E\) \Epsilon E \(\zeta\) \zeta \(\Zeta\) \(Z\) \Zeta Z \(\eta\) \eta \(\Eta\) \(H\) \Eta H \(\theta\) \(\vartheta\) \theta</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 带限函数</title>
      <link>http://jonathanwayy.xyz/2021/ldp6/</link>
      <pubDate>Thu, 24 Jun 2021 22:32:06 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp6/</guid>
      <description>定义 若一个函数对于以原点为中心的有限区间（带宽） \([-\mu_{max}, \mu_{max}]\)以外的频率值，其傅里叶变换均为 0，则称之为带限函数*。*</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 卷积定理</title>
      <link>http://jonathanwayy.xyz/2021/conv-theory/</link>
      <pubDate>Thu, 24 Jun 2021 21:23:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/conv-theory/</guid>
      <description>卷积定义 用算子 \(\star\) 表示两个函数的卷积，定义为 $$(f \star h)(t) = \int_{-\infty}^{\infty} f(\tau)h(t-\tau)d\tau.$$ 卷积定理 空间域中两个函数的卷积的傅里叶变换，等于频率域中两个函数傅里叶变换的乘积。反过</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Graph Convolutional Network Hashing (IJCAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn19/</link>
      <pubDate>Thu, 24 Jun 2021 15:26:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn19/</guid>
      <description>Graph Convolutional Network Hashing for Cross-Modal Retrieval (IJCAI 2019) 本文提出一种针对跨模态检索的图卷积网络哈希 (graph convolution network hashing, GCH)，由一个语义编码器、两个特征编码网络和一个基于融合模块的图卷积网</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- ValueError: only one element tensors can be converted to Python scalars 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp5/</link>
      <pubDate>Thu, 24 Jun 2021 00:01:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp5/</guid>
      <description>问题描述 形如以下操作： lst = [] a, b = torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6]) lst.append(a) lst.append(b) converted_lst = torch.tensor(lst) 得到如下报错信息： ValueError: only one element tensors can be converted to Python scalars 原因分析 元素为 tensor 的 list 无法转化为 tensor。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-modal Scene Graph Matching (WACV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn18/</link>
      <pubDate>Wed, 23 Jun 2021 09:36:01 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn18/</guid>
      <description>Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval (WACV 2020) 出发点 正确的匹配除了要包含相同的目标以外，目标之间的关系也应当相同。 因而，本文使用视觉场景图 (visual scene graph, VSG) 和文本场景图 (textual scene graph, TSG)</description>
    </item>
    
    <item>
      <title>Latex 分段函数的一种实现方式</title>
      <link>http://jonathanwayy.xyz/2021/latex_case/</link>
      <pubDate>Tue, 22 Jun 2021 21:05:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_case/</guid>
      <description>代码实现 $$f(x) = \begin{cases} 2x + 1, \quad if \ x &amp;gt; 1, \\\\ -3x, \quad if \ x \le 1.\end{cases}$$ 呈现效果 $$f(x) = \begin{cases} 2x + 1, \quad if \ x &amp;gt; 1, \\ -3x, \quad if \ x \le 1.\end{cases}$$</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Cross-Modal Center Loss (CVPR 2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn17/</link>
      <pubDate>Tue, 22 Jun 2021 19:53:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn17/</guid>
      <description>Cross-Modal Center Loss for 3D Cross-Modal Retrieval (CVPR 2021) 现有方法的问题 核心思想是最小化由预训练网络提取的多模态特征之间的跨模态差异，而这些预训练网络应当与跨模态数据联合训练 现有的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Deep Cross-Modal Hashing (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn16/</link>
      <pubDate>Tue, 22 Jun 2021 16:33:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn16/</guid>
      <description>Deep Cross-Modal Hashing (CVPR 2017) 哈希的目标 将原始空间数据点映射为汉明空间中的二进制编码，在汉明空间中保留原始空间中的相似度。 两类多模态哈希 (Multi-Modal Hashing, MMH) 多源哈希 (multi-source hashing, MSH) 目的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态哈希] Self-Supervised Adversarial Hashing Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn15/</link>
      <pubDate>Tue, 22 Jun 2021 10:54:41 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn15/</guid>
      <description>Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval (CVPR 2018) 当前(当时)跨模态哈希方法的主要不足 直接使用单类标签来衡量跨模态的语义关联，而事实上标准的跨模态数据集中一个图像实例往往能</description>
    </item>
    
    <item>
      <title>BLWL[40] Manjaro/Archlinux “...” 的签名是未知信任的 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/blwl40/</link>
      <pubDate>Mon, 21 Jun 2021 19:47:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/blwl40/</guid>
      <description>问题描述 Manjaro/ArchLinux 使用 pacman 更新时遇到如下形式的问题： &amp;gt; sudo pacman -Syu ... ... (748/748) 正在检查密钥环里的密钥 [######################] 100% (748/748) 正在检查软件包完整性 [######################] 100% 错误：xxxxx: 来自 &amp;quot;xxxxxxxxxx&amp;quot; 的签名是</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] AXM-Net: Cross-Modal Context Sharing Attention Network (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn14/</link>
      <pubDate>Mon, 21 Jun 2021 14:24:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn14/</guid>
      <description>2101.08238 AXM-Net: Cross-Modal Context Sharing Attention Network for Person Re-ID (2021) 主要困难 各模态中与行人相关的信息结构相当不同 关键在于学习一个能够从数据中提取语义的网络，而不是在训练过程中简单记住各行</description>
    </item>
    
    <item>
      <title>Latex 公式中的空格表示</title>
      <link>http://jonathanwayy.xyz/2021/latex_space/</link>
      <pubDate>Mon, 21 Jun 2021 14:11:57 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_space/</guid>
      <description>类型 代码 效果 备注 两个 quad 空格 a \qquad b \(a \qquad b\) 两个 M 的宽度 quad 空格 a \quad b \(a \quad b\) 一个 M 的宽度 大空格 a\ b \(a \ b\) 1/3 M 的宽度 中等空格 a\;b \(a \; b\) 2/7 M 的宽度 小空格 a\,b</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 频域] FcaNet: Frequency Channel Attention Networks (2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn13/</link>
      <pubDate>Sun, 20 Jun 2021 14:25:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn13/</guid>
      <description>2012.11879 FcaNet: Frequency Channel Attention Networks (2020) 利用频率分析重新思索通道注意力，并从数学上证明传统的全局平均池化 (GAP) 是频域中特征分解的一种特殊情况。 GAP 的潜在问题 尽管简洁高效， GAP</description>
    </item>
    
    <item>
      <title>壁纸分享[23]</title>
      <link>http://jonathanwayy.xyz/2021/bg23/</link>
      <pubDate>Sat, 19 Jun 2021 13:29:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg23/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Deep Adversarial Graph Attention Convolution Network (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn12/</link>
      <pubDate>Thu, 17 Jun 2021 20:35:36 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn12/</guid>
      <description>Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search (MM 2019) 先前工作的问题 孤立对待图像中的局部块，只考虑文本描述中单词级别的上下文关联，因而忽略了图文所包含的结构化语义信息 (structured semantic</description>
    </item>
    
    <item>
      <title>Latex 插入空行</title>
      <link>http://jonathanwayy.xyz/2021/latex_spaceline/</link>
      <pubDate>Wed, 16 Jun 2021 20:38:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_spaceline/</guid>
      <description>有时需要在 Latex 文档中插入一个空行，查阅一些文档并做了一些尝试后，发现了一种较为简单的方法： \\ \hspace*{\fill} \\ 即换行，用空格填充后，再次换行。</description>
    </item>
    
    <item>
      <title>Latex 取消段首缩进</title>
      <link>http://jonathanwayy.xyz/2021/latex_noindent/</link>
      <pubDate>Wed, 16 Jun 2021 20:28:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_noindent/</guid>
      <description>要取消 Latex 段首缩进，可以在需要处理的段落前加上如下代码： \noindent</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] TIPCB: A Simple but Effective Part-based Convolutional Baseline</title>
      <link>http://jonathanwayy.xyz/2021/prn11/</link>
      <pubDate>Tue, 15 Jun 2021 13:42:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn11/</guid>
      <description>2105.11628 TIPCB: A Simple but Effective Part-based Convolutional Baseline for Text-based Person Search 视觉特征学习 在视觉 CNN 分支，ResNet-50 第 3 和第 4 个残差块的输出分别作为低级特征图和高级特征图。 用 GMP 聚合低级特</description>
    </item>
    
    <item>
      <title>BLWL[39] yay 遇到 Error: Rate limit reached 问题解决办法</title>
      <link>http://jonathanwayy.xyz/2021/blwl39/</link>
      <pubDate>Fri, 11 Jun 2021 11:39:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/blwl39/</guid>
      <description>在使用 yay -S &amp;lt;软件名&amp;gt; 安装时遇到如下错误： Error: Rate limit reached 尝试后发现一个有效的替代命令可以解决这个问题： pamac build &amp;lt;软件名&amp;gt; 特此记录</description>
    </item>
    
    <item>
      <title>Matplotlib 颜色表</title>
      <link>http://jonathanwayy.xyz/2021/matplotlib-color/</link>
      <pubDate>Sun, 06 Jun 2021 16:46:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/matplotlib-color/</guid>
      <description>Matplotlib 中的颜色表如下图所示，可以直接通过参数color=&#39;颜色名称&#39;选取对应的颜色。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Reasoning with Heterogeneous Graph Alignment (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn10/</link>
      <pubDate>Thu, 03 Jun 2021 18:30:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn10/</guid>
      <description>Reasoning with Heterogeneous Graph Alignment for Video Question Answering 出发点 需要一个统一的方法同步对模态间和模态内的关联性进行建模与推理。 本文所提到的 “视频段 (video shot)” 指的是一小段能被 3D 卷</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Object-Centric Representation Learning (2021)</title>
      <link>http://jonathanwayy.xyz/2021/prn9/</link>
      <pubDate>Tue, 01 Jun 2021 09:48:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn9/</guid>
      <description>2104.05166 Object-Centric Representation Learning for Video Question Answering 模型高训练度带来的问题 这类模型更倾向于捕捉浅层模式 (shallow patterns)，因而会在浅层统计量形成捷径 (creating shortcuts through surface statistic</description>
    </item>
    
    <item>
      <title>壁纸分享[22]</title>
      <link>http://jonathanwayy.xyz/2021/bg22/</link>
      <pubDate>Mon, 31 May 2021 13:24:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg22/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Location-Aware Graph Convolutional Networks (AAAI 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn8/</link>
      <pubDate>Sun, 30 May 2021 14:39:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn8/</guid>
      <description>Location-aware graph convolutional networks for video question answering (AAAI 2020) 与 IQA 相比 VQA 的几个困难 由于视频包含大量帧，其视觉内容更为复杂，尤其是其中一些帧主要被与问题无关的背景内容 (strong background content) 占据 视频通常</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Beyond RNNs: Positional Self-Attention with Co-Attention(AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn7/</link>
      <pubDate>Sat, 29 May 2021 14:57:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn7/</guid>
      <description>Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering (AAAI 2019) RNN + Attention 方法问题 耗时 由于 RNN 的特点，难以建模长距离依赖关系 本文提出了一个名为 Positional Self-Attention with Co-attention (PSAC) 的新架构，是首个无需使用 RNN 的模型。</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- 跨模态检索] Consensus-Aware Visual-Semantic Embedding (ECCV 2020)</title>
      <link>http://jonathanwayy.xyz/2021/prn6/</link>
      <pubDate>Sat, 29 May 2021 10:55:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn6/</guid>
      <description>2007.08883 Consensus-Aware Visual-Semantic Embedding for Image-Text Matching (ECCV 2020) 当前主流方法 将图像与文本投影到一个公共空间，通常无法充分利用图像中目标以及句子段之间的关系 分块级别的匹配 (fragment-level matching) + 聚合其相似度</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Learnable Aggregating Net with Diversity Learning (MM 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn5/</link>
      <pubDate>Fri, 28 May 2021 19:43:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn5/</guid>
      <description>Learnable Aggregating Net with Diversity Learning for Video Question Answering (MM 2019) V-VQA 三个难点 视频通常包含大量冗余信息 一些视频相关问题涉及多个关键帧，较难定位 有效聚合视频与句子特征以捕捉回答真实分布的</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Structured Two-stream Attention Network (AAAI 2019)</title>
      <link>http://jonathanwayy.xyz/2021/prn4/</link>
      <pubDate>Fri, 28 May 2021 15:21:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn4/</guid>
      <description>Structured two-stream attention network for video question answering (AAAI 2019) 图像 QA 中两种注意力机制 visual attention: &amp;ldquo;where to look&amp;rdquo; question attention: &amp;ldquo;what words to listen to&amp;rdquo; 视频 QA 三个主要困难 考虑长距离时域结构，同时不遗漏重要信息 为了定位相关视频实</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Motion-Appearance Co-Memory Networks (CVPR 2018)</title>
      <link>http://jonathanwayy.xyz/2021/prn3/</link>
      <pubDate>Fri, 28 May 2021 14:06:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn3/</guid>
      <description>Motion-Appearance Co-Memory Networks for Video Question Answering (CVPR 2018) 视频 QA 与 图像 QA 相比三个独有特性 处理较长的图像序列，包含更丰富的信息（数量上及多样性上） 动作与外观信息通常互相关联，能够彼此</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] Gradually Refined Attention (MM 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn2/</link>
      <pubDate>Thu, 27 May 2021 13:55:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn2/</guid>
      <description>Video Question Answering via Gradually Refined Attention over Appearance and Motion (MM17) 延伸模型的缺陷 由 video captioning 与 ImageQA 等任务延伸而来的模型容易弱化或忽视视频的时域信息 这些模型将整个问题编码为单一特征，不具有足够</description>
    </item>
    
    <item>
      <title>[论文阅读笔记 -- VQA] TGIF-QA (CVPR 2017)</title>
      <link>http://jonathanwayy.xyz/2021/prn1/</link>
      <pubDate>Thu, 27 May 2021 13:49:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/prn1/</guid>
      <description>Tgif-qa: Toward spatio-temporal reasoning in visual question answering (CVPR 2017) 开源代码传送门 三点重要贡献 提出专为视频 VQA 设计的三种新任务，需要对视频的时空推断(spatio-temporal reaso</description>
    </item>
    
    <item>
      <title>壁纸分享[21]</title>
      <link>http://jonathanwayy.xyz/2021/bg21/</link>
      <pubDate>Fri, 14 May 2021 19:58:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg21/</guid>
      <description></description>
    </item>
    
    <item>
      <title>OpenCV 与 PIL.Image 之间的图像通道（channel）转换</title>
      <link>http://jonathanwayy.xyz/2021/opencv-pil-channel/</link>
      <pubDate>Fri, 14 May 2021 19:46:19 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/opencv-pil-channel/</guid>
      <description>今天有学弟提到了一个打开图像并显示时图像色调变蓝的问题，经历一番周折后最终解决，在此记录。 问题的根本原因在于 OpenCV 默认是以 BGR 的通道顺序打开和显示</description>
    </item>
    
    <item>
      <title>Markdown 数学符号与公式</title>
      <link>http://jonathanwayy.xyz/2021/md-signs/</link>
      <pubDate>Mon, 10 May 2021 13:45:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/md-signs/</guid>
      <description>符号 代码 描述 \(\sum\) $\sum$ 求和公式 \(\sum_{i=0}^n\) $\sum_{i=0}^n$ 求和上下标 \(\pm\) $\pm 正负号 \(\times\) $\times$ 乘号 \(\div\) $\div$ 除号 \(\mid\) $\mid$ 竖线 \(\cdot\) $\cdot$ 点 \(\circ\) $circ$ 圈 未完待续</description>
    </item>
    
    <item>
      <title>辛格函数 sinc 杂记</title>
      <link>http://jonathanwayy.xyz/2021/sinc/</link>
      <pubDate>Mon, 10 May 2021 13:21:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/sinc/</guid>
      <description>sinc 函数在不同领域有不同的定义，用符号 \(sinc(x)\) 表示，可被定义为归一化的或者非归一化的，不过两种函数都是正弦函数和单调递减函数 \(\frac{1}{x}\) 的乘积。 数字信号处理和</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- Pytorch view 函数 RuntimeError 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp4/</link>
      <pubDate>Sat, 08 May 2021 18:37:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp4/</guid>
      <description>问题描述 在程序中使用形如 A = X.view(32, -1) 的语句调用 view 时出现如下报错： RuntimeError: view size is not compatible with input tensor&#39;s size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead. 原因分析 view() 需要 Tensor 中元素地址连续，</description>
    </item>
    
    <item>
      <title>壁纸分享[20]</title>
      <link>http://jonathanwayy.xyz/2021/bg20/</link>
      <pubDate>Tue, 27 Apr 2021 16:52:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg20/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[38] 激活 vmware 中的 Windows 操作系统</title>
      <link>http://jonathanwayy.xyz/2021/vmware-windows-activate/</link>
      <pubDate>Tue, 27 Apr 2021 14:19:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/vmware-windows-activate/</guid>
      <description>为了方便平时工作（主要是为了用 visio 做图），之前在 vmware 中配置了一个 Windows 10 的虚拟机。 一般的在物理机上适用的激活方式尝试后没能成功在虚拟机中激活 Wind</description>
    </item>
    
    <item>
      <title>ACM 会议论文模板去除 ACM Reference Format 信息</title>
      <link>http://jonathanwayy.xyz/2021/latex_acmtem/</link>
      <pubDate>Fri, 16 Apr 2021 18:48:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/latex_acmtem/</guid>
      <description>在投稿撰文时，可以去掉 ACM 的 latex 模板中会有的 ACM Reference Format 信息。 方法如下： 在 \documentclass[sigconf]{acmart} 下面添加以下几行： \settopmatter{printacmref=false} % Removes citation information below abstract \renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column \pagestyle{plain} % removes running headers</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 《三级笔译实务教材》 学习笔记</title>
      <link>http://jonathanwayy.xyz/2021/catti-swjc3-notes/</link>
      <pubDate>Sat, 10 Apr 2021 20:29:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-swjc3-notes/</guid>
      <description>第一章 经济篇 第一单元 经济贸易 英语的法律表达习惯 同一概念常用两个同义词或三联词来表达。 英汉语义重心差异 英语句子语义一般前重后轻，汉语反之。 译法</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 习语积累</title>
      <link>http://jonathanwayy.xyz/2021/catti-idiom-notes/</link>
      <pubDate>Fri, 09 Apr 2021 16:55:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-idiom-notes/</guid>
      <description>Eng Chi pull one&amp;rsquo;s leg 开玩笑 stand head and shoulders above others 鹤立鸡群 throw a sprat to catch a whale 吃小亏占大便宜 Jack of all trades 多面手</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 庄绎传《英汉翻译简明教程》学习笔记 (Part II)</title>
      <link>http://jonathanwayy.xyz/2021/catti-scect2-notes/</link>
      <pubDate>Thu, 08 Apr 2021 21:14:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-scect2-notes/</guid>
      <description>英汉差异对比 1. 实称、代称与重复 (1) 代词 英语代词用得多，汉语代词用得少。 英语有时先出代词，汉语一般先出实词。 汉译英要在适当的地方增加代词。</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- GELU 激活函数的 Pytorch 实现</title>
      <link>http://jonathanwayy.xyz/2021/ldp3/</link>
      <pubDate>Thu, 25 Mar 2021 17:48:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp3/</guid>
      <description>Transformers 中提出了一个新的激活函数 GELU，由于比较新，该模块仅在 1.8 以上版本的 Pytorch 中被收录。 要在较低版本的 Pytorch 中使用 GELU，可自行编写实现，代码如下：</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 庄绎传《英汉翻译简明教程》学习笔记 (Part I)</title>
      <link>http://jonathanwayy.xyz/2021/catti-scect-notes/</link>
      <pubDate>Sun, 21 Feb 2021 16:02:55 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-scect-notes/</guid>
      <description>Unit 1 Stories Lesson 1 (E - C) 汉译英时“身份”的处理 汉译英时，不一定要把“身份”译作 capacity，可以根据上下文，译作 who he was， who I am 等。 对初学翻译</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 韩刚《90 天攻克 CATTI 三级笔译》学习笔记</title>
      <link>http://jonathanwayy.xyz/2021/catti-hg903-notes/</link>
      <pubDate>Fri, 19 Feb 2021 21:51:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-hg903-notes/</guid>
      <description>第一循环 2006年真题实务 中英文一个差异 —— 事实与评论 中文结构事实、背景在前，表态、判断、结论在后，英文恰恰相反。 一个原则 —— “舍宏观概括，</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 武峰《十二天突破英汉翻译》学习笔记</title>
      <link>http://jonathanwayy.xyz/2021/catti-wf12-notes/</link>
      <pubDate>Sat, 13 Feb 2021 21:26:22 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-wf12-notes/</guid>
      <description>第一天 突破英文中定语从句的翻译（一） 词组和句子修饰单词时后置，翻译成中文前置。 英译汉“三部曲” 断句、翻译、重读。 英文中介词的翻译方法 翻译成中</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 冠词规律总结</title>
      <link>http://jonathanwayy.xyz/2021/catti-article-notes/</link>
      <pubDate>Sun, 07 Feb 2021 22:45:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-article-notes/</guid>
      <description>复数前面一般不加定冠词，除非后面跟定于从句（或其缩略式）进行限定 明确特指对象一般要加定冠词 &amp;ldquo;of&amp;rdquo; 前的单数名词一般要加定冠词，固定词组除外 同位语进</description>
    </item>
    
    <item>
      <title>[CATTI 备考笔记] -- 词汇</title>
      <link>http://jonathanwayy.xyz/2021/catti-vocab-notes/</link>
      <pubDate>Sat, 06 Feb 2021 13:26:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/catti-vocab-notes/</guid>
      <description>Eng Chi Notes full of prunes 愚蠢透顶的；完全错误的；浮夸的；活跃的；兴高采烈的；精力充沛的 prunes and prisms （言行的）装腔作势，矫揉造作 grate on sb. 把某人惹火了 a tenuous hope 一线希望</description>
    </item>
    
    <item>
      <title>壁纸分享[19]</title>
      <link>http://jonathanwayy.xyz/2021/bg19/</link>
      <pubDate>Fri, 22 Jan 2021 14:33:34 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>炼丹杂记 -- nvidia-smi指令报错：Failed to initialize NVML 解决方案</title>
      <link>http://jonathanwayy.xyz/2021/ldp2/</link>
      <pubDate>Fri, 22 Jan 2021 14:27:20 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/ldp2/</guid>
      <description>问题描述 使用指令 nvidia-smi 时报错： Failed to initialize NVML: Driver/library version mismatch 问题原因 NVIDIA 内核驱动版本与系统驱动不一致。 解决办法 网上有很多调整驱动版本的方法教程，但其实最简单的方法</description>
    </item>
    
    <item>
      <title>壁纸分享[18]</title>
      <link>http://jonathanwayy.xyz/2021/bg18/</link>
      <pubDate>Wed, 20 Jan 2021 01:22:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2021/bg18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>壁纸分享[17]</title>
      <link>http://jonathanwayy.xyz/2020/bg17/</link>
      <pubDate>Wed, 23 Dec 2020 13:19:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg17/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[37] 简单干净卸载 cuda 的方法</title>
      <link>http://jonathanwayy.xyz/2020/blwl37/</link>
      <pubDate>Sat, 19 Dec 2020 21:00:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl37/</guid>
      <description>网上有各种有关如何通过一系列命令卸载 cuda 的教程，但其实 cuda 是自带卸载脚本的。 第一步： 找到 cuda 所在路径 cuda 位于 /usr/local/cuda/bin 目录下。 进入目录后运行卸载脚本： sudo ./uninstall_cuda_10.0.pl 第</description>
    </item>
    
    <item>
      <title>通过 Conda 安装 Python OpenCV</title>
      <link>http://jonathanwayy.xyz/2020/conda-opencv/</link>
      <pubDate>Fri, 18 Dec 2020 00:33:49 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/conda-opencv/</guid>
      <description>可通过以下命令安装 OpenCV： conda install -c menpo opencv</description>
    </item>
    
    <item>
      <title>壁纸分享[16]</title>
      <link>http://jonathanwayy.xyz/2020/bg16/</link>
      <pubDate>Tue, 15 Dec 2020 00:04:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg16/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[36] Ubuntu 安装显卡驱动时 No additional drivers available 问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl36/</link>
      <pubDate>Mon, 14 Dec 2020 23:50:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl36/</guid>
      <description>新配置的 Ubuntu 炼丹工作站在通过 Software and Updates 中的 Additional Drivers 选项卡安装 GPU 显卡驱动时出现了 No additional drivers available 的问题。 解决方案如下。 sudo add-apt-repository ppa:xorg-edgers/ppa sudo apt-get update 完成后回到 Software and Updates 中的 Additional Drivers 选项卡</description>
    </item>
    
    <item>
      <title>BLWL[35] Ubuntu 上向日葵被连接时闪退问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl35/</link>
      <pubDate>Mon, 14 Dec 2020 23:18:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl35/</guid>
      <description>新配置的 Ubuntu 炼丹工作站上装的向日葵一被连接就闪退，查阅了一些资料后顺利解决了这个问题，具体方法如下。 sudo apt-get update sudo apt-get upgrade sudo apt-get install lightdm 安装 lightdm 的过程中会让选择</description>
    </item>
    
    <item>
      <title>BLWL[34] Vim 设置背景透明</title>
      <link>http://jonathanwayy.xyz/2020/blwl34/</link>
      <pubDate>Tue, 08 Dec 2020 04:55:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl34/</guid>
      <description>Vim 通过 colorscheme 设置了主题后，通常背景会变成实色，想要让 Vim 的背景色跟随终端的透明度配置，在 .vimrc 文件中加入如下一行即可： hi Normal ctermfg=255 ctermbg=none</description>
    </item>
    
    <item>
      <title>压缩图表空间以调整 Latex 版面</title>
      <link>http://jonathanwayy.xyz/2020/latex_vspace/</link>
      <pubDate>Sun, 06 Dec 2020 23:51:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/latex_vspace/</guid>
      <description>很多会议论文都有特定的模板格式，并且在篇幅上有所限制，为了尽可能地多写一点内容，可以考虑在图像、表格、公式中利用 \vspace{} 来压缩垂直距离。 例如： \begin{figure*}[t] \vspace{-1.0cm}</description>
    </item>
    
    <item>
      <title>壁纸分享[15]</title>
      <link>http://jonathanwayy.xyz/2020/bg15/</link>
      <pubDate>Sat, 14 Nov 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg15/</guid>
      <description></description>
    </item>
    
    <item>
      <title>炼丹杂记 -- &#39; xsrf&#39; argument missing from POST 解决方法</title>
      <link>http://jonathanwayy.xyz/2020/ldp1/</link>
      <pubDate>Thu, 12 Nov 2020 12:47:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/ldp1/</guid>
      <description>问题描述 Jupyter Notebook 保存时出现 ‘_xsrf’ argument missing from POST 错误，保存失败。 解决方法 刷新 Jupyter Notebook 的 home 界面即可，简单粗暴，亲测有效。</description>
    </item>
    
    <item>
      <title>壁纸分享[14]</title>
      <link>http://jonathanwayy.xyz/2020/bg14/</link>
      <pubDate>Sat, 24 Oct 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg14/</guid>
      <description></description>
    </item>
    
    <item>
      <title>花书 阅读笔记</title>
      <link>http://jonathanwayy.xyz/2020/flower-book-notes/</link>
      <pubDate>Mon, 05 Oct 2020 19:34:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/flower-book-notes/</guid>
      <description>Chapter 1 硬编码知识体系 —— 知识库方法（Cyc） 从原始数据中提取模式 —— 机器学习 简单的机器学习算法的性能很大程度上以来于给定数据的表示 很难知道该提</description>
    </item>
    
    <item>
      <title>壁纸分享[13]</title>
      <link>http://jonathanwayy.xyz/2020/bg13/</link>
      <pubDate>Thu, 24 Sep 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg13/</guid>
      <description></description>
    </item>
    
    <item>
      <title>壁纸分享[12]</title>
      <link>http://jonathanwayy.xyz/2020/bg12/</link>
      <pubDate>Sat, 19 Sep 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg12/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[33] Manjaro Linux 下 Docker 的安装与使用</title>
      <link>http://jonathanwayy.xyz/2020/blwl33/</link>
      <pubDate>Mon, 14 Sep 2020 22:17:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl33/</guid>
      <description>背景知识 Docker 是一个开源的应用容器引擎，基于 Go 语言并遵从 Apache 2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发</description>
    </item>
    
    <item>
      <title>壁纸分享[11]</title>
      <link>http://jonathanwayy.xyz/2020/bg11/</link>
      <pubDate>Sat, 12 Sep 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg11/</guid>
      <description></description>
    </item>
    
    <item>
      <title>壁纸分享[10]</title>
      <link>http://jonathanwayy.xyz/2020/bg10/</link>
      <pubDate>Sun, 06 Sep 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg10/</guid>
      <description></description>
    </item>
    
    <item>
      <title>壁纸分享[9]</title>
      <link>http://jonathanwayy.xyz/2020/bg9/</link>
      <pubDate>Wed, 26 Aug 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg9/</guid>
      <description></description>
    </item>
    
    <item>
      <title>KMP 算法笔记 - Next、Nextval数组求法、失配回退及复杂度</title>
      <link>http://jonathanwayy.xyz/2020/kmp/</link>
      <pubDate>Tue, 04 Aug 2020 16:55:15 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kmp/</guid>
      <description>Next 数组求法 1. 字符串 str 元素下标从 1 开始； 2. 令 Next[1] = 0，Next[2] = 1； 3. 令 i = 3，判断 str[i-1] 与 str[Next[i-1]] 是否相等； 3.1 若相等，则 Next[i] = Next[i-1] + 1； 3.2 若不相等，则</description>
    </item>
    
    <item>
      <title>BLWL[32] Pyinstaller 打包时报错 TypeError: an integer is required (got type bytes)</title>
      <link>http://jonathanwayy.xyz/2020/blwl32/</link>
      <pubDate>Sun, 02 Aug 2020 16:50:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl32/</guid>
      <description>报错示例 Traceback (most recent call last): File &amp;quot;/home/godlovesjonny/.local/bin/pyinstaller&amp;quot;, line 8, in &amp;lt;module&amp;gt; sys.exit(run()) File &amp;quot;/usr/lib/python3.8/site-packages/PyInstaller/__main__.py&amp;quot;, line 111, in run run_build(pyi_config, spec_file, **vars(args)) File &amp;quot;/usr/lib/python3.8/site-packages/PyInstaller/__main__.py&amp;quot;, line 63, in run_build PyInstaller.building.build_main.main(pyi_config, spec_file, **kwargs) File &amp;quot;/usr/lib/python3.8/site-packages/PyInstaller/building/build_main.py&amp;quot;, line 844, in main build(specfile, kw.get(&#39;distpath&#39;), kw.get(&#39;workpath&#39;), kw.get(&#39;clean_build&#39;)) File &amp;quot;/usr/lib/python3.8/site-packages/PyInstaller/building/build_main.py&amp;quot;, line 791, in build exec(code, spec_namespace) File &amp;quot;/home/godlovesjonny/Jonny/Installs/v2rayL-master/v2rayL-GUI/v2rayLui.spec&amp;quot;, line 18, in &amp;lt;module&amp;gt; pyz = PYZ(a.pure, a.zipped_data, File &amp;quot;/usr/lib/python3.8/site-packages/PyInstaller/building/api.py&amp;quot;, line 98, in __init__ self.__postinit__() File</description>
    </item>
    
    <item>
      <title>壁纸分享[8]</title>
      <link>http://jonathanwayy.xyz/2020/bg8/</link>
      <pubDate>Sun, 19 Jul 2020 00:03:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg8/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[31] GitHub下fork后同步源的新更新内容</title>
      <link>http://jonathanwayy.xyz/2020/blwl31/</link>
      <pubDate>Thu, 16 Jul 2020 14:24:33 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl31/</guid>
      <description>在 GitHub 下，当 A 开发者 fork 了 B 开发者的库后，若 B 开发者更新了内容， A 开发者可以通过如下方法实现库同步。 给 fork 配置远程库 查看远程状态 $&amp;gt; git remote -v 添加将被同</description>
    </item>
    
    <item>
      <title>壁纸分享[7]</title>
      <link>http://jonathanwayy.xyz/2020/bg7/</link>
      <pubDate>Wed, 15 Jul 2020 00:03:32 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg7/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[Kali学习笔记1] Kali Linux渗透测试介绍</title>
      <link>http://jonathanwayy.xyz/2020/kali1/</link>
      <pubDate>Sun, 12 Jul 2020 15:43:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kali1/</guid>
      <description>安全问题的根源 优点：分工明确，工作效率高。 缺点：从业人员对系统没有整体的认识，对安全认识较为片面。 最大威胁是人，人都会犯错，安全问题不能10</description>
    </item>
    
    <item>
      <title>BLWL[30] Vim成对符号处理插件surround</title>
      <link>http://jonathanwayy.xyz/2020/blwl30/</link>
      <pubDate>Fri, 19 Jun 2020 21:13:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl30/</guid>
      <description>surround 是一款可用于高效操作成对符号的 Vim 插件，可以实现成对符号的替换、删除等功能。 surround 插件 GitHub地址 传送门，插件安装方式很常规，这里不再赘述。</description>
    </item>
    
    <item>
      <title>BLWL[29] git拉取库时断点续传的实现</title>
      <link>http://jonathanwayy.xyz/2020/blwl29/</link>
      <pubDate>Fri, 19 Jun 2020 20:24:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl29/</guid>
      <description>git clone 不支持断点续传，拉取失败的库总是需要从头开始拉取，库大网慢的时候实在是很心累。 可以用 git fetch 解决这个问题。 # 建立同名目录并进入 $&amp;gt; mkdir dirname $&amp;gt; cd dirname #</description>
    </item>
    
    <item>
      <title>壁纸分享[6]</title>
      <link>http://jonathanwayy.xyz/2020/bg6/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:27 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg6/</guid>
      <description></description>
    </item>
    
    <item>
      <title>壁纸分享[5]</title>
      <link>http://jonathanwayy.xyz/2020/bg5/</link>
      <pubDate>Sat, 13 Jun 2020 11:41:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>壁纸分享[4]</title>
      <link>http://jonathanwayy.xyz/2020/bg4/</link>
      <pubDate>Wed, 13 May 2020 11:40:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>考研数学复习杂笔记 -- 线性代数</title>
      <link>http://jonathanwayy.xyz/2020/math-la/</link>
      <pubDate>Tue, 12 May 2020 21:46:35 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/math-la/</guid>
      <description>要证明行列式为零，除了直接计算验证外，可以主动构造相应的其次线性方程组，证明其有非零解(全书P389)；</description>
    </item>
    
    <item>
      <title>BLWL[28] Manjaro无法启动vmware虚拟机问题</title>
      <link>http://jonathanwayy.xyz/2020/blwl28/</link>
      <pubDate>Thu, 30 Apr 2020 10:22:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl28/</guid>
      <description>问题1 Could not open /dev/vmmon: ???. Please make sure that the kernel module `vmmon’ is loaded. 解决方案 1.查看自己的内核版本 &amp;gt; uname -r 5.6.7-1-MANJARO 2.安装对应的 linux-headers sudo pacman -S linux56-headers 3.加载内核模块 sudo modprobe -a vmw_vmci vmmon 问题</description>
    </item>
    
    <item>
      <title>考研数学复习杂笔记 -- 多元函数积分学</title>
      <link>http://jonathanwayy.xyz/2020/math-dj/</link>
      <pubDate>Mon, 27 Apr 2020 17:12:02 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/math-dj/</guid>
      <description>三重积分交换积分次序可采用两两交换的策略</description>
    </item>
    
    <item>
      <title>考研英语复习笔记</title>
      <link>http://jonathanwayy.xyz/2020/eng-ky1/</link>
      <pubDate>Mon, 27 Apr 2020 15:27:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/eng-ky1/</guid>
      <description>1 Lord Irvine said he ____ with a committee report this year&amp;hellip;. (sided / agreed) sided with 一般接人，故此处选择 agreed 2 lay down 1.中断；辞职；放弃 2.规定；制订（条例或规则） 3 be in safe hands (with sb.) 在可靠的人手中；</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[12] - Configuration Management</title>
      <link>http://jonathanwayy.xyz/2020/se-notes12/</link>
      <pubDate>Sun, 26 Apr 2020 16:43:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes12/</guid>
      <description>Because software changes frequently, systems, can be thought of as a set of versions, each of which has to be maintained and managed. Configuration management (CM) is concerned with the policies, processes and tools for managing changing software systems. CM Activities Change management Keeping track of requests for changes to the software from customers and developers, working out the costs and impact of changes, and deciding the changes should be</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[11] - Quality Management</title>
      <link>http://jonathanwayy.xyz/2020/se-notes11/</link>
      <pubDate>Sun, 26 Apr 2020 16:19:25 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes11/</guid>
      <description>Concerned with ensuring that the required level of quality is achieved in a software product. Three principal concerns: At the organizational level, quality management is concerned with establishing a framework of organizational processes and standards that will lead to high-quality software. At the project level, quality management involves the application of specific quality processes and checking that these planned processes have been followed. At the project level, quality management is</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[10] - Project Planning</title>
      <link>http://jonathanwayy.xyz/2020/se-notes10/</link>
      <pubDate>Sun, 26 Apr 2020 13:08:51 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes10/</guid>
      <description>Project planning involves breaking down the work into parts and assign these to project team members, anticipate problems that might arise and prepare tentative solutions to those problems. The aim of planning at this stage is to provide information that will be used in setting a price for the system to customers. Plan sections Introduction Project organization Risk analysis Hardware and software resource requirements Work breakdown Project schedule Monitoring and</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[9] - Project Management</title>
      <link>http://jonathanwayy.xyz/2020/se-notes9/</link>
      <pubDate>Sun, 26 Apr 2020 11:30:59 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes9/</guid>
      <description>Concerned with activities involved in ensuring that software is delivered on time and on schedule and in accordance with the requirements of the organisations developing and procuring the software. Success Criteria Deliver the software to the customer at the agreed time. Keep overall costs within budget. Deliver software that meets the customer’s expectations. Maintain a happy and well-functioning development team. Management</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[8] - Software Evolution</title>
      <link>http://jonathanwayy.xyz/2020/se-notes8/</link>
      <pubDate>Fri, 24 Apr 2020 19:30:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes8/</guid>
      <description>A key problem for all organizations is implementing and managing change to their existing software systems. The software evolution process Change implementation Program Evolution Dynamics Program evolution dynamics is the study of the processes of system change. After several major empirical studies, Lehman and Belady proposed that there were a number of ‘laws’ which applied to all systems as they evolved. There are sensible observations</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[7] - Software Testing</title>
      <link>http://jonathanwayy.xyz/2020/se-notes7/</link>
      <pubDate>Fri, 24 Apr 2020 13:43:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes7/</guid>
      <description>Program Testing Goals To demonstrate to the developer and the customer that the software meets its requirements. (leads to validation testing) To discover situations in which the behavior of the software is incorrect, undesirable or does not conform to its specification. (leads to defect testing) Testing can only show the presence of errors in a program. It cannot demonstrate that there are no remaining faults. Verification vs Validation Verification &amp;ldquo;Are</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[6] - Design And Implementation</title>
      <link>http://jonathanwayy.xyz/2020/se-notes6/</link>
      <pubDate>Thu, 23 Apr 2020 19:09:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes6/</guid>
      <description>Software design and implementation activities are invariably inter-leaved. An Object-oriented Design Process Object-oriented design processes involve developing a number of different system models. They require a lot of effort for development and maintenance of these models and, for small systems, this may not be cost-effective. However, for large systems developed by different groups design models are an important communication mechanism. Common activities Define the context and modes of use of</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[5] - Architectural Design</title>
      <link>http://jonathanwayy.xyz/2020/se-notes5/</link>
      <pubDate>Thu, 23 Apr 2020 13:47:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes5/</guid>
      <description>The design process for identifying the sub-systems making up a system and the framework for sub-system control and communication is architectural design, which is an early stage of the system design process. The output of this design process is a description of the software architecture. It represents the link between specification and design processes and is often carried out in parallel with some specification activities. Each architectural model only shows</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[4] - System Modeling</title>
      <link>http://jonathanwayy.xyz/2020/se-notes4/</link>
      <pubDate>Thu, 23 Apr 2020 09:53:53 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes4/</guid>
      <description>System modeling is the process of developing abstract models of a system, with each model presenting a different view or perspective of that system. System modeling helps the analyst to understand the functionality of the system and models are used to communicate with customers. Unified Modeling Language (UML) The UML is the standard language for visualizing, specifying, constructing, and documenting the artifacts of a software-intensive system. It can be used</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[3] - Requirements Engineering</title>
      <link>http://jonathanwayy.xyz/2020/se-notes3/</link>
      <pubDate>Wed, 22 Apr 2020 17:24:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes3/</guid>
      <description>Types Of Requirement User requirements: Statements in natural language plus diagrams of the services the system provides and its operational constraints. Written for customers. System requirements: A structured document setting out detailed descriptions of the system’s functions, services and operational constraints. Defines what should be implemented so may be part of a contract between client and contractor. Functional And Non-functional Requirements Functional requirements</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[2] - Agile Software Development</title>
      <link>http://jonathanwayy.xyz/2020/se-notes2/</link>
      <pubDate>Wed, 22 Apr 2020 17:18:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes2/</guid>
      <description>Agile Methods Features Focus on the code rather than the design. Are based on an iterative approach to software development. Are intended to deliver working software quickly and evolve this quickly to meet changing requirements. The aim of agile methods is to reduce overheads in the software process (e.g. by limiting documentation) and to be able to respond quickly to changing requirements without excessive rework. The principles of agile methods</description>
    </item>
    
    <item>
      <title>软件工程复习笔记[1] - Software Process</title>
      <link>http://jonathanwayy.xyz/2020/se-notes1/</link>
      <pubDate>Wed, 22 Apr 2020 14:31:05 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/se-notes1/</guid>
      <description>Software Process Software processes are the activities involved in producing a software system. General Software process models: The waterfall model, Incremental development, Reuse-oriented software engineering. Waterfall model phases: Requirements analysis and definition, System and software design, Implementation and unit testing, Integration and system testing, Operation and maintenance. The main drawback of the waterfall model: the difficulty of accommodating change after the process is underway. (In principle, a phase has to</description>
    </item>
    
    <item>
      <title>Numpy散记 -- allclose函数的使用</title>
      <link>http://jonathanwayy.xyz/2020/numpy-allclose/</link>
      <pubDate>Tue, 21 Apr 2020 13:09:31 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/numpy-allclose/</guid>
      <description>函数原型 numpy.allclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False) 参数 a, b：用于比较的两个输入数组 rtol：float型，相对容忍系数（relative tolerance parameter） atol：fl</description>
    </item>
    
    <item>
      <title>Numpy散记 -- clip函数的使用</title>
      <link>http://jonathanwayy.xyz/2020/numpy-clip/</link>
      <pubDate>Tue, 21 Apr 2020 12:54:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/numpy-clip/</guid>
      <description>函数原型 numpy.clip(a, a_min, a_max, out=None, **kwargs) 参数 a：数组 a_max：数组元素最大值 a_min：数组元素最小值 功能 np.clip()函数用于将数组元素的值保持在给定区间</description>
    </item>
    
    <item>
      <title>考研数学复习杂笔记 -- 多元函数微分学</title>
      <link>http://jonathanwayy.xyz/2020/math-dw/</link>
      <pubDate>Mon, 20 Apr 2020 16:19:26 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/math-dw/</guid>
      <description>多元函数可导推不出连续与可微：多元的可导是指一阶偏导数存在，而偏导数是用一元函数极限定义的，只与点\((x_{0}, y_{0})\)邻域内过</description>
    </item>
    
    <item>
      <title>考研数学复习杂笔记 -- 向量代数与空间解析几何</title>
      <link>http://jonathanwayy.xyz/2020/math-vk/</link>
      <pubDate>Mon, 20 Apr 2020 15:53:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/math-vk/</guid>
      <description>混合积为零等价于三向量共面 求\(\vec{a}\)和\(\vec{b}\)的对角线向量可以求\(\vec{a}^{o}+\vec{b}^{o</description>
    </item>
    
    <item>
      <title>Hugo LeaveIt主题修改代码块底色</title>
      <link>http://jonathanwayy.xyz/2020/blog5/</link>
      <pubDate>Wed, 15 Apr 2020 21:47:18 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blog5/</guid>
      <description>如上图，LeaveIt主题在浅色模式下默认的代码块背景色是纯白色，和文字撞色导致观感较差。 可对文件themes/LeaveIt/assets</description>
    </item>
    
    <item>
      <title>Hugo实现LaTex渲染</title>
      <link>http://jonathanwayy.xyz/2020/blog4/</link>
      <pubDate>Wed, 15 Apr 2020 20:56:12 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blog4/</guid>
      <description>Hugo框架本身并不支持LaTex，但是可以通过javascript进行渲染。Hugo官网上提供了多种方法，权衡之后我选择了较为简单的KaT</description>
    </item>
    
    <item>
      <title>浅谈激活函数以零为中心的问题</title>
      <link>http://jonathanwayy.xyz/2020/zero-centered-active-function/</link>
      <pubDate>Wed, 15 Apr 2020 13:20:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/zero-centered-active-function/</guid>
      <description>本文主要探讨神经网络中的激活函数不是以零为中心（non-zero-centered）是否会导致神经网络收敛变慢，并讨论其背后的原因。 神经元 如</description>
    </item>
    
    <item>
      <title>壁纸分享[3]</title>
      <link>http://jonathanwayy.xyz/2020/bg3/</link>
      <pubDate>Mon, 13 Apr 2020 11:38:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[27] Shell 杂记</title>
      <link>http://jonathanwayy.xyz/2020/blwl27/</link>
      <pubDate>Mon, 13 Apr 2020 10:06:16 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl27/</guid>
      <description>cd - 回到前一个工作路径 若在输入命令时中途改变了主意，可以按下** Alt-#* *在行首添加 # 以注释该命令并回车执行（相当于依次按下 Ctrl-A, #, Enter）。这样</description>
    </item>
    
    <item>
      <title>BLWL[26] Axel Command Tips</title>
      <link>http://jonathanwayy.xyz/2020/blwl26/</link>
      <pubDate>Thu, 12 Mar 2020 11:00:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl26/</guid>
      <description>axel 是 Linux 下一个不错的 HTTP/ftp 高速下载工具。 axel 支持多线程下载、断点续传，且可以从多个地址或者从一个地址的多个连接来下载同一个文件。 下载过程中断可以再执</description>
    </item>
    
    <item>
      <title>炼丹杂记 -- 饱和激活函数</title>
      <link>http://jonathanwayy.xyz/2020/dl-notes1/</link>
      <pubDate>Wed, 04 Mar 2020 09:07:11 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/dl-notes1/</guid>
      <description>饱和激活函数 当自变量趋于正无穷时，若激活函数的导数趋于0,则称之为右饱和。 当自变量趋于负无穷时，若激活函数的导数趋于0,则称之为左饱和。 若一</description>
    </item>
    
    <item>
      <title>34 Posh English Words</title>
      <link>http://jonathanwayy.xyz/2020/eng2/</link>
      <pubDate>Tue, 25 Feb 2020 19:58:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/eng2/</guid>
      <description>marvellous great, wonderful splendid excellent, very good sensational very good, excellent, wonderful spiffing very good(often used to mock or emulate posh people) stupendous extremely large, extremely impressive ravishing extremely beautiful dashing attractive, confident and elegent(often used to describe a man) joyous very happy; causing people to be happy glorious very beautiful and impressive or extremely enjoyable eclectic not following one style or using a wide variety [She has very eclectic taste in music.</description>
    </item>
    
    <item>
      <title>壁纸分享[2]</title>
      <link>http://jonathanwayy.xyz/2020/bg2/</link>
      <pubDate>Mon, 10 Feb 2020 11:33:00 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BLWL[25] Top Command Tips</title>
      <link>http://jonathanwayy.xyz/2020/blwl25/</link>
      <pubDate>Mon, 03 Feb 2020 00:44:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl25/</guid>
      <description>top 命令可用于查看和管控系统进程。 top 命令默认以当前消耗的 CPU 时间对所展示的进程进行排序。 若要对进程进行管控，必须以 root 用户身份运行 top。 top 运行画</description>
    </item>
    
    <item>
      <title>BLWL[24] Linux终端快捷键</title>
      <link>http://jonathanwayy.xyz/2020/blwl24/</link>
      <pubDate>Thu, 30 Jan 2020 17:34:13 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl24/</guid>
      <description>Keystrokes for Navigating Command Lines Keystroke Full Name Meaning Ctrl + F Character forward Go forward one character. Ctrl + B Character backward Go backward one character. Alt + F Word forward Go forward one word. Alt + B Word backward Go backward one word. Ctrl + A Beginning of line Go to the beginning of the current line. Ctrl + E End of line Go to the end of</description>
    </item>
    
    <item>
      <title>English Vocab Notes</title>
      <link>http://jonathanwayy.xyz/2020/eng1/</link>
      <pubDate>Wed, 29 Jan 2020 23:32:23 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/eng1/</guid>
      <description>Word Definition     prudent a. careful and sensible; marked by sound judgment   eradicate To eradicate something means to get rid of it completely.   lurk If someone lurks somewhere, they wait there secretly so that they cannot be seen, usually because they intend to do something bad.   posh elegant and fashionable   dough a flour mixture stiff enough to knead or roll; informal terms for money   crisps a thin crisp slice of potato fried in deep fat   mischievous naughtily or annoyingly playful   esbresso strong black coffee brewed by forcing hot water under pressure through finely ground coffee beans   stanch stop the flow of a liquid   efficacy n.</description>
    </item>
    
    <item>
      <title>基于人脸检测的自动口罩/护目镜佩戴小程序</title>
      <link>http://jonathanwayy.xyz/2020/mask-wearing/</link>
      <pubDate>Wed, 29 Jan 2020 18:56:28 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/mask-wearing/</guid>
      <description>最近武汉的疫情闹得沸沸扬扬，大家出行都戴上了口罩预防被传染，很多人还给自己的社交媒体头像戴上了口罩。 为了省去P图时来回来去调整的麻烦，这里开</description>
    </item>
    
    <item>
      <title>[KLI] This, That, These, Those</title>
      <link>http://jonathanwayy.xyz/2020/kli18/</link>
      <pubDate>Tue, 28 Jan 2020 18:53:37 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli18/</guid>
      <description>&amp;ldquo;This, these&amp;rdquo; and &amp;ldquo;that, those&amp;rdquo; use &amp;ldquo;Type 4&amp;rdquo; noun suffixes: -vam and -vetlh, respectively: Ha&amp;rsquo;DIbaHvam &amp;ldquo;this animal&amp;rdquo;, Ha&amp;rsquo;DIbaHmeyvetlh &amp;ldquo;those animals&amp;rdquo;.
Whether &amp;ldquo;this&amp;rdquo; or &amp;ldquo;these&amp;rdquo; is appropriate as a translation of -vam depends on whether the noun is singular or plural; similarly with &amp;ldquo;that&amp;rdquo; or &amp;ldquo;those&amp;rdquo; for -vetlh.
Note that these type 4 endings come after the type 2 plural suffix and -&amp;lsquo;e&amp;rsquo; would come last as a type 5 suffix.</description>
    </item>
    
    <item>
      <title>[KLI] To Be Or Not To Be</title>
      <link>http://jonathanwayy.xyz/2020/kli17/</link>
      <pubDate>Tue, 28 Jan 2020 18:47:04 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli17/</guid>
      <description>Klingon does not have a verb &amp;ldquo;to be&amp;rdquo;. Instead, pronouns help to fill that role.
For example, jIH means &amp;ldquo;I&amp;rdquo; or &amp;ldquo;me&amp;rdquo; but also means &amp;ldquo;I am&amp;rdquo; in sentences such as tlhIngan jIH &amp;ldquo;I am a Klingon&amp;rdquo;.
ghaH means &amp;ldquo;he&amp;rdquo;, &amp;ldquo;she&amp;rdquo;, &amp;ldquo;him&amp;rdquo;, or &amp;ldquo;her&amp;rdquo; and also means &amp;ldquo;he is&amp;rdquo; or &amp;ldquo;she is&amp;rdquo; in sentences such as tlhIngan ghaH &amp;ldquo;He is a Klingon&amp;rdquo; or &amp;ldquo;She is a Klingon&amp;rdquo;.
To specify who the &amp;ldquo;he&amp;rdquo;, &amp;ldquo;she&amp;rdquo;, or &amp;ldquo;it&amp;rdquo; is, Klingon uses pronouns in combination with a &amp;ldquo;Type 5&amp;rdquo; noun suffix -&amp;lsquo;e&amp;rsquo;.</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Pronouns</title>
      <link>http://jonathanwayy.xyz/2020/kli16/</link>
      <pubDate>Tue, 28 Jan 2020 17:23:09 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli16/</guid>
      <description>Kli Eng     jIH I (am); me   SoH you (are); you   ghaH he (is), she (is); him, her   &amp;lsquo;oH it (is); it   maH we (are); us   tlhIH you (are) - plural; you   chaH they (are) - language-users; them   bIH they (are) - objects etc.; them    Pronouns can be used to represent a noun.</description>
    </item>
    
    <item>
      <title>壁纸分享[1]</title>
      <link>http://jonathanwayy.xyz/2020/bg1/</link>
      <pubDate>Sun, 26 Jan 2020 11:35:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/bg1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Manjaro KDE 有活动窗口时模糊桌面小插件 Inactive Blur</title>
      <link>http://jonathanwayy.xyz/2020/sharp3/</link>
      <pubDate>Sun, 26 Jan 2020 11:11:17 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/sharp3/</guid>
      <description>Manjaro KDE 下一个挺有意思的桌面插件 Inactive Blur 安装后在桌面配置中启用，可以对模糊度、渐变时间、壁纸图片等进行相关设置 无活动窗口时： 有活动窗口时：</description>
    </item>
    
    <item>
      <title>[KLI] More Verb Prefixes</title>
      <link>http://jonathanwayy.xyz/2020/kli15/</link>
      <pubDate>Sat, 25 Jan 2020 22:00:44 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli15/</guid>
      <description>In the previous post, we have introduced the most common verb prefixes: jI-, vI-, bI-, Da-, ma-, Su-, and no prefix at all (sometimes called the &amp;ldquo;null&amp;rdquo; prefix).
Here we are going to introduce some new verb prefixes for combinations of subjects and objects:
   Prefix Subject Object     jI- I no object   vI- I him/her/it/them   bI- you (singular) no object   Da- you (singular) him/her/it/them   ma- we no object   Su- you (plural) no object   lu- they him/her/it   &amp;mdash;&amp;mdash;&amp;mdash;- &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;   qa- I you (singular)   Sa- I you (plural)   cho- you (singular) me   ju- you (singular) us   pI- we you (singular)   re- we you (plural)   wI we him, her, it   DI- we them   tu- you (plural) me   che- you (plural) us   bo- you (plural) him, her, it, them   mu- he, she, it, they me   Du- he, she, it you (singular)   nI- they you (singular)   nu- he, she, it, they us   lI- he, she, it, they you (plural)    Pay special attention to the fact that when the subject is &amp;ldquo;we&amp;rdquo;, there are separate prefixes wI- and DI- depending on whether the third-person object is singular (him, her, it) or plural (them) &amp;ndash; unlike when the subject is &amp;ldquo;I&amp;rdquo; (vI- for both singular and plural third person subjects) or &amp;ldquo;you (singular)&amp;rdquo; (Da- for both singular and plural third person subjects) or &amp;ldquo;you (plural)&amp;rdquo; (bo- for both singular and plural third person subjects).</description>
    </item>
    
    <item>
      <title>[KLI] Can, Cannot, Cannot Cannot...</title>
      <link>http://jonathanwayy.xyz/2020/kli14/</link>
      <pubDate>Sat, 25 Jan 2020 21:49:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli14/</guid>
      <description>The &amp;ldquo;Type 5&amp;rdquo; verb suffix -laH indicates &amp;ldquo;can&amp;rdquo; or &amp;ldquo;able to&amp;rdquo;.
For example, it makes the difference between tlhIngan Hol vIjatlh &amp;ldquo;I speak Klingon&amp;rdquo; and tlhIngan Hol vIjatlhlaH &amp;ldquo;I can speak Klingon&amp;rdquo;.
As introduced in the previous post, the verb suffix -be&#39; means &amp;ldquo;not&amp;rdquo;.
You may remember that this suffix is classified as a &amp;ldquo;rover&amp;rdquo;. Unlike suffix types 1-9, some of the rovers can actually be placed in different orders and change the meaning of the sentence slightly based on where they occur.</description>
    </item>
    
    <item>
      <title>Hugo 添加标签页卡图标</title>
      <link>http://jonathanwayy.xyz/2020/blog3/</link>
      <pubDate>Sat, 25 Jan 2020 11:16:48 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blog3/</guid>
      <description>将需要的图标图片保存为PNG格式放到static目录下即可 可以用一些Favicon生成工具先将图片制作成比较标准的图标，此前介绍过一款很方便</description>
    </item>
    
    <item>
      <title>全平台 Favicon 在线生成器 Real Favicon Generator</title>
      <link>http://jonathanwayy.xyz/2020/sharp2/</link>
      <pubDate>Sat, 25 Jan 2020 11:06:10 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/sharp2/</guid>
      <description>一款 Favicon 在线生成工具，图形化操作上传需要制作的图片即可 网站传送门</description>
    </item>
    
    <item>
      <title>[KLI] Suffixes for Each Other</title>
      <link>http://jonathanwayy.xyz/2020/kli13/</link>
      <pubDate>Fri, 24 Jan 2020 20:27:21 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli13/</guid>
      <description>-&amp;lsquo;egh indicates that the subject of the verb affects itself (or the subjects affect themselves). For example, from legh (see), one could form legh&amp;rsquo;egh torgh &amp;ldquo;Torg sees himself&amp;rdquo; or legh&amp;rsquo;egh puqpu&amp;rsquo; &amp;ldquo;the children see themselves&amp;rdquo; (perhaps in a mirror).
-chuq indicates that the subjects of the verb affect each other. It only makes sense if the subject is plural: &amp;ldquo;we, you, they&amp;rdquo;. For example, leghchuq puqpu&#39; would mean &amp;ldquo;the children see each other&amp;rdquo; &amp;ndash; that is, each child sees another child.</description>
    </item>
    
    <item>
      <title>[KLI] Apostrophes And Quotes</title>
      <link>http://jonathanwayy.xyz/2020/kli12/</link>
      <pubDate>Fri, 24 Jan 2020 20:14:03 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli12/</guid>
      <description>Klingon uses the apostrophe &#39; as a letter.
It does not use the double-quote character &amp;quot; as a letter. When you see what might look like a double-quote in the middle of the word, it is actually two apostrophes side by side.
For example, maw&#39; means &amp;ldquo;to be crazy&amp;rdquo; or &amp;ldquo;he/she is crazy&amp;rdquo;; when you add the question suffix -&amp;lsquo;a&amp;rsquo; , you get maw&#39;&amp;lsquo;a&amp;rsquo;? &amp;ldquo;is he/she crazy?&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>[KLI] Negatives And Questions</title>
      <link>http://jonathanwayy.xyz/2020/kli11/</link>
      <pubDate>Fri, 24 Jan 2020 20:03:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli11/</guid>
      <description>The verb suffix -&amp;lsquo;a&amp;rsquo; for a yes/no question and the verb suffix -be&#39; for negative.
The verb suffix -&amp;lsquo;a&amp;rsquo; is classified as a &amp;ldquo;type 9&amp;rdquo; verb suffix and will always be the last suffix on a verb. The verb suffix -be&#39; is classified as a &amp;ldquo;rover&amp;rdquo;.
These suffixes can be added to any verb to turn it into a negative or a question. For example, jIQong &amp;ldquo;I slept&amp;rdquo;, jIQongbe&#39; &amp;ldquo;I did not sleep&amp;rdquo;, jIQong&amp;rsquo;a&#39;?</description>
    </item>
    
    <item>
      <title>Hugo LeaveIt添加网站流量统计</title>
      <link>http://jonathanwayy.xyz/2020/blog2/</link>
      <pubDate>Fri, 24 Jan 2020 16:28:50 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blog2/</guid>
      <description>不蒜子是一个通过仅仅两行代码实现的网页流量计数器 1.在themes/layouts/partials/head.html文件中引入不蒜子js</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Words for &#34;Yes&#34; And &#34;No&#34;</title>
      <link>http://jonathanwayy.xyz/2020/kli10/</link>
      <pubDate>Fri, 24 Jan 2020 15:51:42 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli10/</guid>
      <description>HISlaH means &amp;ldquo;yes&amp;rdquo; and ghobe&#39; means &amp;ldquo;no&amp;rdquo;.
These words are primarily used to answer yes/no questions.
Besides these two words, Qo&#39; is used to express refusal (as in &amp;ldquo;No, I won&amp;rsquo;t!&amp;quot;). HIja&#39; also means &amp;ldquo;yes&amp;rdquo; and is a direct synonym with no different connotations.
Note that unlike the English word &amp;ldquo;no&amp;rdquo;, the words ghobe&#39; and Qo&#39; cannot be used as determiners (as in &amp;ldquo;We have no bananas.&amp;quot;), nor as adverbs (&amp;ldquo;I am no better.</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Adjectives</title>
      <link>http://jonathanwayy.xyz/2020/kli9/</link>
      <pubDate>Fri, 24 Jan 2020 15:44:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli9/</guid>
      <description>Klingon does not have adjectives as a separate class of words; instead, it has verbs which mean things such as &amp;ldquo;be handsome&amp;rdquo;, &amp;ldquo;be smart&amp;rdquo;, or &amp;ldquo;be big&amp;rdquo;.
A sentence such as val torgh &amp;ldquo;Torg is smart&amp;rdquo; has the same grammar (verb + subject) as yaj torgh &amp;ldquo;Torg understands&amp;rdquo;, even though one sentence has an adjective in English and the other an active verb.
Note that the English translation includes the connecting word &amp;ldquo;is&amp;rdquo; when you use an adjective, but the Klingon translation just connects the subject directly to the verb without using any sort of connecting word.</description>
    </item>
    
    <item>
      <title>内网文件共享工具 NitroShare</title>
      <link>http://jonathanwayy.xyz/2020/sharp1/</link>
      <pubDate>Fri, 24 Jan 2020 15:20:08 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/sharp1/</guid>
      <description>NitroShare 是一款基于Qt5的跨平台开源应用软件，可以在本地网络（内网）中实现文件共享。 NitroShare 已包含在AUR中，Manjaro 下可直接使用 yay nitroshare 命令完成安装</description>
    </item>
    
    <item>
      <title>[KLI] Joining Two Sentences With &#34;And&#34;</title>
      <link>http://jonathanwayy.xyz/2020/kli8/</link>
      <pubDate>Fri, 24 Jan 2020 12:56:54 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli8/</guid>
      <description>As mentioned in the previous post, nouns are joined with je.
To join two sentences with &amp;ldquo;and&amp;rdquo; a different word is used: &amp;lsquo;ej.
This word is placed between the sentences.
For example, &amp;ldquo;I run&amp;rdquo; (jIqet) + &amp;ldquo;I jump&amp;rdquo; (jISup) can become &amp;ldquo;I run and I jump&amp;rdquo; (jIqet &amp;lsquo;ej jISup).
&amp;lsquo;ej is only for joining sentences or verb phrases together, not nouns &amp;ndash; you cannot say torgh &amp;lsquo;ej mara, for example.</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Plurals</title>
      <link>http://jonathanwayy.xyz/2020/kli7/</link>
      <pubDate>Fri, 24 Jan 2020 12:48:25 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli7/</guid>
      <description>English plurals are a good example of using suffixes. In English an -s or an -es is generally added to the end of the noun to make it plural.
Klingon plurals are formed in a similar fashion to the English method of forming plurals. In Klingon a -pu&#39;, -Du&#39;, or -mey is added to the end of the noun.
These are the &amp;ldquo;Type 2&amp;rdquo; noun suffixes.
Nearly all Klingon nouns belong to one of three groups, depending on which &amp;ldquo;Type 2&amp;rdquo; noun suffix they use to form their plural:</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Verb And Noun Suffixes</title>
      <link>http://jonathanwayy.xyz/2020/kli6/</link>
      <pubDate>Fri, 24 Jan 2020 12:39:30 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli6/</guid>
      <description>Meaning is added to Klingon words through use of syllables added to the front or ends of words.
Syllables added to the beginnings of words are called prefixes and in Klingon indicate who is doing a particular verb and who that action is done to.
Suffixes are added to the ends of words and occassionally you will encounter a word with more than one suffix. Klingon linguists categorize these suffixes according to which ones cannot occur together and what order they must occur in.</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Word Order</title>
      <link>http://jonathanwayy.xyz/2020/kli5/</link>
      <pubDate>Fri, 24 Jan 2020 12:34:14 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli5/</guid>
      <description>Klingon word order in a sentence may seem like the opposite of English word order - first comes the object (if any), then the verb, then the subject. So a sentence such as mara legh torgh means &amp;ldquo;Torg sees Mara&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>[KLI] Joining Nouns With And Without &#34;And&#34;</title>
      <link>http://jonathanwayy.xyz/2020/kli4/</link>
      <pubDate>Fri, 24 Jan 2020 12:22:46 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli4/</guid>
      <description>Nouns are joined with je, which comes after the nouns.
If there is no je after two nouns next to each other, the effect is similar to possession: mara pong &amp;ldquo;Mara&amp;rsquo;s name&amp;rdquo;; tlhIngan Hol &amp;ldquo;a Klingon&amp;rsquo;s language, the Klingon language&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Verbs</title>
      <link>http://jonathanwayy.xyz/2020/kli3/</link>
      <pubDate>Fri, 24 Jan 2020 11:47:52 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli3/</guid>
      <description>Klingon verbs do not have tense (past, present, future), so a verb such as yaj could mean &amp;ldquo;understands, understood, will understand&amp;rdquo;.
In grammar, a subject is the one doing the action and an object is the one the action is done to. Klingon verbs show the subject and the object of verbs by means of prefixes.
The most important verb prefixes are:
 jI- = I (subject), no object bI- = you (subject), no object &amp;ndash; for single person ma- = we (subject), no object Su- = you (subject), no object &amp;ndash; for multiple people, also some times said as &amp;ldquo;you guys&amp;rdquo;, &amp;ldquo;all of you&amp;rdquo;, &amp;ldquo;you all&amp;rdquo;, or &amp;ldquo;y&amp;rsquo;all&amp;rdquo; vI- = I (subject), him/her/it/them (object) Da- = you (subject), him/her/it/them (object) &amp;ndash; for single person lu- = they (subject), him/her/it (object)  If the subject is third person (he/she/it/they) and has either no object or a third-person object (him/her/it/them), then the verb has no prefix.</description>
    </item>
    
    <item>
      <title>[KLI] nuqheH &amp; nuqjatlh &amp; Qapla&#39;</title>
      <link>http://jonathanwayy.xyz/2020/kli2/</link>
      <pubDate>Fri, 24 Jan 2020 10:47:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli2/</guid>
      <description>nuqneH is a truncated form of nuq DaneH, meaning &amp;ldquo;What do you want?&amp;rdquo;
It is a common misconception that this is &amp;ldquo;the Klingon word for hello&amp;rdquo;. In fact, Klingons have no word for hello. If a Klingon wishes to say something, they&amp;rsquo;ll walk up to you and say it, without wasting time - as they see it - on idle chatter.
nuqjatlh? is a truncated form of nuq Dajatlh?, meaning &amp;ldquo;What did you say?</description>
    </item>
    
    <item>
      <title>[KLI] Klingon Alphabet</title>
      <link>http://jonathanwayy.xyz/2020/kli1/</link>
      <pubDate>Fri, 24 Jan 2020 10:44:47 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/kli1/</guid>
      <description>letter prounciation     a &amp;lsquo;at   b b   ch chay   D Day   e &amp;lsquo;et   gh ghay   H Hay   I &amp;lsquo;It   j jay   l l   m may   n n   ng ngay   o &amp;lsquo;ot   p p   Q Qay   q qay   r ray   S Say   t t   tlh tlhay   u &amp;lsquo;ut   v v   w way   y yay   &#39; qaghwI&amp;rsquo;    Notes:  In Klingon, case matters.</description>
    </item>
    
    <item>
      <title>修改LeaveIt主题标题栏失去焦点时内容</title>
      <link>http://jonathanwayy.xyz/2020/blog1/</link>
      <pubDate>Fri, 24 Jan 2020 09:51:39 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blog1/</guid>
      <description>LeaveIt主题默认在失去焦点时会在标题栏显示I Miss You 可以在themes/LeaveIt/assets/js/main.js文件中进行修改 找</description>
    </item>
    
    <item>
      <title>BLWL[23] Ranger Notes</title>
      <link>http://jonathanwayy.xyz/2020/blwl23/</link>
      <pubDate>Thu, 23 Jan 2020 22:45:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl23/</guid>
      <description>许多 Ranger 命令与 Vim 类似 [/] 用于切换父文件夹 zh 或 Ctrl+h 显示/收起隐藏文件 zv 切换是否启用预览脚本 zi 切换是否预览图片 dU 查看当前目录下各个文件夹大小 o_ 系列用于</description>
    </item>
    
    <item>
      <title>BLWL[22] 撤销git提交</title>
      <link>http://jonathanwayy.xyz/2020/blwl22/</link>
      <pubDate>Thu, 23 Jan 2020 22:44:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl22/</guid>
      <description>Git Commit Withdrawal 撤销上一次提交 git reset &amp;ndash;soft HEAD^ 撤销前n次提交 git reset &amp;ndash;soft HEAD~n 仅修改 commit 注释 git commit &amp;ndash;amend 参数： &amp;ndash;soft 不删除工作空间改动代码，撤销 commit，不撤销 git add . &amp;ndash;hard 删除工作</description>
    </item>
    
    <item>
      <title>BLWL[21] Ack Command Tips</title>
      <link>http://jonathanwayy.xyz/2020/blwl21/</link>
      <pubDate>Thu, 23 Jan 2020 22:43:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl21/</guid>
      <description>ack 是一个使用 Perl 语言开发的高效代码搜索工具 默认会搜索当前目录下所有文件内容，只要包含关键字就输出 文本搜索 ack keyword ack -l keyword # 只显示文件名 ack -i keyword # 忽略大</description>
    </item>
    
    <item>
      <title>BLWL[20] 订阅Linux邮件列表</title>
      <link>http://jonathanwayy.xyz/2020/blwl20/</link>
      <pubDate>Thu, 23 Jan 2020 22:42:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl20/</guid>
      <description>学习 Linux 内核可以订阅 Linux 的邮件列表，订阅的方法如下： 登录网站： http://vger.kernel.org/vger-lists.html 找到自己感兴趣的模块 登录自己的邮箱，编辑邮件内容： subcribe [你要订阅的模块名]，发送到</description>
    </item>
    
    <item>
      <title>BLWL[19] 修改iPython使用的默认Python</title>
      <link>http://jonathanwayy.xyz/2020/blwl19/</link>
      <pubDate>Thu, 23 Jan 2020 22:41:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl19/</guid>
      <description>iPython 是一个很好用的交互式 Python 解释器， Manjaro 前一次内核升级后系统 Python 升到了 3.8，而 Pytorch 目前还只支持到 Python3.7，因此配了 conda，但是 iPython 默认调</description>
    </item>
    
    <item>
      <title>BLWL[18] Vimscript Notes</title>
      <link>http://jonathanwayy.xyz/2020/blwl18/</link>
      <pubDate>Thu, 23 Jan 2020 22:40:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl18/</guid>
      <description>:echo 命令输出的信息在脚本运行完毕后就会消失， :echom 打印的信息会保存下来，可以执行 :messages 命令再次查看 :set /:set no或直接 :set ! 可切换布尔选项的值 :set ? 命令可获取一</description>
    </item>
    
    <item>
      <title>BLWL[17] Vim保存上次退出时光标位置</title>
      <link>http://jonathanwayy.xyz/2020/blwl17/</link>
      <pubDate>Thu, 23 Jan 2020 22:39:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl17/</guid>
      <description>记录上次关闭某一文件时的光标位置，并在下一次打开该文件时将光标移动到该位置 在 .vimrc 中添加 au BufReadPost * if line(&amp;quot;&#39;\&amp;quot;&amp;quot;) &amp;gt; 1 &amp;amp;&amp;amp; line(&amp;quot;&#39;\&amp;quot;&amp;quot;) &amp;lt;= line(&amp;quot;$&amp;quot;) | exe &amp;quot;normal! g&#39;\&amp;quot;&amp;quot; | endif 保存即可</description>
    </item>
    
    <item>
      <title>BLWL[16] Vimdiff Tips</title>
      <link>http://jonathanwayy.xyz/2020/blwl16/</link>
      <pubDate>Thu, 23 Jan 2020 22:38:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl16/</guid>
      <description>Vimdiff 是 Vim 自带的一个文件差异编辑器 启动 vimdiff： vimdiff file1 file2 常用命令： ]c 下一差异 [c 上一差异 do 导入差异 dp 导出差异 zo 打开折叠 zc 关闭折叠 :diffupdate 重新扫描文件</description>
    </item>
    
    <item>
      <title>BLWL[15] Vim Tips</title>
      <link>http://jonathanwayy.xyz/2020/blwl15/</link>
      <pubDate>Thu, 23 Jan 2020 22:37:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl15/</guid>
      <description>i 如 ci&amp;quot;，di&amp;lt;，yi( 等，在相应符号间执行有关操作 f 查询与其他操作配合使用实现操作至某字符的效果，如df:，yfa visual 模式</description>
    </item>
    
    <item>
      <title>BLWL[14] Vim Macro的使用</title>
      <link>http://jonathanwayy.xyz/2020/blwl14/</link>
      <pubDate>Thu, 23 Jan 2020 22:36:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl14/</guid>
      <description>可以通过 Vim 的宏录制完成重复的同一操作 在 normal 模式下输入 qa（qb，qc，etc.）选择将录制好的宏放入寄存器 a（b，c，etc.） 正常情况下， Vim</description>
    </item>
    
    <item>
      <title>BLWL[13] 为较常用命令设置别名</title>
      <link>http://jonathanwayy.xyz/2020/blwl13/</link>
      <pubDate>Thu, 23 Jan 2020 22:35:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl13/</guid>
      <description>可以为较常用的命令设置别名 指令：alias 语法： alias alias_name=&#39;command&#39; 如： alias ra=&#39;ranger&#39; 要长期生效，将命令添加在相应 shell 的配置文件中即可。</description>
    </item>
    
    <item>
      <title>BLWL[12] Manjaro KDE安装并激活Edraw</title>
      <link>http://jonathanwayy.xyz/2020/blwl12/</link>
      <pubDate>Thu, 23 Jan 2020 22:34:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl12/</guid>
      <description>在日常科研写论文的过程中，经常需要用到 Visio 之类的画图工具来绘制模型图。但是 Linux 环境下并不支持 Visio。 Edraw Max 的跨平台性使其成为了 Linux 下 Visio 很好的替代</description>
    </item>
    
    <item>
      <title>BLWL[11] 使用Clear命令Terminals Database Inaccessible报错问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl11/</link>
      <pubDate>Thu, 23 Jan 2020 22:33:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl11/</guid>
      <description>问题： 当使用 clear 命令时出现如下报错 ~$ clear terminals database is inaccessible 临时解决方法： ~$ export TERMINFO=/usr/share/terminfo 最好将上面这条 export 命令添加到 .bashrc 中。</description>
    </item>
    
    <item>
      <title>BLWL[10] Manjaro更新时Invalid Software Package问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl10/</link>
      <pubDate>Thu, 23 Jan 2020 22:32:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl10/</guid>
      <description>Manjaro 更新报错-无效或已损坏的软件包( PGP 签名) 原因：使用了社区源且开启了验证，关闭验证即可 vim /etc/pacman.conf 找到社区源相关部分 [archlinuxcn] #SigLevel = Optional TrustedOnly SigLevel = Optional TrustAll Server = http://repo.archlinuxcn.org/$arch</description>
    </item>
    
    <item>
      <title>BLWL[9] Unzip解压中文乱码问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl9/</link>
      <pubDate>Thu, 23 Jan 2020 22:31:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl9/</guid>
      <description>在 Linux 下使用 unzip 解压文件时，解压完毕的文件中若包含中文内容，可能会出现乱码的情况，本文提供一个可供参考的解决方案。 1.执行 unzip 命令，查看系统上是否</description>
    </item>
    
    <item>
      <title>BLWL[8] Manjaro KDE成功安装并平稳使用TIM</title>
      <link>http://jonathanwayy.xyz/2020/blwl8/</link>
      <pubDate>Thu, 23 Jan 2020 22:30:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl8/</guid>
      <description>配置好镜像源（开箱后的常规三步走即可） 安装 QQ 或 TIM， pacman 一下即可 sudo pacman -S deepin.com.qq.office sudo pacman -S deepin.com.qq.im 尝试一下是否可以打开（如果启动菜单没有，可以在 /opt/deepinwine/apps/ 目录下找到）</description>
    </item>
    
    <item>
      <title>BLWL[7] Manjaro KDE 画面撕裂问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl7/</link>
      <pubDate>Thu, 23 Jan 2020 22:29:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl7/</guid>
      <description>就如在 BLWL02 中所提到的，之前在新机子上装 Manjaro KDE 屡试未果，画面一直撕裂，最后没办法换了 XFCE XFCE 倒确实顺风顺水没出什么幺蛾子，但是用习惯了 KDE 的华丽画风导致</description>
    </item>
    
    <item>
      <title>BLWL[6] Manjaro KDE安装Google拼音输入法</title>
      <link>http://jonathanwayy.xyz/2020/blwl6/</link>
      <pubDate>Thu, 23 Jan 2020 22:28:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl6/</guid>
      <description>先安装相关软件 sudo pacman -S fcitx-im fcitx-configtool fcitx-googlepinyin 然后在用户根目录编辑 .xprofile 文件（没有就新建一个） vim ~/.xprofile 若是刚装好的 Manjaro 上使用 vim 需要安装一下， pacman 即可 内容写： export LC_ALL=zh_CN.UTF-8 export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=&amp;quot;@im=fcitx&amp;quot;</description>
    </item>
    
    <item>
      <title>BLWL[5] Manjaro KDE 中文字符变方框问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl5/</link>
      <pubDate>Thu, 23 Jan 2020 22:27:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl5/</guid>
      <description>该问题一般出现在刚刚装完的 Manjaro 上，一些操作后突然中文字符全部变成了方框 一般情况下可以通过安装字体解决 sudo pacman -S wqy-microhei 然后重启即可</description>
    </item>
    
    <item>
      <title>BLWL[4] Manjaro KDE上Teamviewer闪退问题解决方案</title>
      <link>http://jonathanwayy.xyz/2020/blwl4/</link>
      <pubDate>Thu, 23 Jan 2020 22:26:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl4/</guid>
      <description>直接 pacman 安装的 TV 会出现一直 &amp;ldquo;Not Ready,&amp;hellip;&amp;rdquo; 的情况 此时先 sudo teamviewer --daemon enable 再打开 Teamviewer 即可</description>
    </item>
    
    <item>
      <title>BLWL[3] Manjaro Pip替换清华源</title>
      <link>http://jonathanwayy.xyz/2020/blwl3/</link>
      <pubDate>Thu, 23 Jan 2020 22:25:56 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl3/</guid>
      <description>修改 ~/.pip/pip.conf (没有就创建一个) [global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple</description>
    </item>
    
    <item>
      <title>BLWL[2] Manjaro Xfce桌面背景替换</title>
      <link>http://jonathanwayy.xyz/2020/blwl2/</link>
      <pubDate>Thu, 23 Jan 2020 22:24:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl2/</guid>
      <description>新机子一开始想也装 KDE 桌面版，然而独显驱动似乎配置上出了什么问题，看了一些资料捣鼓了两天仍然未见成效 主要是 KDE 桌面的画面撕裂问题，暂时没找到好的</description>
    </item>
    
    <item>
      <title>BLWL[1] 使用Pacman优雅地安装程序</title>
      <link>http://jonathanwayy.xyz/2020/blwl1/</link>
      <pubDate>Thu, 23 Jan 2020 22:23:58 +0800</pubDate>
      
      <guid>http://jonathanwayy.xyz/2020/blwl1/</guid>
      <description>Reason to use pacman Arch 下简洁高效的包管理命令 享受 AUR(Arch User Repository)，软件库相当庞大，无需像 Debian 系一样手动添加 ppa 源等 Commonly Used Commands 安装软件 sudo pacman -S 软件名 获取最</description>
    </item>
    
  </channel>
</rss>
